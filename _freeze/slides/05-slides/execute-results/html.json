{
  "hash": "269b7a830f598ea80ecdbb474cb0c9c1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical Inference\"\nformat: \n  revealjs:\n    theme: simple\n    smaller: true\n    slide-number: true\n    # incremental: true\n    # code-link: true\n    chalkboard: true\n    history: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Overview\n\n::::: columns\n::: {.column style=\"font-size: smaller;\"}\n1.   **Population vs. Sample**\n\n3.  **Inventing Null Worlds**\n\n4.  **The Central Limit theorem**\n\n5.  **Theoretical Distributions**\n\n:::\n\n::: {.column style=\"font-size: smaller;\"}\n\n:::\n:::::\n\n# Population vs. Sample\n\n---\n\n## Why do we do statistics ?\n\n<br>\nTo make inferences about a population based on observing only a sample\n\n---\n\n## Are action movies better than comedies?\n\n. . . \n\n### Data → Calculation → Estimate → Truth {.center}\n\n:::{.fragment}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Category    |Description                                   |Notation                                                                      |\n|:-----------|:---------------------------------------------|:-----------------------------------------------------------------------------|\n|Data        |IMDB ratings                                  |$D$                                                                           |\n|Calculation |Average action rating − average comedy rating |$\\bar{D} = \\frac{\\sum{D}_\\text{Action}}{N} - \\frac{\\sum{D}_\\text{Comedy}}{N}$ |\n|Estimate    |$\\bar{D}$ in a sample of movies               |$\\hat{\\delta}$                                                                |\n|Truth       |Difference in rating for *all* movies         |$\\delta$                                                                      |\n\n\n:::\n:::\n\n\n\n\n:::\n\n---\n\n## Greek, Latin, and extra markings\n\n<br>\n\n. . . \n\n:::: columns\n::: {.column width=\"50%\"}\n\n**Greek**\n\n- Letters like $\\delta$ are the ***truth***\n\n- Letters with extra markings like $\\hat{\\delta}$ are our ***estimate*** of the truth based on our sample\n\n:::\n\n::: {.column width=\"50%\"}\n\n**Latin**\n\n- Letters like $D$ are ***actual data*** from our sample\n\n- Letters with extra markings like $\\bar{D}$ are ***calculations*** from our sample\n\n:::\n::::\n\n---\n\n## Your turn #1: Calculating an estimate\n\nCollect IMDB ratings for a bunch of films via the `ggplot2movies` package.\n\n1. Install the package (use either console or the Rstudio interface. Do not use a Script)\n\n2. Load the package in your script. \n\n3. Load the movies data (type: `data(\"movies\")`)\n\n4. Make a new cleaned data frame by\n  - selecting only the `title`, `year`, `rating`, `Action` and `Comedy` columns\n  - filtering out films that classify as both Action and Comedy\n  - making a new variable `genre` (using `mutate()` and `case_when()`) which takes the values \"Action\" or \"Comedy\"\n  - removing the now obsolete `Action` and `Comedy` columns (use `select` and `-`)\n\n5. Calculate the average ratings for the two genres\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_6157d945\" data-update-every=\"1\" data-start-immediately=\"true\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:1em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">08</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n---\n\n## Your turn #1: Calculating an estimate \n\n1. Install the package (use either console or the Rstudio interface. Do not use a Script)\n\nUse `install.packages(\"ggplot2movies\")` in your console.\n\n2. Load the package in your script. \n\nUse `library(ggplot2movies)` in your script.\n\n3. Load the movies data (type: `data(\"movies\")`)\n\n---\n\n## Your turn #1: Calculating an estimate \n\n4. Make a new cleaned data (`movie_data`) frame by\n  - selecting only the `title`, `year`, `rating`, `Action` and `Comedy` columns\n  - filtering out films that classify as both Action and Comedy\n  - making a new variable `genre` (using `mutate()` and `case_when()`) which takes the values \"Action\" or \"Comedy\"\n  - removing the now obsolete `Action` and `Comedy` columns (use `select` and `-`)\n  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean up data\nmovie_data <- movies |> \n  select(title, year, rating, Action, Comedy) |> \n  filter(!(Action == 1 & Comedy == 1)) |> \n  mutate(genre = case_when(Action == 1 ~ \"Action\",\n                           Comedy == 1 ~ \"Comedy\",\n                           TRUE ~ \"Neither\")) |>\n  filter(genre != \"Neither\") |>\n  # Make genre a factor (not necessary at this point)\n  mutate(genre = factor(genre)) |> \n  select(-Action, -Comedy)\n```\n:::\n\n\n\n---\n\n## Your turn #1: Calculating an estimate \n\n5. Calculate the average ratings for the two genres\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmovie_data |> \n  group_by(genre) |> \n  summarize(avg_rating = mean(rating)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  genre  avg_rating\n  <fct>       <dbl>\n1 Action       5.24\n2 Comedy       5.97\n```\n\n\n:::\n:::\n\n\n\n---\n\n## So, are action movies better than comedies? \n\n:::{.center}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  genre  avg_rating\n  <fct>       <dbl>\n1 Action       5.24\n2 Comedy       5.97\n```\n\n\n:::\n:::\n\n\n:::\n\n$$\n\\hat{\\delta} = \\bar{D} = 5.24 - 5.97 = -0.73\n$$\n\n. . .\n\nAction movies seem to be slightly worse. But...\n\n. . .\n\nWe don't know if the estimate we found in this sample is actually true for the population of **all films**\n\n# Inventing Null Worlds\n\n---\n\n## Simulated Null World \n\n- Let's try to imagine a world with no differences between action and comedy movies\n\n. . .\n\n- We simulate data with ratings for 1'000'000 movies where there is no difference (the true $\\delta$ is 0). Imagine that's the population, i.e. all movies ever made.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234) # For reproducibility\n\nimaginary_movies <- tibble(\n  movie_id = 1:1000000,\n  rating = sample(seq(1, 10, by = 0.1), size = 1000000, replace = TRUE),\n  genre = sample(c(\"Comedy\", \"Action\"), size = 1000000, replace = TRUE)\n)\n```\n:::\n\n\n\n---\n\n## Simulated Null World \n\nOur simulated action movies and comedies don't all have the same rating, but on average there's (almost) no difference\n\n:::: columns\n::: {.column width=\"30%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimaginary_movies |> \n  group_by(genre) |> \n  summarize(avg_rating = mean(rating)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  genre  avg_rating\n  <chr>       <dbl>\n1 Action       5.51\n2 Comedy       5.50\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(imaginary_movies, \n       aes(x = rating, fill = genre)) +\n  geom_bar(alpha = 0.4, position = \"identity\") +\n  scale_x_continuous(breaks = seq(1,10))\n```\n\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n--- \n\n## Sampling & Estimating in the Null world\n\nIn the actual IMDB data, we looked at a sample of about 20'000 films. \n\n. . .\n\n<br>\n\nWe can randomly pick a sample of that same size from our simulated population\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# draw a sample of 20'000 films\nimaginary_sample <- imaginary_movies |> \n  sample_n(20000)\n```\n:::\n\n\n\n. . .\n\nIn this sample, we actually find a small difference\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute rating difference in the sample\nestimate <- imaginary_sample |> \n  group_by(genre) |> \n  summarize(avg_rating = mean(rating)) |> \n  summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %>%\n  pull(diff)\n\nestimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.03535811\n```\n\n\n:::\n:::\n\n\n\n---\n\nLet's repeat this process of sampling and estimating 1000 times, and store the results.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_simulations <- 1000\ndifferences <- c() # make an empty vector\n\nfor (i in 1:n_simulations) {\n  # draw a sample of 20'000 films\n  imaginary_sample <- imaginary_movies |> \n    sample_n(20000)\n  # compute rating difference in the sample\n  estimate <- imaginary_sample |> \n    group_by(genre) |> \n    summarize(avg_rating = mean(rating)) |> \n    summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %>%\n    pull(diff)\n  \n  differences[i] <- estimate\n}\n```\n:::\n\n\n\n---\n\nWe can plot the results for an overview\n\n::::columns\n\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_simulations <- 1000\ndifferences <- c() # make an empty vector\n\nfor (i in 1:n_simulations) {\n  # draw a sample of 20'000 films\n  imaginary_sample <- imaginary_movies |> \n    sample_n(20000)\n  # compute rating difference in the sample\n  estimate <- imaginary_sample |> \n    group_by(genre) |> \n    summarize(avg_rating = mean(rating)) |> \n    summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %>%\n    pull(diff)\n  \n  differences[i] <- estimate\n}\n```\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  labs(title = \"Distribution of Rating Differences\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n---\n\n## Check $\\hat{\\delta}$ in the null world\n\nDoes the estimate we found in the  IMDB data ($\\hat{\\delta}$ = -0.73) fit well into the world where the true difference $\\delta$ is 0?\n\n. . .\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  labs(title = \"Distribution of Rating Differences\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## Check $\\hat{\\delta}$ in the null world\n\nDoes the estimate we found in the  IMDB data ($\\hat{\\delta}$ = -0.73) fit well into the world where the true difference $\\delta$ is 0? Not really.\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  geom_vline(xintercept = -0.73, color = \"red\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Distribution of Rating Differences\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n\n---\n\n## So, again, are action movies better than comedies? \n\n::: {.incremental}\n\n- We can now pretty confidently say that in a world where there is no difference, observing what we observed is super unlikely. \n\n- Therefore, we're pretty confident that in fact there is a difference.\n\n- (We still don't know what the true difference is, but at least we can say it's unlikely to be 0) \n\n- 🎉 Congratulations, if you got that, you got the whole intuition behind hypothesis testing. \n\n:::\n\n---\n\nAll this is good, but how (un)likely **exactly** is it to observe our $\\hat{\\delta}$ in the null world? \n\n. . .\n\nThat is where the central limit theorem and theoretical distributions come into play...\n\n# The central limit theorem\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nYou have seen before the estimated mean differences of our imaginary samples (the $\\hat{\\delta}s$), somehow magically, form a curve that is...\n\n- bell-shaped \n- centered around the true value ($\\delta$), which in our case was 0. \n\n:::{.fragment fragment-index=\"1\"}\nThis distribution of estimates is also called the **sampling distribution**.\n:::\n\n:::{.fragment fragment-index=\"2\"}\nThe central limit theorem states that, with many observations, the sampling distribution approximates a normal distribution.\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n:::: r-stack\n\n:::{.fragment .fade-out fragment-index=\"3\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::{.fragment .fade-in fragment-index=\"3\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n:::\n\n::::\n\n# Theoretical distributions\n\n---\n\n## Quick recap\n\n::: {.incremental}\n\n- Remember our problem: We were not sure how (un)likely exactly our observation was in the Null world \n\n- Thanks to the central limit theorem, we know that sampling distributions approximate theoretical distributions.\n\n- And for theoretical distributions, thanks to math, we know exactly how likely a certain value is 🎉 \n\n:::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nThe most famous bell-shaped distribution is the (standard) normal distribution. \n\nThe standard normal distribution is centered around 0 and has a standard deviation of 1. \n\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nWe know, e.g., that 99% of the distribution lie between $\\pm$ 2.58\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nOr that 95% of the distribution lie between $\\pm$ 1.96\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::::\n\n--- \n\n:::: columns\n::: {.column width=\"40%\"}\n\nNow, all we need to do is bring our sampling distribution on the scale of a standard normal distribution. \n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nNow, all we need to do is bring our sampling distribution on the scale of a standard normal distribution. \n\nWe achieve this by \n\n1. Subtracting the mean from all values (in our case, that is 0, so nothing happens) \n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-wrap}\ndifferences_mean_centered <- differences - mean(differences)\n```\n:::\n\n\n\nIn our case, that is (almost) 0, so not much happens \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(differences)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.006633846\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n:::: r-stack\n:::{.fragment .fade-out fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-23-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::{.fragment .fade-in fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-24-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nNow, all we need to do is bring our sampling distribution on the scale of a standard normal distribution. \n\nWe achieve this by \n\n1. Subtracting the mean from all values \n\n2. Dividing by the standard deviation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndifferences_scaled <- differences_mean_centered / sd(differences_mean_centered)\n```\n:::\n\n\n\nSince the sd is small than 1, our values become bigger\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(differences_mean_centered)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03814568\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n:::: r-stack\n:::{.fragment .fade-out fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-27-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::{.fragment .fade-in fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nInstead of a histogram, we can use a density plot (which uses the same y-axis as the normal distribution, namely density)\n:::\n\n::: {.column width=\"60%\"}\n\n:::: r-stack\n:::{.fragment .fade-out fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-29-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::{.fragment .fade-in fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-30-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nFinally, we can lay over the standard normal distribution\n:::\n\n::: {.column width=\"60%\"}\n\n:::: r-stack\n:::{.fragment .fade-out fragment-index=\"1\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-31-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n:::{.fragment .fade-in fragment-index=\"1\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::::\n\n:::\n\n::::\n\n---\n\n:::: columns\n::: {.column width=\"40%\"}\n\nNow we can say for sure that in our Null world, chances that we get an estimate as extreme as the one in our IMBD data is **less than 5%**\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-slides_files/figure-revealjs/unnamed-chunk-33-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::::\n\n---\n\nYou can even calculate the exact probability of observing the estimate in a null world...\n\n. . .\n\n1. Bring your estimate on a scale of the standard normal distribution (that is also called a z-value)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate <- 0.73\nsd_sampling_distribution <- sd(differences)\n\nz_scaled_estimate = estimate / sd_sampling_distribution\n\nz_scaled_estimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 19.13716\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n::: {.callout-note}\nYou don't need to do a simulation of your sampling distribution all the time. \nIn general, we obtain the standard deviation of the (imaginary) sampling distribution with math. This standard deviation is so important that it has its own name: the **Standard Error (SE)**\n:::\n\n---\n\nYou can even calculate the exact probability of observing the estimate in a null world...\n\n1. Bring your estimate on a scale of the standard normal distribution (that is also called a z-value)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate <- 0.73\nsd_sampling_distribution <- sd(differences)\n\nz_scaled_estimate = estimate / sd_sampling_distribution\n\nz_scaled_estimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 19.13716\n```\n\n\n:::\n:::\n\n\n\n2. Look up the corresponding probability (luckily, in R that's very easy)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the pnorm() function gives the cumulative probability from the standard normal distribution \n\n# Two-tailed (i.e. a value \"at least as extreme as\", in both directions)\nprobability <- 2 * (1 - pnorm(z_scaled_estimate)) \n\n# in our case, the probability is reeaally low (practically 0)\nprobability\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n::: {.callout-note}\nIn the real world, people actually use a slightly different version of the standard normal distribution, the t-distribution. The principle, however, is the same.\n:::\n\n---\n\n🎉 The probability that you have just calculated is also called p-value 🎉\n\nIt's the probability of observing an estimate at least as extreme as the one in our sample, in a world where there is no true effect (the Null world). \n\n---\n\n## Hypothesis testing in a nutshell {.incremental}\n\n:::{.incremental style=\"font-size: smaller;\"}\n- **Step 1: Calculate an estimate based on your sample ($\\hat{\\delta}$).**  \n  This is the main measure you care about: the difference in means, the average, the median, the proportion, the difference in proportions, etc.\n\n- **Step 2: Use simulation to invent a world where the true effect ($\\delta$) is null.**  \n  Simulate what the world would look like if there was no difference between two groups, or if there was no difference in proportions, or where the average value is a specific number.\n\n- **Step 3: Look at $\\hat{\\delta}$ in the null world.**  \n  Put the sample statistic in the null world and see if it fits well.\n\n- **Step 4: Calculate the probability that $\\hat{\\delta}$ could exist in the null world.**  \n  This is the p-value, or the probability that you'd see a $\\hat{\\delta}$ at least that high in a world where there's no difference.\n\n- **Step 5: Decide if $\\hat{\\delta}$ is statistically significant.**  \n  Choose some evidentiary standard or threshold for deciding if there's sufficient proof for rejecting the null world. Standard thresholds (from least to most rigorous) are 0.1, 0.05, and 0.01.\n:::\n\n# An applied example\n\n---\n\n## Are action movies better than comedies? \n\n. . . \n\nWe can use a single command in R to test this hypothesis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform a t-test to compare ratings between Action and Comedy movies\nt.test(rating ~ genre, data = movie_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  rating by genre\nt = -26.537, df = 5578.2, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group Action and group Comedy is not equal to 0\n95 percent confidence interval:\n -0.7907698 -0.6819730\nsample estimates:\nmean in group Action mean in group Comedy \n            5.237372             5.973744 \n```\n\n\n:::\n:::\n\n\n\n. . .\n\nWe get a very small p-value\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using format() to use non-scientific notation\nformat(2.2204460493e-16, scientific = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"0.0000000000000002220446\"\n```\n\n\n:::\n:::\n\n\n\n---\n\nThat's it for today :)\n\n\n\n\n\n\n\n",
    "supporting": [
      "05-slides_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}