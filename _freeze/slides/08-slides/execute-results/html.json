{
  "hash": "1e660f7e3f3aef3f1f0842238f685026",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Colliders and Confounders\"\nformat: \n  revealjs:\n    theme: simple\n    smaller: true\n    slide-number: true\n    # incremental: true\n    # code-link: true\n    chalkboard: true\n    history: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Overview\n\n::::: columns\n::: {.column style=\"font-size: smaller;\"}\n1.  **What is Causality**\n\n2. **Correlation is not causality**\n\n3. **Confounders**\n\n4.  **Colliders**\n\n:::\n\n::: {.column style=\"font-size: smaller;\"}\n\n:::\n:::::\n\n# What is Causality? \n\n---\n\n## We all have an idea of what ‚Äúcausality‚Äù means. \n\n<br>\n\nWhenever we ask ‚Äúwhy‚Äù question, we are asking for a cause.\n\n---\n\n## A simple definition\n\n- We could say that X causes Y if‚Ä¶\n\n- we were we to intervene and change the value of X without changing anything else‚Ä¶\n\n- and then Y would change as a result.\n\n---\n\n## Associations vs. Causality\n\n::::: columns\n::: {.column}\n**How do we figure out associations?**\n\n<br>\n\nLooking at data, using math and statistics\n:::\n\n::: {.column}\n**How do we figure out causation? **\n\n<br>\n\nPhilosophy (and good research design). No math or stats.\n:::\n\n:::::\n\n---\n\n![](images/simpsons.jpg){width=\"80%\"}\n\n# Confounders\n\n---\n\n## Does self-confidence make you being kissed more often? \n\nImagine you are a researcher and have this (slightly stupid) research question. \n\n\n\n::: {.cell}\n\n:::\n\n\n\n---\n\n## What does this (made up!) data suggest? \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-3-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## There appears to be a relationship!\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## We can run the regression\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(kisses ~ self_confidence, data = kisses)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = kisses ~ self_confidence, data = kisses)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-466.55  -91.91   -0.48   80.90  437.60 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       99.413     35.181   2.826   0.0052 ** \nself_confidence   74.779      6.691  11.177   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 142.7 on 198 degrees of freedom\nMultiple R-squared:  0.3868,\tAdjusted R-squared:  0.3838 \nF-statistic: 124.9 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nüéâ We have an answer to our research question!\n\nOr, wait, do we?\n\n---\n\n## What does plot suggest? \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## No more relationship within the different subgroups\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-7-1.png){width=100%}\n:::\n:::\n\n\n\n--- \n\n## In fact, this is how the data was generated\n\nRelationship status increases both kisses and self confidence. They are otherwise independent.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234) # For reproducibility\n\nsample_size <- 200\n\nkisses <- tibble(\n  id = 1:sample_size,\n  relationship = sample(0:1, sample_size, replace = TRUE),\n  # we use rtruncnorm() to add some random variation\n  # a and b arguments in rtruncnorm() mark the limits of the sampling\n  kisses = 300 + 300*relationship + rtruncnorm(sample_size, mean = 0, sd = 100, a = - 300),\n  self_confidence = 4 + 2*relationship + rtruncnorm(sample_size, mean = 0, sd = 1, a = - 4, b = 2)\n) |> \n  # pick nicer values for the relationship variable\n  mutate(relationship = recode_factor(relationship, `0` = \"single\", \n                                      `1` = \"in couple\"))\n```\n:::\n\n\n\n---\n\n## Relationship status is a \"Confounder\"\n\n- To account for confounders, in a regression analysis, we can add it as another predictor to our regression model. \n\n- People also call this \"controlling for a variable\"\n\n- This is like looking into the two groups (relationship vs. single) separately.\n\n---\n\n## Relationship status is a \"Confounder\"\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(kisses ~ self_confidence + relationship, data = kisses)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = kisses ~ self_confidence + relationship, data = kisses)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-290.439  -63.130    6.422   57.785  297.704 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            311.300     27.773  11.209   <2e-16 ***\nself_confidence         -1.261      6.786  -0.186    0.853    \nrelationshipin couple  311.225     20.566  15.133   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 97.25 on 197 degrees of freedom\nMultiple R-squared:  0.7165,\tAdjusted R-squared:  0.7136 \nF-statistic: 248.9 on 2 and 197 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n- Our research question was about a causal effect of self confidence, so we only interpret the `self_confidence` estimate. Note how the effect is tiny now, and statistically not significantly different from 0. \n\n---\n\n::: {.callout-note}\nAs a rule, never interpret the estimates of control variables in regressions. Focus on the one variable that your research question was on. \n:::\n\n---\n\n## Confounders\n\nIn sum we want to control for confounders in our analyses\n\n# Colliders\n\n---\n\n## Are shabby-looking restaurants serving nicer food than fancy ones?\n\n\n\n::: {.cell}\n\n:::\n\n\n\nImagine that's your research question. \n\nYou know that restaurants in your town are rated based on two criteria: food quality and atmosphere.\n\nYou check out all the greatest restaurants in town (at least 4 out of 5 stars) and this is what you observe: \n\n---\n\n## Data of 4- and 5-star restaurants\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-11-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## There appears to be a relationship!\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## But remember, we are only looking at the best restaurants\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=100%}\n:::\n\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-13-2.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## Yet, our research questions was about restaurants in general \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-14-1.png){width=100%}\n:::\n\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-14-2.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## When looking at all restaurants, there is no relationship\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-slides_files/figure-revealjs/unnamed-chunk-15-1.png){width=100%}\n:::\n:::\n\n\n\n---\n\n## In fact, this is how the data was generated\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size <- 1000\n\n# Generate independent food quality and atmosphere scores (1 to 5)\nrestaurants <- tibble(\n  id = 1:sample_size,\n  food_quality = sample(1:5, sample_size, replace = TRUE),\n  atmosphere = sample(1:5, sample_size, replace = TRUE),\n  # Overall rating depends on both factors (rounded to nearest integer)\n  rating = round((food_quality + atmosphere) / 2 )\n) |> \n  # add an additional variable of whether 4 or more stars\n  mutate(stars = ifelse(rating >= 4, \"4 or 5\", \"less than 4\"))\n```\n:::\n\n\n\n---\n\n## Restaurant stars is a \"Collider variable\"\n\nIf we look at **only the best** restaurants, our model yields a **statistically significant negative association**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_restaurants <- restaurants |> \n  filter(stars == \"4 or 5\")\n\nmodel <- lm(atmosphere ~ food_quality, data = best_restaurants)\n\ntidy(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)     6.06     0.183       33.2 2.16e-118\n2 food_quality   -0.517    0.0439     -11.8 8.30e- 28\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nNote that this similar to adding stars as a control variable (for both subgroups, selecting them independently yields a negative relationship)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(atmosphere ~ food_quality + stars, data = restaurants)\n\ntidy(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 √ó 5\n  term             estimate std.error statistic   p.value\n  <chr>               <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)         5.94     0.120       49.4 2.71e-270\n2 food_quality       -0.488    0.0271     -18.0 7.81e- 63\n3 starsless than 4   -2.47     0.0781     -31.6 1.91e-152\n```\n\n\n:::\n:::\n\n\n\n---\n\n## Restaurant stars is a \"Collider variable\"\n\nIf we look at **all** restaurants, our model will yield **no statistically significant association** (in line with the true data generating process). \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(atmosphere ~ food_quality, data = restaurants)\n\ntidy(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   2.98       0.107    28.0    1.92e-127\n2 food_quality  0.00285    0.0315    0.0904 9.28e-  1\n```\n\n\n:::\n:::\n\n\n\n---\n\n## Colliders\n\nWe do not want to control/condition on colliders in our analyses. \n\n---\n\n::: {.callout-note}\nNote that the restaurant case we have discussed is a special case of collider bias, which is called a **selection bias**. The idea behind a name is that you **select** a non-random sample of a population that you want to make claims about.\n:::\n\n---\n\nThat's it for today :)\n\n\n\n\n",
    "supporting": [
      "08-slides_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}