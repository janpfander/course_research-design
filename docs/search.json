[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Jan Pfänder |  Institut Jean Nicod, ENS-PSL |  jan.pfander@psl.eu |  Bluesky",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "",
    "text": "Jan Pfänder |  Institut Jean Nicod, ENS-PSL |  jan.pfander@psl.eu |  Bluesky",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description-and-objectives",
    "href": "syllabus.html#course-description-and-objectives",
    "title": "Syllabus",
    "section": "Course Description and Objectives",
    "text": "Course Description and Objectives\nIn science, but also in politics, in court, in airport-bestsellers, or at your lunch table, claims are made based on data and science. In this course, you will learn to think critically about data, and whether it actually supports the claim it is meant to. A less fancy title for this class would have been “Introduction to Research Design”.\nThis class is hands-on, meaning that you will learn how to design a study, organize a project, analyze data, present results and read scientific literature.\nThe class is structured into four main blocks.\n\nData Analysis - You will develop the competences to understand and analyze data\nStatistics - You will learn basic statistical concepts.\nCausal Inference - You will get an understanding of how different research designs do or do not permit causal claims.\nScience - You will get an idea of how science works, including how evidence accumulates and how scientific publishing works",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nAn up-to date schedule can be found on the course website. This is also the place where all course content, including slides, assignments and additional resources will be posted.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#language",
    "href": "syllabus.html#language",
    "title": "Syllabus",
    "section": "Language",
    "text": "Language\nAlthough the class will be held in English, you can ask questions in French at any time.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#participation",
    "href": "syllabus.html#participation",
    "title": "Syllabus",
    "section": "Participation",
    "text": "Participation\nThis class will be highly interactive. You are strongly encouraged to participate in lectures and interrupt at any time. This means asking deep and challenging questions, but also asking simple clarification questions like “I’m just not getting this, please explain it in some new way” or “I’m lost, can you remind me why we’re talking about this?”. Don’t blame yourself if you don’t get something. Teachers are also just humans–for me to help you, I need you to communicate with me.\nA lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#requirements",
    "href": "syllabus.html#requirements",
    "title": "Syllabus",
    "section": "Requirements",
    "text": "Requirements\nYou are expected to bring a laptop, tablet, or Chromebook (or whatever else you use and can have R and RStudio run on it) to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\nIf this presents a problem for you, please let me know via email or in person and we will figure something out.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#evaluation",
    "href": "syllabus.html#evaluation",
    "title": "Syllabus",
    "section": "Evaluation",
    "text": "Evaluation\nThis class is not graded–you either pass or fail. This is meant to alleviate pressure for high performance. However, you are expected to prepare for class by completing assigned readings and problem sets, attend all lectures, and meaningfully contribute to in-class exercises and discussion.\n\nAssignments\nTo pass this class, you will need to have completed all assignments. These include\n\nWeekly problem sets\nA pre-registration for a study\nA group presentation on a scientific paper\n\nIt is ok if you get things wrong, but for you to pass, I need to see that you at least tried.\n\n\nAttendance\nSince being present and doing your homework is the only requirement to pass, I will very strictly apply the Règlement de la scolarité et des études:\n\n“Si une étudiante ou un étudiant est signalé absent trois fois dans une UE de 24h ou plus, au cours d’un même semestre, sans justification valable, il ou elle obtient la note finale de zéro à cette UE.”\n\nI will check presence during every session and report each absence. You can miss two classes, but starting with the third missed class, you will need to justify each absence. All justifications are to be presented to the secretary and will be validated by them",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#credit",
    "href": "syllabus.html#credit",
    "title": "Syllabus",
    "section": "Credit",
    "text": "Credit\nThe content of this course is inspired by and draws on material from openly and freely available courses from brilliant teachers, including\n\nAndrew Heiss’ “Program Evaluation for Public Service”\nLouis Sirugue’s “Introduction to Econometrics & Programming”\nMine Çetinkaya-Rundel’s “STA 199: Introduction to Data Science and Statistical Thinking” and “STA 101 - Data Analysis and Statistical Inference”\nMegan Hall’s workshop on “Keeping it tidy”\nSam Shanny-Csik’s Data Visualization & Communication",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/10-slides.html#overview",
    "href": "slides/10-slides.html#overview",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Overview",
    "text": "Overview\n\n\n\nOn the whole science works\nReplication Crisis\nReproducibility\nReplicability\n\nP-Hacking\nFile-drawer effect\n\n\n\n\nHow to do better science?\n\nReproducible manuscripts\nPreregistrations"
  },
  {
    "objectID": "slides/10-slides.html#section",
    "href": "slides/10-slides.html#section",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "If I have seen further than others,\nit is by standing upon the shoulders\nof giants.\n— Isaac Newton"
  },
  {
    "objectID": "slides/10-slides.html#science-is-cumulative",
    "href": "slides/10-slides.html#science-is-cumulative",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Science is cumulative",
    "text": "Science is cumulative\n\n\nResearchers build on each others findings\n\n\n\nThis way, science is self correcting: If something doesn’t doesn’t turn out to be right, (at some point) other researchers will notice"
  },
  {
    "objectID": "slides/10-slides.html#a-typical-textbook-pyramid-of-evidence",
    "href": "slides/10-slides.html#a-typical-textbook-pyramid-of-evidence",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "(A typical textbook) pyramid of evidence",
    "text": "(A typical textbook) pyramid of evidence"
  },
  {
    "objectID": "slides/10-slides.html#reproducibility",
    "href": "slides/10-slides.html#reproducibility",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nWhen scientists can obtain the results of other scientists…\n\n… using the same data and following the same methods\n\n Would this ever not be the case?\n\n\n Unfortunately, yes!"
  },
  {
    "objectID": "slides/10-slides.html#section-1",
    "href": "slides/10-slides.html#section-1",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "Oza, A. (2023). Reproducibility trial: 246 biologists get different results from same data sets. Nature."
  },
  {
    "objectID": "slides/10-slides.html#replicability",
    "href": "slides/10-slides.html#replicability",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Replicability",
    "text": "Replicability\n\nWhen scientists can obtain the results of other scientists…\n\n… collecting new data, following the same methods"
  },
  {
    "objectID": "slides/10-slides.html#section-2",
    "href": "slides/10-slides.html#section-2",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "OPEN SCIENCE COLLABORATION. (2015). Estimating the reproducibility of psychological science. Science.\n\n\n\n\n\n\n\nConfusing!\n\n\nThe paper uses the word “reproducibility”, but in fact they replicated studies.\nThat is, they collected new data."
  },
  {
    "objectID": "slides/10-slides.html#what-has-gone-wrong-is-science-a-big-fraud",
    "href": "slides/10-slides.html#what-has-gone-wrong-is-science-a-big-fraud",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "What has gone wrong? Is science a big fraud?",
    "text": "What has gone wrong? Is science a big fraud?\n\nNo! Fraud in science does happen, but it’s rare.\n\nThere are two main issues:\n\nP-hacking\nFile-drawer effect"
  },
  {
    "objectID": "slides/10-slides.html#your-turn-p-hacking",
    "href": "slides/10-slides.html#your-turn-p-hacking",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Your turn: P-hacking",
    "text": "Your turn: P-hacking\nImagine you had run a fictional experiment (download the data here:  imaginary_beatle_experiment.csv or from this week’s content page) to test whether listening to certain music affects people’s behavior or how they perceive themselves. In this fictional experiment, participants were randomly assigned to either:\n\nTreatment group: Listened to “When I’m Sixty-Four” by The Beatles.\nControl group: Listened to an instrumental jazz piece of similar length.\n\nAfterwards, participants completed a battery of self-report measures and cognitive tasks.\nExplore the dataset and look for any evidence that listening to “When I’m 64” had a significant effect on participants (tip, run regressions, you can even add covariates, look only at a subgroup of the data etc.)\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/10-slides.html#solution",
    "href": "slides/10-slides.html#solution",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Solution",
    "text": "Solution\n\n# You could have tried for example to run this\nmodel &lt;- lm(actual_age ~ condition, data = imaginary_beatle_experiment)\n\nsummary(model)\n\n\nCall:\nlm(formula = actual_age ~ condition, data = imaginary_beatle_experiment)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.675 -3.043  0.325  2.325  9.957 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       25.6750     0.4665   55.04   &lt;2e-16 ***\nconditionControl  -1.6321     0.6829   -2.39   0.0181 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.172 on 148 degrees of freedom\nMultiple R-squared:  0.03717,   Adjusted R-squared:  0.03066 \nF-statistic: 5.713 on 1 and 148 DF,  p-value: 0.0181\n\n\nA significant difference! But completely implausible."
  },
  {
    "objectID": "slides/10-slides.html#solution-1",
    "href": "slides/10-slides.html#solution-1",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Solution",
    "text": "Solution\nThis is how the data was generated:\n\n# a function to simulate the data\nsimulate_phacking_data &lt;- function(n = 150) {\n  tibble(\n    id = 1:n,\n    # simulate the experimental manipulation\n    condition = sample(c(\"Beatles\", \"Control\"), n, replace = TRUE),\n    # all variables below are generate completely independently of the manipulation\n    actual_age = round(rnorm(n, mean = 25, sd = 4)),\n    gender = sample(c(\"Male\", \"Female\", \"Other\"), n, replace = TRUE, prob = c(0.45, 0.45, 0.1)),\n    political_orientation = sample(1:7, n, replace = TRUE),\n    height_cm = round(rnorm(n, mean = 170, sd = 10)),\n    reaction_time_ms = round(rlnorm(n, meanlog = 6.5, sdlog = 0.3)),\n    mood_score = round(rnorm(n, mean = 5, sd = 1.5), 1),\n    memory_score = round(rnorm(n, mean = 10, sd = 3)),\n    confidence = sample(1:7, n, replace = TRUE),\n    perceived_age = actual_age + rnorm(n, mean = 0, sd = 2),\n    stress_level = round(rnorm(n, mean = 4, sd = 1.5), 1),\n    sleep_hours = round(rnorm(n, mean = 7, sd = 1.2), 1),\n    caffeine_intake_mg = round(rnorm(n, mean = 200, sd = 75)),\n    exercise_minutes = round(rnorm(n, mean = 30, sd = 15)),\n    social_media_minutes = round(rnorm(n, mean = 90, sd = 40)),\n    screen_time_hours = round(rnorm(n, mean = 5, sd = 2), 1)\n  )\n}\n\nNo true effect on any other variable."
  },
  {
    "objectID": "slides/10-slides.html#solution-2",
    "href": "slides/10-slides.html#solution-2",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Solution",
    "text": "Solution\nAnd this is how the sample was picked:\n\n# simulate until a data set returns a treatment \n# effect on actual age of participants\n\nset.seed(13487)\n\n# Simulate multiple datasets and \"p-hack\" until p &lt; .05\nfind_false_positive &lt;- function(n = 10, max_tries = 10000) {\n  for (i in 1:max_tries) {\n    data &lt;- simulate_phacking_data(n)\n    model &lt;- lm(actual_age ~ condition, data = data)\n    p_val &lt;- tidy(model) |&gt; \n      filter(term == \"conditionControl\") |&gt; \n      pull(p.value)\n    \n    if (p_val &lt; 0.05) {\n      cat(\"🔎 Found significant p =\", round(p_val, 4), \"on try\", i, \"\\n\")\n      return(data)\n    }\n  }\n  stop(\"❌ No significant result found within max_tries.\")\n}\n\n# Example: Find a \"lucky\" false positive dataset\nimaginary_beatley_experiment &lt;- find_false_positive(n = 150)\n\nRe-sample until–by chance–a significant result pops up."
  },
  {
    "objectID": "slides/10-slides.html#p-hacking",
    "href": "slides/10-slides.html#p-hacking",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "P-Hacking",
    "text": "P-Hacking\n\nRemember a p-value:\nIt’s the probability of observing an estimate at least as extreme as the one in our sample, in a world where there is no true effect (the Null world).\n\nRemember statistical significance:\nIf p-value &lt; 5% (arbitrary threshold)\nWe accept a 5% chance that our results could have occurred in a Null world."
  },
  {
    "objectID": "slides/10-slides.html#p-hacking-1",
    "href": "slides/10-slides.html#p-hacking-1",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "P-Hacking",
    "text": "P-Hacking\nThat means:\nIn a world where there is no effect, in 5% of (or 1 out of 20) samples, we find a false positive.\n\nIf we look at a different outcome variable, that’s basically taking a new sample.\n\n\nIf we measure 20 outcomes, in a world where there is no effect, we would expect 1 to yield a statistically significant effect."
  },
  {
    "objectID": "slides/10-slides.html#section-3",
    "href": "slides/10-slides.html#section-3",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "How did they achieve it?\n\n\n\nJust like you in the exercise: p-hacking\nThey collected information about a number of characteristics of their study subjects, and then controlled for one that happened to give them the result they were looking at. (The age of the subject’s father).\nThey also continued the experiment until they got a significant result, rather than predetermining the sample size."
  },
  {
    "objectID": "slides/10-slides.html#file-drawer-effect",
    "href": "slides/10-slides.html#file-drawer-effect",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "File-drawer effect",
    "text": "File-drawer effect\n\nIllustration from Calling Bullshit"
  },
  {
    "objectID": "slides/10-slides.html#section-4",
    "href": "slides/10-slides.html#section-4",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "Researchers are incentives to publish positive, statistically significant results.\nBut this can result faulty images of the evidence."
  },
  {
    "objectID": "slides/10-slides.html#how-bad-is-the-issue",
    "href": "slides/10-slides.html#how-bad-is-the-issue",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "How bad is the issue?",
    "text": "How bad is the issue?\n\n\n\n\nIoannidis, J. P. A. (2005). Why Most Published Research Findings Are False. PLoS Medicine."
  },
  {
    "objectID": "slides/10-slides.html#lets-take-a-step-back",
    "href": "slides/10-slides.html#lets-take-a-step-back",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Let’s take a step back",
    "text": "Let’s take a step back\n\nAssume that we have a “total Null world” (no true effect for no study in science)\n\n\n\n\n\n\n\n\n\n\n\nH₀ True (100%)\n\n\n\n\nSignificant Finding (Positive result) α = 5%, 1−β = 80%\nFalse Positive 5%\n\n\nNon-Significant Finding (Negative result) 1−α = 95%, β = 20%\nTrue Negative 95%"
  },
  {
    "objectID": "slides/10-slides.html#lets-take-a-step-back-1",
    "href": "slides/10-slides.html#lets-take-a-step-back-1",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Let’s take a step back",
    "text": "Let’s take a step back\n\nNow assume we live in a “total True world” (only true effects in all of science)\n\n\n\n\n\n\n\n\n\n\n\n\nH₀ True (0%)\nH₁ True (100%)\n\n\n\n\nSignificant Finding (Positive result) α = 5%, 1−β = 80%\n0%\nTrue Positive 80%\n\n\nNon-Significant Finding (Negative result) 1−α = 95%, β = 20%\n0%\nFalse Negative 20%"
  },
  {
    "objectID": "slides/10-slides.html#now-lets-assume-a-world-where-half-of-science-tests-true-effects",
    "href": "slides/10-slides.html#now-lets-assume-a-world-where-half-of-science-tests-true-effects",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Now let’s assume a world where half of science tests true effects",
    "text": "Now let’s assume a world where half of science tests true effects\n\n\nFor illustration, let’s assume science consists of n = 200 studies\n\n\n\n\n\n\n\n\n\n\n\nH₀ True (50%)\nH₁ True (50%)\n\n\n\n\nSignificant Finding (Positive result) α = 5%, 1−β = 80%\nFalse Positive 5% × 50% = 2.5% (5 studies)\nTrue Positive 80% × 50% = 40% (80 studies)\n\n\nNon-Significant Finding (Negative result) 1−α = 95%, β = 20%\nTrue Negative 95% × 50% = 47.5% (95 studies)\nFalse Negative 20% × 50% = 10% (20 studies)"
  },
  {
    "objectID": "slides/10-slides.html#and-now-lets-assume-a-world-where-only-5-of-science-tests-true-effects",
    "href": "slides/10-slides.html#and-now-lets-assume-a-world-where-only-5-of-science-tests-true-effects",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "And now let’s assume a world where only 5% of science tests true effects",
    "text": "And now let’s assume a world where only 5% of science tests true effects\n\n\nIn other words, we assume scientists generally test implausible hypotheses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\) True (95%)\n\\(H_1\\) True (5%)\n\n\n\n\nSignificant Finding (Positive result) \\(\\alpha = 5\\%, 1-\\beta = 80\\%\\)\nFalse Positive 5% × 95% = 4.75% (9.5 studies)\nTrue Positive 80% × 5% = 4% (8 studies)\n\n\nNon-Significant Finding (Negative result) \\(1-\\alpha = 95\\%, \\beta = 20\\%\\)\nTrue Negative 95% × 95% = 90.25% (180.5 studies)\nFalse Negative 20% × 5% = 1% (2 studies)"
  },
  {
    "objectID": "slides/10-slides.html#we-never-know-the-ratio-of-true-vs.-null-effects-in-science",
    "href": "slides/10-slides.html#we-never-know-the-ratio-of-true-vs.-null-effects-in-science",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "We never know the ratio of true vs. null effects in science…",
    "text": "We never know the ratio of true vs. null effects in science…\n\n\n…but what we would like to know is:\n\nGiven that we observe a statistically significant effect, what’s the probability that it is true?"
  },
  {
    "objectID": "slides/10-slides.html#positive-predictive-value-ppv",
    "href": "slides/10-slides.html#positive-predictive-value-ppv",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Positive Predictive Value (PPV)",
    "text": "Positive Predictive Value (PPV)\n\n\\[\n\\text{PPV} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} = \\frac{8}{8 + 9.5} = \\frac{8}{17.5} \\approx 45.7\\%\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\) True (95%)\n\\(H_1\\) True (5%)\n\n\n\n\nSignificant Finding (Positive result) \\(\\alpha = 5\\%, 1-\\beta = 80\\%\\)\nFalse Positive 5% × 95% = 4.75% (9.5 studies)\nTrue Positive 80% × 5% = 4% (8 studies)\n\n\nNon-Significant Finding (Negative result) \\(1-\\alpha = 95\\%, \\beta = 20\\%\\)\nTrue Negative 95% × 95% = 90.25% (180.5 studies)\nFalse Negative 20% × 5% = 1% (2 studies)"
  },
  {
    "objectID": "slides/10-slides.html#us-food-and-drug-administration-fda",
    "href": "slides/10-slides.html#us-food-and-drug-administration-fda",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "US Food and Drug Administration (FDA)",
    "text": "US Food and Drug Administration (FDA)\n\n\nIn the United States clinical trials (experiments using human subjects to test outcomes of medical treatments) are required by law to register this trial with the FDA\nThis involves explaining what the trial is designed to test, how the trial will be conducted, and how the outcomes will be measured.\nOnce the trial is completed, the researchers are also required to report the results to the FDA.\nHowever, they are not required to publish the results in a scientific journal."
  },
  {
    "objectID": "slides/10-slides.html#two-main-solutions",
    "href": "slides/10-slides.html#two-main-solutions",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Two main solutions",
    "text": "Two main solutions\n\nAt the least, make data and code public\n\n(at best, write reproducible manuscripts)"
  },
  {
    "objectID": "slides/10-slides.html#two-main-solutions-1",
    "href": "slides/10-slides.html#two-main-solutions-1",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Two main solutions",
    "text": "Two main solutions\n\nAt the least, make data and code public\n\n(at best, write reproducible manuscripts)\n\n\nPreregister studies"
  },
  {
    "objectID": "slides/10-slides.html#pre-registration-in-a-nutshell",
    "href": "slides/10-slides.html#pre-registration-in-a-nutshell",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Pre-registration in a nutshell",
    "text": "Pre-registration in a nutshell\nA time-stamped document describing the details of the planned study\n\nBenefits:\n\nmakes research process more transparent\nallows to clearly distinguish a priori and post-hoc decisions\nmakes it harder to fool (the researchers themselve and others)"
  },
  {
    "objectID": "slides/10-slides.html#how-exactly-does-it-work",
    "href": "slides/10-slides.html#how-exactly-does-it-work",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "How exactly does it work?",
    "text": "How exactly does it work?\n\n    \nThere are different options but the most common one is to use the Open Science Framework (OSF)\n\nlarge number of templates\nall participating authors get informed and can cancel within 48h\nprereg can be kept privat for a while (if needed to protect the project)"
  },
  {
    "objectID": "slides/10-slides.html#what-goes-into-a-preregistration",
    "href": "slides/10-slides.html#what-goes-into-a-preregistration",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "What goes into a preregistration?",
    "text": "What goes into a preregistration?\nAnything that might be considered a researcher degree of freedom\n\nfixed decisions (e.g. the research design, outcome measures)\ndecision rules (e.g. “if we cannot collect 100 participants until June 5 2025, we will stop the data collection that very day and…”)\nstatistical models (ideally analysis scripts, including data-dependent decision rules)\nsample size and power analysis"
  },
  {
    "objectID": "slides/10-slides.html#two-main-solutions-2",
    "href": "slides/10-slides.html#two-main-solutions-2",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Two main solutions",
    "text": "Two main solutions\n\nAt the least, make data and code public\n\n(at best, write reproducible manuscripts)\n\nPreregister studies\n\n\n\nChange the scientific publishing system"
  },
  {
    "objectID": "slides/10-slides.html#registered-reports",
    "href": "slides/10-slides.html#registered-reports",
    "title": "Scientific Publishing and the Replication Crisis",
    "section": "Registered reports",
    "text": "Registered reports\n\n\nIllustration from the OSF\n\njournals commit to publishing results, no matter whether significant or not\nrelevance of a study is determined based on the research question, not the result"
  },
  {
    "objectID": "slides/08-slides.html#overview",
    "href": "slides/08-slides.html#overview",
    "title": "Colliders and Confounders",
    "section": "Overview",
    "text": "Overview\n\n\n\nWhat is Causality\nCorrelation is not causality\nConfounders\nColliders"
  },
  {
    "objectID": "slides/08-slides.html#we-all-have-an-idea-of-what-causality-means.",
    "href": "slides/08-slides.html#we-all-have-an-idea-of-what-causality-means.",
    "title": "Colliders and Confounders",
    "section": "We all have an idea of what “causality” means.",
    "text": "We all have an idea of what “causality” means.\n\nWhenever we ask “why” question, we are asking for a cause."
  },
  {
    "objectID": "slides/08-slides.html#a-simple-definition",
    "href": "slides/08-slides.html#a-simple-definition",
    "title": "Colliders and Confounders",
    "section": "A simple definition",
    "text": "A simple definition\n\nWe could say that X causes Y if…\nwe were we to intervene and change the value of X without changing anything else…\nand then Y would change as a result."
  },
  {
    "objectID": "slides/08-slides.html#associations-vs.-causality",
    "href": "slides/08-slides.html#associations-vs.-causality",
    "title": "Colliders and Confounders",
    "section": "Associations vs. Causality",
    "text": "Associations vs. Causality\n\n\nHow do we figure out associations?\n\nLooking at data, using math and statistics\n\nHow do we figure out causation? \n\nPhilosophy (and good research design). No math or stats."
  },
  {
    "objectID": "slides/08-slides.html#does-self-confidence-make-you-being-kissed-more-often",
    "href": "slides/08-slides.html#does-self-confidence-make-you-being-kissed-more-often",
    "title": "Colliders and Confounders",
    "section": "Does self-confidence make you being kissed more often?",
    "text": "Does self-confidence make you being kissed more often?\nImagine you are a researcher and have this (slightly stupid) research question."
  },
  {
    "objectID": "slides/08-slides.html#what-does-this-made-up-data-suggest",
    "href": "slides/08-slides.html#what-does-this-made-up-data-suggest",
    "title": "Colliders and Confounders",
    "section": "What does this (made up!) data suggest?",
    "text": "What does this (made up!) data suggest?"
  },
  {
    "objectID": "slides/08-slides.html#there-appears-to-be-a-relationship",
    "href": "slides/08-slides.html#there-appears-to-be-a-relationship",
    "title": "Colliders and Confounders",
    "section": "There appears to be a relationship!",
    "text": "There appears to be a relationship!"
  },
  {
    "objectID": "slides/08-slides.html#we-can-run-the-regression",
    "href": "slides/08-slides.html#we-can-run-the-regression",
    "title": "Colliders and Confounders",
    "section": "We can run the regression",
    "text": "We can run the regression\n\nmodel &lt;- lm(kisses ~ self_confidence, data = kisses)\n\nsummary(model)\n\n\nCall:\nlm(formula = kisses ~ self_confidence, data = kisses)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-466.55  -91.91   -0.48   80.90  437.60 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       99.413     35.181   2.826   0.0052 ** \nself_confidence   74.779      6.691  11.177   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 142.7 on 198 degrees of freedom\nMultiple R-squared:  0.3868,    Adjusted R-squared:  0.3838 \nF-statistic: 124.9 on 1 and 198 DF,  p-value: &lt; 2.2e-16\n\n\n🎉 We have an answer to our research question!\nOr, wait, do we?"
  },
  {
    "objectID": "slides/08-slides.html#what-does-plot-suggest",
    "href": "slides/08-slides.html#what-does-plot-suggest",
    "title": "Colliders and Confounders",
    "section": "What does plot suggest?",
    "text": "What does plot suggest?"
  },
  {
    "objectID": "slides/08-slides.html#no-more-relationship-within-the-different-subgroups",
    "href": "slides/08-slides.html#no-more-relationship-within-the-different-subgroups",
    "title": "Colliders and Confounders",
    "section": "No more relationship within the different subgroups",
    "text": "No more relationship within the different subgroups"
  },
  {
    "objectID": "slides/08-slides.html#in-fact-this-is-how-the-data-was-generated",
    "href": "slides/08-slides.html#in-fact-this-is-how-the-data-was-generated",
    "title": "Colliders and Confounders",
    "section": "In fact, this is how the data was generated",
    "text": "In fact, this is how the data was generated\nRelationship status increases both kisses and self confidence. They are otherwise independent.\n\nset.seed(1234) # For reproducibility\n\nsample_size &lt;- 200\n\nkisses &lt;- tibble(\n  id = 1:sample_size,\n  relationship = sample(0:1, sample_size, replace = TRUE),\n  # we use rtruncnorm() to add some random variation\n  # a and b arguments in rtruncnorm() mark the limits of the sampling\n  kisses = 300 + 300*relationship + rtruncnorm(sample_size, mean = 0, sd = 100, a = - 300),\n  self_confidence = 4 + 2*relationship + rtruncnorm(sample_size, mean = 0, sd = 1, a = - 4, b = 2)\n) |&gt; \n  # pick nicer values for the relationship variable\n  mutate(relationship = recode_factor(relationship, `0` = \"single\", \n                                      `1` = \"in couple\"))"
  },
  {
    "objectID": "slides/08-slides.html#relationship-status-is-a-confounder",
    "href": "slides/08-slides.html#relationship-status-is-a-confounder",
    "title": "Colliders and Confounders",
    "section": "Relationship status is a “Confounder”",
    "text": "Relationship status is a “Confounder”\n\nTo account for confounders, in a regression analysis, we can add it as another predictor to our regression model.\nPeople also call this “controlling for a variable”\nThis is like looking into the two groups (relationship vs. single) separately."
  },
  {
    "objectID": "slides/08-slides.html#relationship-status-is-a-confounder-1",
    "href": "slides/08-slides.html#relationship-status-is-a-confounder-1",
    "title": "Colliders and Confounders",
    "section": "Relationship status is a “Confounder”",
    "text": "Relationship status is a “Confounder”\n\nmodel &lt;- lm(kisses ~ self_confidence + relationship, data = kisses)\n\nsummary(model)\n\n\nCall:\nlm(formula = kisses ~ self_confidence + relationship, data = kisses)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-290.439  -63.130    6.422   57.785  297.704 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            311.300     27.773  11.209   &lt;2e-16 ***\nself_confidence         -1.261      6.786  -0.186    0.853    \nrelationshipin couple  311.225     20.566  15.133   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 97.25 on 197 degrees of freedom\nMultiple R-squared:  0.7165,    Adjusted R-squared:  0.7136 \nF-statistic: 248.9 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nOur research question was about a causal effect of self confidence, so we only interpret the self_confidence estimate. Note how the effect is tiny now, and statistically not significantly different from 0."
  },
  {
    "objectID": "slides/08-slides.html#confounders-1",
    "href": "slides/08-slides.html#confounders-1",
    "title": "Colliders and Confounders",
    "section": "Confounders",
    "text": "Confounders\nIn sum we want to control for confounders in our analyses"
  },
  {
    "objectID": "slides/08-slides.html#are-shabby-looking-restaurants-serving-nicer-food-than-fancy-ones",
    "href": "slides/08-slides.html#are-shabby-looking-restaurants-serving-nicer-food-than-fancy-ones",
    "title": "Colliders and Confounders",
    "section": "Are shabby-looking restaurants serving nicer food than fancy ones?",
    "text": "Are shabby-looking restaurants serving nicer food than fancy ones?\nImagine that’s your research question.\nYou know that restaurants in your town are rated based on two criteria: food quality and atmosphere.\nYou check out all the greatest restaurants in town (at least 4 out of 5 stars) and this is what you observe:"
  },
  {
    "objectID": "slides/08-slides.html#data-of-4--and-5-star-restaurants",
    "href": "slides/08-slides.html#data-of-4--and-5-star-restaurants",
    "title": "Colliders and Confounders",
    "section": "Data of 4- and 5-star restaurants",
    "text": "Data of 4- and 5-star restaurants"
  },
  {
    "objectID": "slides/08-slides.html#there-appears-to-be-a-relationship-1",
    "href": "slides/08-slides.html#there-appears-to-be-a-relationship-1",
    "title": "Colliders and Confounders",
    "section": "There appears to be a relationship!",
    "text": "There appears to be a relationship!"
  },
  {
    "objectID": "slides/08-slides.html#but-remember-we-are-only-looking-at-the-best-restaurants",
    "href": "slides/08-slides.html#but-remember-we-are-only-looking-at-the-best-restaurants",
    "title": "Colliders and Confounders",
    "section": "But remember, we are only looking at the best restaurants",
    "text": "But remember, we are only looking at the best restaurants"
  },
  {
    "objectID": "slides/08-slides.html#yet-our-research-questions-was-about-restaurants-in-general",
    "href": "slides/08-slides.html#yet-our-research-questions-was-about-restaurants-in-general",
    "title": "Colliders and Confounders",
    "section": "Yet, our research questions was about restaurants in general",
    "text": "Yet, our research questions was about restaurants in general"
  },
  {
    "objectID": "slides/08-slides.html#when-looking-at-all-restaurants-there-is-no-relationship",
    "href": "slides/08-slides.html#when-looking-at-all-restaurants-there-is-no-relationship",
    "title": "Colliders and Confounders",
    "section": "When looking at all restaurants, there is no relationship",
    "text": "When looking at all restaurants, there is no relationship"
  },
  {
    "objectID": "slides/08-slides.html#in-fact-this-is-how-the-data-was-generated-1",
    "href": "slides/08-slides.html#in-fact-this-is-how-the-data-was-generated-1",
    "title": "Colliders and Confounders",
    "section": "In fact, this is how the data was generated",
    "text": "In fact, this is how the data was generated\n\nsample_size &lt;- 1000\n\n# Generate independent food quality and atmosphere scores (1 to 5)\nrestaurants &lt;- tibble(\n  id = 1:sample_size,\n  food_quality = sample(1:5, sample_size, replace = TRUE),\n  atmosphere = sample(1:5, sample_size, replace = TRUE),\n  # Overall rating depends on both factors (rounded to nearest integer)\n  rating = round((food_quality + atmosphere) / 2 )\n) |&gt; \n  # add an additional variable of whether 4 or more stars\n  mutate(stars = ifelse(rating &gt;= 4, \"4 or 5\", \"less than 4\"))"
  },
  {
    "objectID": "slides/08-slides.html#restaurant-stars-is-a-collider-variable",
    "href": "slides/08-slides.html#restaurant-stars-is-a-collider-variable",
    "title": "Colliders and Confounders",
    "section": "Restaurant stars is a “Collider variable”",
    "text": "Restaurant stars is a “Collider variable”\nIf we look at only the best restaurants, our model yields a statistically significant negative association.\n\nbest_restaurants &lt;- restaurants |&gt; \n  filter(stars == \"4 or 5\")\n\nmodel &lt;- lm(atmosphere ~ food_quality, data = best_restaurants)\n\ntidy(model)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     6.06     0.183       33.2 2.16e-118\n2 food_quality   -0.517    0.0439     -11.8 8.30e- 28\n\n\n\nNote that this similar to adding stars as a control variable (for both subgroups, selecting them independently yields a negative relationship)\n\nmodel &lt;- lm(atmosphere ~ food_quality + stars, data = restaurants)\n\ntidy(model)\n\n# A tibble: 3 × 5\n  term             estimate std.error statistic   p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         5.94     0.120       49.4 2.71e-270\n2 food_quality       -0.488    0.0271     -18.0 7.81e- 63\n3 starsless than 4   -2.47     0.0781     -31.6 1.91e-152"
  },
  {
    "objectID": "slides/08-slides.html#restaurant-stars-is-a-collider-variable-1",
    "href": "slides/08-slides.html#restaurant-stars-is-a-collider-variable-1",
    "title": "Colliders and Confounders",
    "section": "Restaurant stars is a “Collider variable”",
    "text": "Restaurant stars is a “Collider variable”\nIf we look at all restaurants, our model will yield no statistically significant association (in line with the true data generating process).\n\nmodel &lt;- lm(atmosphere ~ food_quality, data = restaurants)\n\ntidy(model)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   2.98       0.107    28.0    1.92e-127\n2 food_quality  0.00285    0.0315    0.0904 9.28e-  1"
  },
  {
    "objectID": "slides/08-slides.html#colliders-1",
    "href": "slides/08-slides.html#colliders-1",
    "title": "Colliders and Confounders",
    "section": "Colliders",
    "text": "Colliders\nWe do not want to control/condition on colliders in our analyses."
  },
  {
    "objectID": "slides/06-slides.html#overview",
    "href": "slides/06-slides.html#overview",
    "title": "Statistical Power",
    "section": "Overview",
    "text": "Overview\n\n\n\nThe Central Limit Theorem revisited\nFrom Null worlds to True effect worlds\nStatistical power\nA power simulation"
  },
  {
    "objectID": "slides/06-slides.html#are-action-movies-better-than-comedies",
    "href": "slides/06-slides.html#are-action-movies-better-than-comedies",
    "title": "Statistical Power",
    "section": "Are action movies better than comedies?",
    "text": "Are action movies better than comedies?\nIn the previous session on hypothesis testing, we invented a null world:\nWe simulated a population of 1’000’000 movies with no difference.\n\nset.seed(1234) # For reproducibility\n\nimaginary_movies_null &lt;- tibble(\n  movie_id = 1:1000000,\n  rating = sample(seq(1, 10, by = 0.1), size = 1000000, replace = TRUE),\n  genre = sample(c(\"Comedy\", \"Action\"), size = 1000000, replace = TRUE)\n)"
  },
  {
    "objectID": "slides/06-slides.html#sampling-distribution",
    "href": "slides/06-slides.html#sampling-distribution",
    "title": "Statistical Power",
    "section": "Sampling distribution",
    "text": "Sampling distribution\nWe randomly drew 1,000 samples from this population and calculated the difference between action movies and comedies for each.\nWe called the distribution of the differences from the different samples the sampling distribution\nOur sample size was always the same: 20,000.\n\nn_simulations &lt;- 1000\ndifferences &lt;- c() # make an empty vector\nsample_size &lt;- 20000\n\nfor (i in 1:n_simulations) {\n  # draw a sample of 20'000 films\n  imaginary_sample &lt;- imaginary_movies |&gt; \n    sample_n(sample_size)\n  # compute rating difference in the sample\n  estimate &lt;- imaginary_sample |&gt; \n    group_by(genre) |&gt; \n    summarize(avg_rating = mean(rating)) |&gt; \n    summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %&gt;%\n    pull(diff)\n  \n  differences[i] &lt;- estimate\n}"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem-part-i",
    "href": "slides/06-slides.html#the-central-limit-theorem-part-i",
    "title": "Statistical Power",
    "section": "The Central Limit Theorem (part I)",
    "text": "The Central Limit Theorem (part I)\nThe sampling distribution approximates the shape of a normal distribution"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem-part-ii",
    "href": "slides/06-slides.html#the-central-limit-theorem-part-ii",
    "title": "Statistical Power",
    "section": "The Central Limit Theorem (part II)",
    "text": "The Central Limit Theorem (part II)\n\nThis is what the sampling distribution looks like with samples of size 10,000"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem-part-ii-1",
    "href": "slides/06-slides.html#the-central-limit-theorem-part-ii-1",
    "title": "Statistical Power",
    "section": "The Central Limit Theorem (part II)",
    "text": "The Central Limit Theorem (part II)\nAnd with samples of size 1,000"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem-part-ii-2",
    "href": "slides/06-slides.html#the-central-limit-theorem-part-ii-2",
    "title": "Statistical Power",
    "section": "The Central Limit Theorem (part II)",
    "text": "The Central Limit Theorem (part II)\nThe smaller the sample, the larger the standard deviation of the sampling distribution"
  },
  {
    "objectID": "slides/06-slides.html#how-is-this-relevant-for-hypothesis-testing",
    "href": "slides/06-slides.html#how-is-this-relevant-for-hypothesis-testing",
    "title": "Statistical Power",
    "section": "How is this relevant for hypothesis testing?",
    "text": "How is this relevant for hypothesis testing?\nImagine we find an effect of -0.2 in our sample"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem",
    "href": "slides/06-slides.html#the-central-limit-theorem",
    "title": "Statistical Power",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n(part I)\n\nThe sampling distribution approximates the shape of a normal distribution\n\n(part II)\n\nThe smaller the sample, the larger the standard deviation of the sampling distribution"
  },
  {
    "objectID": "slides/06-slides.html#two-errors",
    "href": "slides/06-slides.html#two-errors",
    "title": "Statistical Power",
    "section": "Two errors",
    "text": "Two errors\n\n\nHypothesis Testing\n\n\nStatistical Power"
  },
  {
    "objectID": "slides/06-slides.html#two-errors-1",
    "href": "slides/06-slides.html#two-errors-1",
    "title": "Statistical Power",
    "section": "Two errors",
    "text": "Two errors\n\n\n\n\n\n\n\n\n\n\n\nHypothesis Testing\nPower Analysis\n\n\n\n\nAim\nRule out that we observe something just by chance.\nEnsure that we would find an effect.\n\n\nError question\n“What are the chances that we find an effect at least this large in our sample, given that there is no effect in the population?”\n“What are the chances that we do not find a statistically significant effect in our sample, although there is a certain effect in the population?”\n\n\nTypical threshold for acceptable error\n\\(\\alpha\\) = 5 %\n\\(\\beta\\) = 20 %"
  },
  {
    "objectID": "slides/06-slides.html#statistical-power-1",
    "href": "slides/06-slides.html#statistical-power-1",
    "title": "Statistical Power",
    "section": "Statistical Power",
    "text": "Statistical Power\nStatistical power is the probability of detecting an effect with a hypothesis test, given a certain effect size\n(Or \\(1 - \\beta\\))"
  },
  {
    "objectID": "slides/06-slides.html#your-turn-1-calculating-power",
    "href": "slides/06-slides.html#your-turn-1-calculating-power",
    "title": "Statistical Power",
    "section": "Your turn #1: Calculating power",
    "text": "Your turn #1: Calculating power\n\nCreate your true effect world: Simulate a population with a true difference of -0.5 between action and comedy movies.\nGet your sampling distribution: Simulate 1000 random samples of size n = 1000 and store the results.\nPlot your Sampling distribution (use data.frame() to turn your vector into a data frame that can be read by ggplot)\nPrepare for hypothesis testing: bring the results on scale of the standard normal distribution (divide by the standard deviation of your distribution)\nCheck the transformation: plot the new, standardized values\nCalculate your power: Check how many (standardized) differences are below the 5% threshold, i.e. smaller than or equal to -1.96 (hint: use mutate() in combination with ifelse to create a new variable significant that takes the values of TRUE or FALSE. Then use summarize() and sum() to calculate the share). Are you above the 80% power threshold?\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "slides/06-slides.html#the-central-limit-theorem-again",
    "href": "slides/06-slides.html#the-central-limit-theorem-again",
    "title": "Statistical Power",
    "section": "The central limit theorem (again)",
    "text": "The central limit theorem (again)\nThe larger the sample size, the more statistical power"
  },
  {
    "objectID": "slides/04-slides.html#overview",
    "href": "slides/04-slides.html#overview",
    "title": "Data visualization",
    "section": "Overview",
    "text": "Overview\n\n\n\nThe ggplot function\nMapping data to aesthetics\nDifferent geoms\nScales\n\n\n\nFacets\nCoordinates\nThemes"
  },
  {
    "objectID": "slides/04-slides.html#the-ggplot-function-1",
    "href": "slides/04-slides.html#the-ggplot-function-1",
    "title": "Data visualization",
    "section": "The ggplot() function",
    "text": "The ggplot() function\n\n\nggplot() from the ggplot2 package is what we’re gonna use for all our plots\nIt takes the following core arguments:\n\nggplot(data, aes()) + geometry + other_stuff\n\n\nData: the values to plot\nMapping (aes, for aesthetics): the structure of the plot\nGeometry: the type of plot\n\n\nYou can also use a pipe\n\ndata |&gt; \nggplot(aes()) + geometry + other_stuff"
  },
  {
    "objectID": "slides/04-slides.html#the-ggplot-function-2",
    "href": "slides/04-slides.html#the-ggplot-function-2",
    "title": "Data visualization",
    "section": "The ggplot() function",
    "text": "The ggplot() function\nTake for instance the gapminder data you’ve previously installed.\n\nlibrary(gapminder)\n\n# The data() function in R is used to list, load, \n# and access built-in or package-provided datasets. \ndata(gapminder) \n\nLet’s get a quick overview of the data again.\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786."
  },
  {
    "objectID": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita",
    "href": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita",
    "title": "Data visualization",
    "section": "What’s the relationship between life expectancy and GDP per capita?",
    "text": "What’s the relationship between life expectancy and GDP per capita?\n\n\n… we expect of course that higher GDP per capita leads to greater life expactancy."
  },
  {
    "objectID": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-1",
    "href": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-1",
    "title": "Data visualization",
    "section": "What’s the relationship between life expectancy and GDP per capita?",
    "text": "What’s the relationship between life expectancy and GDP per capita?\n\n\n\nWe first assign the gapminder data to ggplot()\nThe result is just an empty plot\n\n\n\nggplot(data = gapminder)"
  },
  {
    "objectID": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-2",
    "href": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-2",
    "title": "Data visualization",
    "section": "What’s the relationship between life expectancy and GDP per capita?",
    "text": "What’s the relationship between life expectancy and GDP per capita?\n\n\n\nNext, we map out the plot by adding the x and y axes\n\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp))"
  },
  {
    "objectID": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-3",
    "href": "slides/04-slides.html#whats-the-relationship-between-life-expectancy-and-gdp-per-capita-3",
    "title": "Data visualization",
    "section": "What’s the relationship between life expectancy and GDP per capita?",
    "text": "What’s the relationship between life expectancy and GDP per capita?\n\n\n\nWe then define how we want to plot our data\nIn this case, let’s go for the raw data points\n\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "slides/04-slides.html#mapping-data-to-aesthetics",
    "href": "slides/04-slides.html#mapping-data-to-aesthetics",
    "title": "Data visualization",
    "section": "Mapping data to aesthetics",
    "text": "Mapping data to aesthetics\nSo far, only two variables appear in our plot (mapped onto the x and the y axis)\n\nBut we can add more variables to the plot, by assigning them to certain asthetics"
  },
  {
    "objectID": "slides/04-slides.html#mapping-data-to-aesthetics-1",
    "href": "slides/04-slides.html#mapping-data-to-aesthetics-1",
    "title": "Data visualization",
    "section": "Mapping data to aesthetics",
    "text": "Mapping data to aesthetics\n\n\n\nFor example, we can display the variable continent as colors\n\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"
  },
  {
    "objectID": "slides/04-slides.html#mapping-data-to-aesthetics-2",
    "href": "slides/04-slides.html#mapping-data-to-aesthetics-2",
    "title": "Data visualization",
    "section": "Mapping data to aesthetics",
    "text": "Mapping data to aesthetics\n\n\n\nFor example, we can display the variable continent as colors\nNote that a legend gets added automatically to the plot\n\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()"
  },
  {
    "objectID": "slides/04-slides.html#mapping-data-to-aesthetics-3",
    "href": "slides/04-slides.html#mapping-data-to-aesthetics-3",
    "title": "Data visualization",
    "section": "Mapping data to aesthetics",
    "text": "Mapping data to aesthetics\n\n\n\nWe could further display population size by mapping it to the size aesthetic\n\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point()"
  },
  {
    "objectID": "slides/04-slides.html#grammatical-layers",
    "href": "slides/04-slides.html#grammatical-layers",
    "title": "Data visualization",
    "section": "Grammatical Layers",
    "text": "Grammatical Layers\n\n\nSo far we know about data, aesthetics, and geometries\n\nThink of these components as layers\n\nWe add them to foundational ggplot() with +"
  },
  {
    "objectID": "slides/04-slides.html#possible-aesthetics",
    "href": "slides/04-slides.html#possible-aesthetics",
    "title": "Data visualization",
    "section": "Possible aesthetics",
    "text": "Possible aesthetics\n\n\ncolor (discrete)\n\n\n\n\n\n\n\n\n\ncolor (continuous)\n\n\n\n\n\n\n\n\n\n\nsize\n\n\n\n\n\n\n\n\n\nfill\n\n\n\n\n\n\n\n\n\n\nshape\n\n\n\n\n\n\n\n\n\nalpha"
  },
  {
    "objectID": "slides/04-slides.html#possible-geoms",
    "href": "slides/04-slides.html#possible-geoms",
    "title": "Data visualization",
    "section": "Possible geoms",
    "text": "Possible geoms\n\n\n\n\n\nExample geom\n\n\nWhat it makes\n\n\n\n\n\n\n\ngeom_col()\n\n\nBar charts\n\n\n\n\n\n\n\ngeom_text()\n\n\nText\n\n\n\n\n\n\n\ngeom_point()\n\n\nPoints\n\n\n\n\n\n\n\ngeom_boxplot() \n\n\nBoxplots\n\n\n\n\n\n\n\ngeom_sf()\n\n\nMaps"
  },
  {
    "objectID": "slides/04-slides.html#possible-geoms-1",
    "href": "slides/04-slides.html#possible-geoms-1",
    "title": "Data visualization",
    "section": "Possible geoms",
    "text": "Possible geoms\nThere are dozens of possible geoms andeach class session will cover different ones.\n\nSee the {ggplot2} documentation for complete examples of all the different geom layers"
  },
  {
    "objectID": "slides/04-slides.html#additional-layers",
    "href": "slides/04-slides.html#additional-layers",
    "title": "Data visualization",
    "section": "Additional Layers",
    "text": "Additional Layers\n\n\nThere are many of other grammatical layers we can use to describe graphs!\nWe sequentially add layers onto the foundational ggplot() plot to create complex figures"
  },
  {
    "objectID": "slides/04-slides.html#scales",
    "href": "slides/04-slides.html#scales",
    "title": "Data visualization",
    "section": "Scales",
    "text": "Scales\nScales change how variables are mapped\n\n\n\nExample layer\n\n\nWhat it does\n\n\n\n\nscale_x_continuous()\n\n\nMake the x-axis continuous\n\n\n\n\nscale_x_continuous(breaks = 1:5) \n\n\nManually specify axis ticks\n\n\n\n\nscale_x_log10()\n\n\nLog the x-axis\n\n\n\n\nscale_color_gradient()\n\n\nUse a gradient\n\n\n\n\nscale_fill_viridis_d()\n\n\nFill with discrete viridis colors"
  },
  {
    "objectID": "slides/04-slides.html#scales-1",
    "href": "slides/04-slides.html#scales-1",
    "title": "Data visualization",
    "section": "Scales",
    "text": "Scales\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point()"
  },
  {
    "objectID": "slides/04-slides.html#scales-2",
    "href": "slides/04-slides.html#scales-2",
    "title": "Data visualization",
    "section": "Scales",
    "text": "Scales\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10()"
  },
  {
    "objectID": "slides/04-slides.html#scales-3",
    "href": "slides/04-slides.html#scales-3",
    "title": "Data visualization",
    "section": "Scales",
    "text": "Scales\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "slides/04-slides.html#facets",
    "href": "slides/04-slides.html#facets",
    "title": "Data visualization",
    "section": "Facets",
    "text": "Facets\nFacets show subplots for different subsets of data\n\n\n\nExample layer\n\n\nWhat it does\n\n\n\n\nfacet_wrap(vars(continent))\n\n\nPlot for each continent\n\n\n\n\nfacet_wrap(vars(continent, year)) \n\n\nPlot for each continent/year\n\n\n\n\nfacet_wrap(…, ncol = 1)\n\n\nPut all facets in one column\n\n\n\n\nfacet_wrap(…, nrow = 1)\n\n\nPut all facets in one row"
  },
  {
    "objectID": "slides/04-slides.html#facets-1",
    "href": "slides/04-slides.html#facets-1",
    "title": "Data visualization",
    "section": "Facets",
    "text": "Facets\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "slides/04-slides.html#facets-2",
    "href": "slides/04-slides.html#facets-2",
    "title": "Data visualization",
    "section": "Facets",
    "text": "Facets\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() +\n  facet_wrap(vars(continent))"
  },
  {
    "objectID": "slides/04-slides.html#facets-3",
    "href": "slides/04-slides.html#facets-3",
    "title": "Data visualization",
    "section": "Facets",
    "text": "Facets\n\n\n\nggplot(data = gapminder |&gt; \n         filter(year %in% c(2002, 2007)), \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() +\n  facet_wrap(vars(continent, \n                  year), nrow = 2)"
  },
  {
    "objectID": "slides/04-slides.html#coordinates",
    "href": "slides/04-slides.html#coordinates",
    "title": "Data visualization",
    "section": "Coordinates",
    "text": "Coordinates\nChange the coordinate system\n\n\n\nExample layer\n\n\nWhat it does\n\n\n\n\ncoord_cartesian()\n\n\nPlot for each continent\n\n\n\n\ncoord_cartesian(ylim = c(1, 10)) \n\n\nZoom in where y is 1–10\n\n\n\n\ncoord_flip()\n\n\nSwitch x and y\n\n\n\n\ncoord_polar()\n\n\nUse circular polar system"
  },
  {
    "objectID": "slides/04-slides.html#coordinates-1",
    "href": "slides/04-slides.html#coordinates-1",
    "title": "Data visualization",
    "section": "Coordinates",
    "text": "Coordinates\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "slides/04-slides.html#coordinates-2",
    "href": "slides/04-slides.html#coordinates-2",
    "title": "Data visualization",
    "section": "Coordinates",
    "text": "Coordinates\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() +\n  coord_cartesian(ylim = c(70, 80), \n                  xlim = c(10000, 30000))"
  },
  {
    "objectID": "slides/04-slides.html#coordinates-3",
    "href": "slides/04-slides.html#coordinates-3",
    "title": "Data visualization",
    "section": "Coordinates",
    "text": "Coordinates\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() + \n  coord_flip()"
  },
  {
    "objectID": "slides/04-slides.html#labels",
    "href": "slides/04-slides.html#labels",
    "title": "Data visualization",
    "section": "Labels",
    "text": "Labels\nAdd labels to the plot with a single labs() layer\n\n\n\nExample layer\n\n\nWhat it does\n\n\n\n\nlabs(title = “Neat title”)\n\n\nTitle\n\n\n\n\nlabs(caption = “Something”)\n\n\nCaption\n\n\n\n\nlabs(y = “Something”)\n\n\ny-axis\n\n\n\n\nlabs(size = “Population”)\n\n\nTitle of size legend"
  },
  {
    "objectID": "slides/04-slides.html#theme",
    "href": "slides/04-slides.html#theme",
    "title": "Data visualization",
    "section": "Theme",
    "text": "Theme\nChange the appearance of anything in the plot\nThere are many built-in themes\n\n\n\nExample layer\n\n\nWhat it does\n\n\n\n\ntheme_grey()\n\n\nDefault grey background\n\n\n\n\ntheme_bw()\n\n\nBlack and white\n\n\n\n\ntheme_dark()\n\n\nDark\n\n\n\n\ntheme_minimal()\n\n\nMinimal"
  },
  {
    "objectID": "slides/04-slides.html#theme-1",
    "href": "slides/04-slides.html#theme-1",
    "title": "Data visualization",
    "section": "Theme",
    "text": "Theme\nThere are collections of pre-built themes online,like the {ggthemes} package"
  },
  {
    "objectID": "slides/04-slides.html#theme-2",
    "href": "slides/04-slides.html#theme-2",
    "title": "Data visualization",
    "section": "Theme",
    "text": "Theme\nOrganizations often make their own custom themes, like the BBC"
  },
  {
    "objectID": "slides/04-slides.html#theme-options",
    "href": "slides/04-slides.html#theme-options",
    "title": "Data visualization",
    "section": "Theme options",
    "text": "Theme options\nMake theme adjustments with theme()\nThere are a billion options here!\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() +\n  labs(title = \"Health and wealth grow together\",\n       subtitle = \"Data from the world\",\n       x = \"Wealth (GDP per capita)\",\n       y = \"Health (life expectancy)\",\n       color = \"Continent\",\n       size = \"Population\",\n       caption = \"Source: The Gapminder Project\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/04-slides.html#theme-options-1",
    "href": "slides/04-slides.html#theme-options-1",
    "title": "Data visualization",
    "section": "Theme options",
    "text": "Theme options\nMake theme adjustments with theme()\nThere are a billion options here!\n\n\nggplot(data = gapminder, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, \n                     size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_color_viridis_d() +\n  labs(title = \"Health and wealth grow together\",\n       subtitle = \"Data from the world\",\n       x = \"Wealth (GDP per capita)\",\n       y = \"Health (life expectancy)\",\n       color = \"Continent\",\n       size = \"Population\",\n       caption = \"Source: The Gapminder Project\") +\n  theme_minimal() +\n  theme(legend.position = \"top\",\n        plot.title = element_text(face = \"bold\"),\n        axis.title.y = element_text(face = \"italic\"))"
  },
  {
    "objectID": "slides/04-slides.html#there-are-many-many-more-options",
    "href": "slides/04-slides.html#there-are-many-many-more-options",
    "title": "Data visualization",
    "section": "There are many, many more options",
    "text": "There are many, many more options\n\n\nSee the {ggplot2} documentation for complete examples of everything you can do"
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\nTake this tibble (very similar to a data.frame) of temperature recordings at three stations on three dates:\n\ntemp_data_untidy &lt;- tribble(\n  ~date, ~station1, ~station2,  ~station3,\n  \"2023-10-01\", 30.1, 29.8,  31.2,\n  \"2023-11-01\", 28.6, 29.1,  33.4,\n  \"2023-12-01\", 29.9, 28.5,  32.3\n)\n\nImagine our goal is to track temperature across time."
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures-1",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures-1",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\n\nWhat makes this data untidy? Describe.\nMake a new data frame called temp_data_tidy. Use pivot_longer() to tidy the data and create a new temperature and station variable.\nMake a plot that tracks the temperature changes over time for station1 only. Use filter() to select the station and use mutate() in combination with the as_date() function to convert the date variable from character to a date format. into a date. Use geom_line for the plot.\nNow use the the non-filtered data frame with all stations. Add another aesthetic layer to your previous plot, so that your new plot allows to differentiate temperature changes between the different stations. Tip: Use color\n\n\n\n\n−+\n06:00"
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures-2",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures-2",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\n1.  What makes this data untidy? Describe.\n\n\n\n\nVariables are columns\nObservations are rows\nValues are cells\n\n\n\n\n\n\n\ndate\nstation1\nstation2\nstation3\n\n\n\n\n2023-10-01\n30.1\n29.8\n31.2\n\n\n2023-11-01\n28.6\n29.1\n33.4\n\n\n2023-12-01\n29.9\n28.5\n32.3\n\n\n\n\n\n\nMultiple observations (temperature recordings) per row"
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures-3",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures-3",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\n\nMake a new data frame called temp_data_tidy. Use pivot_longer() to tidy the data and create a new temperature and station variable.\n\n\ntemp_data_tidy &lt;- temp_data_untidy |&gt; \n  pivot_longer(cols = starts_with(\"station\"),\n               names_to = \"station\",\n               values_to = \"temperature\")\n\n\n\n\n\n\ndate\nstation\ntemperature\n\n\n\n\n2023-10-01\nstation1\n30.1\n\n\n2023-10-01\nstation2\n29.8\n\n\n2023-10-01\nstation3\n31.2\n\n\n2023-11-01\nstation1\n28.6\n\n\n2023-11-01\nstation2\n29.1\n\n\n2023-11-01\nstation3\n33.4\n\n\n2023-12-01\nstation1\n29.9\n\n\n2023-12-01\nstation2\n28.5\n\n\n2023-12-01\nstation3\n32.3"
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures-4",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures-4",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\n\nMake a plot that tracks the temperature changes over time for station1 only. Use filter() to select the station and use mutate() in combination with the as_date() function to convert the date variable from character to a date format. into a date. Use geom_line for the plot.\n\n\ntemp_data_tidy |&gt; \n  filter(station == \"station1\") |&gt; \n  mutate(date = as_date(date)) |&gt; \n  ggplot(aes(x = date, y = temperature)) +\n  geom_line()"
  },
  {
    "objectID": "slides/04-slides.html#your-turn-1-untidy-temperatures-5",
    "href": "slides/04-slides.html#your-turn-1-untidy-temperatures-5",
    "title": "Data visualization",
    "section": "Your turn #1: untidy temperatures",
    "text": "Your turn #1: untidy temperatures\n\nNow use the the non-filtered data frame with all stations. Add another aesthetic layer to your previous plot, so that your new plot allows to differentiate temperature changes between the different stations. Tip: Use color\n\n\ntemp_data_tidy |&gt; \n  mutate(date = as_date(date)) |&gt; \n  ggplot(aes(x = date, y = temperature, color = station)) +\n  geom_line()"
  },
  {
    "objectID": "slides/04-slides.html#thats-it-for-today",
    "href": "slides/04-slides.html#thats-it-for-today",
    "title": "Data visualization",
    "section": "That’s it for today :)",
    "text": "That’s it for today :)"
  },
  {
    "objectID": "slides/02-slides.html#overview",
    "href": "slides/02-slides.html#overview",
    "title": "Data manipulation basics",
    "section": "Overview",
    "text": "Overview\n\n\n\nThe tidyverse\n\nR Packages\nImporting data\n\nThe dplyr package\n\nfilter()\nmutate()\nifelse()\npipes |&gt;\nsummarize()\ngroup_by()\n\n\n\n\nThe tidy data format"
  },
  {
    "objectID": "slides/02-slides.html#packages",
    "href": "slides/02-slides.html#packages",
    "title": "Data manipulation basics",
    "section": "Packages",
    "text": "Packages"
  },
  {
    "objectID": "slides/02-slides.html#packages-1",
    "href": "slides/02-slides.html#packages-1",
    "title": "Data manipulation basics",
    "section": "Packages",
    "text": "Packages"
  },
  {
    "objectID": "slides/02-slides.html#packages-2",
    "href": "slides/02-slides.html#packages-2",
    "title": "Data manipulation basics",
    "section": "Packages",
    "text": "Packages\n\n\nSo far we only used functions that are directly available in R\n\nBut there are tons of user-created functions out there that can make your life so much easier\nThese functions are shared in what we call packages\n\nPackages are bundles of functions that R users put at the disposal of other R users\n\nPackages are centralized on the Comprehensive R Archive Network (CRAN)\nTo download and install a CRAN package you can simply type `install.packages()"
  },
  {
    "objectID": "slides/02-slides.html#using-packages",
    "href": "slides/02-slides.html#using-packages",
    "title": "Data manipulation basics",
    "section": "Using packages",
    "text": "Using packages\n\n\n\n\n\ninstall.packages(\"name\")\n\n\n\nfiles to your computer\nDo this once per computer\n\n\n\n\nlibrary(\"name\")\n\n\n\nLoads the package\nDo this once per R session"
  },
  {
    "objectID": "slides/02-slides.html#the-tidyverse-1",
    "href": "slides/02-slides.html#the-tidyverse-1",
    "title": "Data manipulation basics",
    "section": "The tidyverse",
    "text": "The tidyverse\n\n\n“The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.”\n\n… the tidyverse makes data science faster, easier and more fun…"
  },
  {
    "objectID": "slides/02-slides.html#the-tidyverse-2",
    "href": "slides/02-slides.html#the-tidyverse-2",
    "title": "Data manipulation basics",
    "section": "The tidyverse",
    "text": "The tidyverse"
  },
  {
    "objectID": "slides/02-slides.html#the-tidyverse-3",
    "href": "slides/02-slides.html#the-tidyverse-3",
    "title": "Data manipulation basics",
    "section": "The tidyverse",
    "text": "The tidyverse\n\nlibrary(tidyverse)\n\nThe tidyverse package is a shortcut for installing and loading all the key tidyverse packages"
  },
  {
    "objectID": "slides/02-slides.html#the-tidyverse-4",
    "href": "slides/02-slides.html#the-tidyverse-4",
    "title": "Data manipulation basics",
    "section": "The tidyverse",
    "text": "The tidyverse\n\n\n\ninstall.packages(\"tidyverse\")\n\nInstalls all of these:\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"tidyr\")\ninstall.packages(\"readr\")\ninstall.packages(\"purrr\")\ninstall.packages(\"tibble\")\ninstall.packages(\"stringr\")\ninstall.packages(\"forcats\")\ninstall.packages(\"lubridate\")\ninstall.packages(\"hms\")\ninstall.packages(\"DBI\")\ninstall.packages(\"haven\")\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\ninstall.packages(\"readxl\")\ninstall.packages(\"rvest\")\ninstall.packages(\"xml2\")\ninstall.packages(\"modelr\")\ninstall.packages(\"broom\")\n\n\n\nlibrary(tidyverse)\n\nLoads all of these:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(purrr)\nlibrary(tibble)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(lubridate)"
  },
  {
    "objectID": "slides/02-slides.html#importing-data",
    "href": "slides/02-slides.html#importing-data",
    "title": "Data manipulation basics",
    "section": "Importing data",
    "text": "Importing data\n\n\n\n\n\n\nWork with plain text data\n\n\nmy_data &lt;- read_csv(“file.csv”)\n\n\n\n\n\n\n\nWork with Excel files\n\n\nmy_data &lt;- read_excel(“file.xlsx”)\n\n\n\n\n\n\n\nWork with Stata, SPSS, and SAS data\n\n\nmy_data &lt;- read_stata(“file.dta”)"
  },
  {
    "objectID": "slides/02-slides.html#dplyr-verbs-for-manipulating-data",
    "href": "slides/02-slides.html#dplyr-verbs-for-manipulating-data",
    "title": "Data manipulation basics",
    "section": "dplyr: verbs for manipulating data",
    "text": "dplyr: verbs for manipulating data\n\n\n\nExtract rows with filter()\n\n\n\n\n\n\n\nExtract columns with select()\n\n\n\n\n\n\n\nArrange/sort rows with arrange()\n\n\n\n\n\n\n\nMake new columns with mutate()\n\n\n\n\n\n\n\nMake group summaries with group_by() |&gt; summarize()"
  },
  {
    "objectID": "slides/02-slides.html#filter",
    "href": "slides/02-slides.html#filter",
    "title": "Data manipulation basics",
    "section": "filter()",
    "text": "filter()\nExtract rows that meet some sort of test\n\n\nThe general idea:\n\nfilter(\n  some_data, \n  ... # one or more tests \n  )\n\n\n\nLet’s try this on the gapminder data set that you’ve installed earlier.\n\n\n\nfilter(.data = gapminder, country == \"Denmark\")\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\n\n\n\n\nDenmark\nEurope\n1952\n\n\nDenmark\nEurope\n1957\n\n\nDenmark\nEurope\n1962\n\n\nDenmark\nEurope\n1967\n\n\nDenmark\nEurope\n1972\n\n\n…\n…\n…"
  },
  {
    "objectID": "slides/02-slides.html#logical-tests",
    "href": "slides/02-slides.html#logical-tests",
    "title": "Data manipulation basics",
    "section": "Logical tests",
    "text": "Logical tests\n\n\n\n\n\n\n\n\n\n\nTest\nMeaning\nTest\nMeaning\n\n\n\n\nx &lt; y\nLess than\nx %in% y\nIn (group membership)\n\n\nx &gt; y\nGreater than\nis.na(x)\nIs missing\n\n\n==\nEqual to\n!is.na(x)\nIs not missing\n\n\nx &lt;= y\nLess than or equal to\n\n\n\n\nx &gt;= y\nGreater than or equal to\n\n\n\n\nx != y\nNot equal to"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-1-filtering",
    "href": "slides/02-slides.html#your-turn-1-filtering",
    "title": "Data manipulation basics",
    "section": "Your turn #1: Filtering",
    "text": "Your turn #1: Filtering\nUse filter() and logical tests to show…\n\nThe data for Canada\nAll data for countries in Oceania\nRows where the life expectancy is greater than 82\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-1-filtering-1",
    "href": "slides/02-slides.html#your-turn-1-filtering-1",
    "title": "Data manipulation basics",
    "section": "Your turn #1: Filtering",
    "text": "Your turn #1: Filtering\nUse filter() and logical tests to show…\n\n\nThe data for Canada\n\n\nfilter(gapminder, country == \"Canada\")\n\n\n\n\nAll data for countries in Oceania\n\n\nfilter(gapminder, continent == \"Oceania\")\n\n\n\n\nRows where the life expectancy is greater than 82\n\n\nfilter(gapminder, lifeExp &gt; 82)"
  },
  {
    "objectID": "slides/02-slides.html#common-mistakes",
    "href": "slides/02-slides.html#common-mistakes",
    "title": "Data manipulation basics",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nUsing = instead of ==\n\n\n\n\nBad\n\nfilter(gapminder, country = \"Canada\")\n\n\n\n\nGood\n\nfilter(gapminder, country == \"Canada\")\n\n\n\n\n\n\nForgetting quotes (\"\")\n\n\n\n\nBad\n\nfilter(gapminder, country == Canada)\n\n\n\n\nGood\n\nfilter(gapminder, country == \"Canada\")"
  },
  {
    "objectID": "slides/02-slides.html#filter-with-multiple-conditions",
    "href": "slides/02-slides.html#filter-with-multiple-conditions",
    "title": "Data manipulation basics",
    "section": "filter() with multiple conditions",
    "text": "filter() with multiple conditions\nExtract rows that meet every test\n\nfilter(gapminder, country == \"Denmark\", year &gt; 2000)\n\n\n\n# A tibble: 2 × 6\n  country continent  year lifeExp     pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;     &lt;dbl&gt;\n1 Denmark Europe     2002    77.2 5374693    32167.\n2 Denmark Europe     2007    78.3 5468120    35278."
  },
  {
    "objectID": "slides/02-slides.html#boolean-operators",
    "href": "slides/02-slides.html#boolean-operators",
    "title": "Data manipulation basics",
    "section": "Boolean operators",
    "text": "Boolean operators\n\n\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\na & b\nand\n\n\na | b\nor\n\n\n!a\nnot"
  },
  {
    "objectID": "slides/02-slides.html#boolean-operators-1",
    "href": "slides/02-slides.html#boolean-operators-1",
    "title": "Data manipulation basics",
    "section": "Boolean operators",
    "text": "Boolean operators\n\nThe default is “and”\n\n\nThese do the same thing:\n\n\n\nfilter(gapminder, \n       country == \"Denmark\", \n       year &gt; 2000)\n\n\n\nfilter(gapminder, \n       country == \"Denmark\" & \n         year &gt; 2000)"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-2-filtering",
    "href": "slides/02-slides.html#your-turn-2-filtering",
    "title": "Data manipulation basics",
    "section": "Your turn #2: Filtering",
    "text": "Your turn #2: Filtering\nUse filter() and Boolean logical tests to show…\n\nCanada before 1970\nCountries where life expectancy in 2007 is below 50\nCountries where life expectancy in 2007 is below 50 and are not in Africa\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-2-filtering-1",
    "href": "slides/02-slides.html#your-turn-2-filtering-1",
    "title": "Data manipulation basics",
    "section": "Your turn #2: Filtering",
    "text": "Your turn #2: Filtering\nUse filter() and Boolean logical tests to show…\n\nCanada before 1970\n\n\nfilter(gapminder, country == \"Canada\", year &lt; 1970)\n\n\nCountries where life expectancy in 2007 is below 50\n\n\nfilter(gapminder, year == 2007, lifeExp &lt; 50)\n\n\nCountries where life expectancy in 2007 is below 50 and are not in Africa\n\n\nfilter(gapminder, year == 2007, lifeExp &lt; 50, \n       continent != \"Africa\")"
  },
  {
    "objectID": "slides/02-slides.html#common-mistakes-1",
    "href": "slides/02-slides.html#common-mistakes-1",
    "title": "Data manipulation basics",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nCollapsing multiple tests into one\n\n\n\n\nBad\n\nfilter(gapminder, \n       1960 &lt; year &lt; 1980)\n\n\n\n\nGood\n\nfilter(gapminder,\n       year &gt; 1960, \n       year &lt; 1980)\n\n\n\n\n\n\nUsing multiple tests instead of %in%\n\n\n\n\nBad\n\nfilter(gapminder,\n       country == \"Mexico\",\n       country == \"Canada\",\n       country == \"United States\")\n\n\n\n\nGood\n\nfilter(gapminder,\n       country %in% c(\"Mexico\", \"Canada\",\n                      \"United States\"))"
  },
  {
    "objectID": "slides/02-slides.html#common-syntax",
    "href": "slides/02-slides.html#common-syntax",
    "title": "Data manipulation basics",
    "section": "Common Syntax",
    "text": "Common Syntax\nEvery dplyr verb function follows the same pattern\n\n\n\n\nverb(data, ...)\n\n\nverb = dplyr function/verb\ndata = data frame to transfom\n... = what you the verb to do exatly"
  },
  {
    "objectID": "slides/02-slides.html#mutate",
    "href": "slides/02-slides.html#mutate",
    "title": "Data manipulation basics",
    "section": "mutate()",
    "text": "mutate()\nCreate new columns\n\n\nThe general idea:\n\nmutate(\n  some_data, \n  ... # new columns to make\n  )\n\n\n\nLet’s try this on the gapminder data\n\nmutate(gapminder, gdp = gdpPercap * pop)\n\n\n\n\n\n\n\n\ncountry\nyear\n…\ngdp\n\n\n\n\nAfghanistan\n1952\n…\n6567086330\n\n\nAfghanistan\n1957\n…\n7585448670\n\n\nAfghanistan\n1962\n…\n8758855797\n\n\nAfghanistan\n1967\n…\n9648014150\n\n\nAfghanistan\n1972\n…\n9678553274\n\n\nAfghanistan\n1977\n…\n11697659231"
  },
  {
    "objectID": "slides/02-slides.html#mutate-1",
    "href": "slides/02-slides.html#mutate-1",
    "title": "Data manipulation basics",
    "section": "mutate()",
    "text": "mutate()\nCreate new columns\n\n\nThe general idea:\n\nmutate(\n  some_data, \n  ... # new columns to make\n  )\n\n\nWe can also create multiple new columns at once\n\n\nmutate(gapminder, gdp = gdpPercap * pop,\n                  pop_mil = round(pop / 1000000))\n\n\n\n\n\n\n\n\ncountry\nyear\n…\ngdp\npop_mil\n\n\n\n\nAfghanistan\n1952\n…\n6567086330\n8\n\n\nAfghanistan\n1957\n…\n7585448670\n9\n\n\nAfghanistan\n1962\n…\n8758855797\n10\n\n\nAfghanistan\n1967\n…\n9648014150\n12\n\n\nAfghanistan\n1972\n…\n9678553274\n13\n\n\nAfghanistan\n1977\n…\n11697659231\n15"
  },
  {
    "objectID": "slides/02-slides.html#ifelse",
    "href": "slides/02-slides.html#ifelse",
    "title": "Data manipulation basics",
    "section": "ifelse()",
    "text": "ifelse()\nDo conditional tests within mutate()\n\n\n\n\nifelse(test,\n       value_if_true, \n       value_if_false)\n\n\ntest = a logical test\nvalue_if_true = what happens if test is true\nvalue_if_false = what happens if test is false"
  },
  {
    "objectID": "slides/02-slides.html#ifelse-1",
    "href": "slides/02-slides.html#ifelse-1",
    "title": "Data manipulation basics",
    "section": "ifelse()",
    "text": "ifelse()\nThe new variable can take any sort of class\n\n# a new logical variable\nmutate(gapminder, \n       after_1960 = ifelse(year &gt; 1960, TRUE, FALSE)\n       )\n\n\n\n# a new character variable\nmutate(gapminder, \n       after_1960 = ifelse(year &gt; 1960, \n                           \"After 1960\", \n                           \"Before 1960\")\n       )\n\n\n\n# a new numeric variable\nmutate(gapminder, \n       after_1960 = ifelse(year &gt; 1960, 0, 1)\n       )"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-3-mutating",
    "href": "slides/02-slides.html#your-turn-3-mutating",
    "title": "Data manipulation basics",
    "section": "Your turn #3: Mutating",
    "text": "Your turn #3: Mutating\nUse mutate() to…\n\nAdd an africa column that is TRUE if the country is on the African continent\nAdd a column for logged GDP per capita (hint: use log())\nAdd an africa_asia column that says “Africa or Asia” if the country is in Africa or Asia, and “Not Africa or Asia” if it’s not\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-3-mutating-1",
    "href": "slides/02-slides.html#your-turn-3-mutating-1",
    "title": "Data manipulation basics",
    "section": "Your turn #3: Mutating",
    "text": "Your turn #3: Mutating\nUse mutate() to…\n\n\nAdd an africa column that is TRUE if the country is on the African continent\n\n\nmutate(gapminder, africa = ifelse(continent == \"Africa\", \n                                  TRUE, FALSE))\n\n\n\n\nAdd a column for logged GDP per capita (hint: use log())\n\n\nmutate(gapminder, log_gdpPercap = log(gdpPercap))\n\n\n\n\nAdd an africa_asia column that says “Africa or Asia” if the country is in Africa or Asia, and “Not Africa or Asia” if it’s not\n\n\nmutate(gapminder, \n       africa_asia = \n         ifelse(continent %in% c(\"Africa\", \"Asia\"), \n                \"Africa or Asia\", \n                \"Not Africa or Asia\"))"
  },
  {
    "objectID": "slides/02-slides.html#what-if-you-have-multiple-verbs",
    "href": "slides/02-slides.html#what-if-you-have-multiple-verbs",
    "title": "Data manipulation basics",
    "section": "What if you have multiple verbs?",
    "text": "What if you have multiple verbs?\n\nSolution 1: Intermediate variables\n\ngapminder_2002 &lt;- filter(gapminder, year == 2002)\n\ngapminder_2002_log &lt;- mutate(gapminder_2002,\n                             log_gdpPercap = log(gdpPercap))\n\n\n\nSolution 2: Nested functions\n\nfilter(mutate(gapminder_2002, \n              log_gdpPercap = log(gdpPercap)), \n       year == 2002)\n\n\n\nSolution 3: Pipes!\n\nThe |&gt; operator (pipe) takes an object on the left and passes it as the first argument of the function on the right\n\n\ngapminder |&gt; \n  filter(year == 2002) |&gt; \n  mutate(log_gdpPercap = log(gdpPercap))"
  },
  {
    "objectID": "slides/02-slides.html#section",
    "href": "slides/02-slides.html#section",
    "title": "Data manipulation basics",
    "section": "|>",
    "text": "|&gt;\nWhy using pipes?\n\n\nleave_house(get_dressed(get_out_of_bed(wake_up(me, time = \"8:00\"), side = \"correct\"),\n    pants = TRUE, shirt = TRUE), car = TRUE, bike = FALSE)\n\n… 🤯 not easy to read\n\n\n\n\nme |&gt; \n  wake_up(time = \"8:00\") |&gt; \n  get_out_of_bed(side = \"correct\") |&gt; \n  get_dressed(pants = TRUE, shirt = TRUE) |&gt; \n  leave_house(car = TRUE, bike = FALSE)\n\n… 🎉 easy to read"
  },
  {
    "objectID": "slides/02-slides.html#vs",
    "href": "slides/02-slides.html#vs",
    "title": "Data manipulation basics",
    "section": "|> vs %>%",
    "text": "|&gt; vs %&gt;%\n\nThere are actually multiple pipes!\n%&gt;% was invented first, but requires a package to use\n|&gt; is part of base R\nThey’re interchangeable 99% of the time (Just be consistent)\n\n\n\n\n\n\n\n\nYou do not have to type the pipe by hand every time\n\n\nYou can use the shortcut cmd + shift + m in R Studio."
  },
  {
    "objectID": "slides/02-slides.html#summarize",
    "href": "slides/02-slides.html#summarize",
    "title": "Data manipulation basics",
    "section": "summarize()",
    "text": "summarize()\nCompute a table of summaries\n\n\n\n\nTake a data frame\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\n\n\n\n\nAfghanistan\nAsia\n1952\n28.801\n\n\nAfghanistan\nAsia\n1957\n30.332\n\n\nAfghanistan\nAsia\n1962\n31.997\n\n\nAfghanistan\nAsia\n1967\n34.02\n\n\n…\n…\n…\n…\n\n\n\n\n\n\n\n\n\n\n\nMake a summary\n\n\ngapminder |&gt;\n    summarize(mean_life = mean(lifeExp))\n\n\n\n# A tibble: 1 × 1\n  mean_life\n      &lt;dbl&gt;\n1      59.5\n\n\n\n\nOr several summaries\n\ngapminder |&gt; \n  summarize(mean_life = mean(lifeExp),\n            min_life = min(lifeExp))\n\n\n\n# A tibble: 1 × 2\n  mean_life min_life\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      59.5     23.6"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-4-summarizing",
    "href": "slides/02-slides.html#your-turn-4-summarizing",
    "title": "Data manipulation basics",
    "section": "Your turn #4: Summarizing",
    "text": "Your turn #4: Summarizing\nUse summarize() to calculate…\n\nThe first (minimum) year in the dataset\nThe last (maximum) year in the dataset\nThe number of rows in the dataset (use the cheatsheet)\nThe number of distinct countries in the dataset (use the cheatsheet)\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-4-summarizing-1",
    "href": "slides/02-slides.html#your-turn-4-summarizing-1",
    "title": "Data manipulation basics",
    "section": "Your turn #4: Summarizing",
    "text": "Your turn #4: Summarizing\nOne Solution for all:\n\ngapminder |&gt; \n  summarize(first = min(year),\n            last = max(year),\n            num_rows = n(),\n            num_unique = n_distinct(country))\n\n# A tibble: 1 × 4\n  first  last num_rows num_unique\n  &lt;int&gt; &lt;int&gt;    &lt;int&gt;      &lt;int&gt;\n1  1952  2007     1704        142"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-5-summarizing",
    "href": "slides/02-slides.html#your-turn-5-summarizing",
    "title": "Data manipulation basics",
    "section": "Your turn #5: Summarizing",
    "text": "Your turn #5: Summarizing\nUse filter() and summarize() to calculate…\n\nthe number of unique countries and\nthe median life expectancy\n\non the African continent in 2007.\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-5-summarizing-1",
    "href": "slides/02-slides.html#your-turn-5-summarizing-1",
    "title": "Data manipulation basics",
    "section": "Your turn #5: Summarizing",
    "text": "Your turn #5: Summarizing\nUse filter() and summarize() to calculate…\n\nthe number of unique countries and\nthe median life expectancy\n\non the African continent in 2007.\n\ngapminder |&gt;\n  filter(continent == \"Africa\", year == 2007) |&gt;\n  summarise(n_countries = n_distinct(country), \n            med_le = median(lifeExp))\n\n# A tibble: 1 × 2\n  n_countries med_le\n        &lt;int&gt;  &lt;dbl&gt;\n1          52   52.9"
  },
  {
    "objectID": "slides/02-slides.html#group_by",
    "href": "slides/02-slides.html#group_by",
    "title": "Data manipulation basics",
    "section": "group_by()",
    "text": "group_by()\nPut rows into groups based on values in a column\n\ngapminder |&gt; group_by(continent)\n\n\nNothing happens by itself!\nPowerful when combined with summarize()"
  },
  {
    "objectID": "slides/02-slides.html#group_by-1",
    "href": "slides/02-slides.html#group_by-1",
    "title": "Data manipulation basics",
    "section": "group_by()",
    "text": "group_by()\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\n\n\n\n\nAfghanistan\nAsia\n1952\n28.801\n\n\nAfghanistan\nAsia\n1957\n30.332\n\n\nAfghanistan\nAsia\n1962\n31.997\n\n\nAfghanistan\nAsia\n1967\n34.02\n\n\n…\n…\n…\n…\n\n\n\n\n\n\n\n\n\nA simple summary\n\ngapminder |&gt;\n    summarize(n_countries = n_distinct(country))\n\n\n\n# A tibble: 1 × 1\n  n_countries\n        &lt;int&gt;\n1         142\n\n\n\n\nA grouped summary\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarize(n_countries = n_distinct(country)) \n\n\n\n# A tibble: 5 × 2\n  continent n_countries\n  &lt;fct&gt;           &lt;int&gt;\n1 Africa             52\n2 Americas           25\n3 Asia               33\n4 Europe             30\n5 Oceania             2"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-6-grouping-and-summarizing",
    "href": "slides/02-slides.html#your-turn-6-grouping-and-summarizing",
    "title": "Data manipulation basics",
    "section": "Your turn #6: Grouping and summarizing",
    "text": "Your turn #6: Grouping and summarizing\n\nFind the minimum, maximum, and median life expectancy for each continent\n\n\n\nFind the minimum, maximum, and median life expectancy for each continent in 2007 only\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-6-grouping-and-summarizing-1",
    "href": "slides/02-slides.html#your-turn-6-grouping-and-summarizing-1",
    "title": "Data manipulation basics",
    "section": "Your turn #6: Grouping and summarizing",
    "text": "Your turn #6: Grouping and summarizing\n\nFind the minimum, maximum, and median life expectancy for each continent\n\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarize(min_le = min(lifeExp),\n            max_le = max(lifeExp),\n            med_le = median(lifeExp))\n\n\nFind the minimum, maximum, and median life expectancy for each continent in 2007 only\n\n\ngapminder |&gt; \n  filter(year == 2007) |&gt; \n  group_by(continent) |&gt; \n  summarize(min_le = min(lifeExp),\n            max_le = max(lifeExp),\n            med_le = median(lifeExp))"
  },
  {
    "objectID": "slides/02-slides.html#dplyr-verbs-for-manipulating-data-1",
    "href": "slides/02-slides.html#dplyr-verbs-for-manipulating-data-1",
    "title": "Data manipulation basics",
    "section": "dplyr: verbs for manipulating data",
    "text": "dplyr: verbs for manipulating data\n\n\n\nExtract rows with filter()\n\n\n\n\n\n\n\nExtract columns with select()\n\n\n\n\n\n\n\nArrange/sort rows with arrange()\n\n\n\n\n\n\n\nMake new columns with mutate()\n\n\n\n\n\n\n\nMake group summaries with group_by() |&gt; summarize()"
  },
  {
    "objectID": "slides/02-slides.html#tidy-data-1",
    "href": "slides/02-slides.html#tidy-data-1",
    "title": "Data manipulation basics",
    "section": "Tidy data",
    "text": "Tidy data\nYou can represent the same underlying data in multiple ways.\n\n\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\n\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583"
  },
  {
    "objectID": "slides/02-slides.html#tidy-data-2",
    "href": "slides/02-slides.html#tidy-data-2",
    "title": "Data manipulation basics",
    "section": "Tidy data",
    "text": "Tidy data\nTidy data has the following properties:\n\n\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\nVariables are columns\nObservations are rows\nValues are cells"
  },
  {
    "objectID": "slides/02-slides.html#why-ensure-that-your-data-is-tidy",
    "href": "slides/02-slides.html#why-ensure-that-your-data-is-tidy",
    "title": "Data manipulation basics",
    "section": "Why ensure that your data is tidy?",
    "text": "Why ensure that your data is tidy?\nThere are two main advantages:\n\n\nThere’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.\n\n\n\n\nThere’s a specific advantage to placing variables in columns because it allows R’s vectorized nature to shine. As you learned in ?@sec-mutate and ?@sec-summarize, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.\n\n\n\ndplyr, ggplot2, and all the other packages in the tidyverse are designed to work with tidy data."
  },
  {
    "objectID": "slides/02-slides.html#will-i-ever-encounter-a-dataset-that-isnt-tidy",
    "href": "slides/02-slides.html#will-i-ever-encounter-a-dataset-that-isnt-tidy",
    "title": "Data manipulation basics",
    "section": "Will I ever encounter a dataset that isn’t tidy?",
    "text": "Will I ever encounter a dataset that isn’t tidy?\n\nYes, unfortunately, most real data is untidy.\nThere are two main reasons:\n\nData is often organized to facilitate some goal other than analysis. For example, it’s common for data to be structured to make data entry, not analysis, easy.\nMost people aren’t familiar with the principles of tidy data, and it’s hard to derive them yourself unless you spend a lot of time working with data."
  },
  {
    "objectID": "slides/02-slides.html#pivoting-data",
    "href": "slides/02-slides.html#pivoting-data",
    "title": "Data manipulation basics",
    "section": "Pivoting data",
    "text": "Pivoting data\ntidyr provides two main functions to “pivot” data in a tidy format:\n\npivot_longer()\n\nand\n\npivot_wider()\n\n\nHere, we’ll only discuss pivot_longer() because it’s the most common case."
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer",
    "href": "slides/02-slides.html#pivot_longer",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nSuppose we have three patients with ids A, B, and C, and we take two blood pressure measurements on each patient.\nWe’ll create the data with tribble(), a handy function for constructing small tibbles by hand:\n\n\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\ndf\n\n# A tibble: 3 × 3\n  id      bp1   bp2\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A       100   120\n2 B       140   115\n3 C       120   125"
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer-1",
    "href": "slides/02-slides.html#pivot_longer-1",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nWe want our new dataset to have three variables: id (already exists), measurement (the column names), and value (the cell values)\nTo achieve this, we need to pivot df longer"
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer-2",
    "href": "slides/02-slides.html#pivot_longer-2",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nThe values in a column that was already a variable in the original dataset (id) need to be repeated, once for each column that is pivoted."
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer-3",
    "href": "slides/02-slides.html#pivot_longer-3",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nThe column names become values of the new variable measurement"
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer-4",
    "href": "slides/02-slides.html#pivot_longer-4",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nThe cell values become values of the new variable value"
  },
  {
    "objectID": "slides/02-slides.html#pivot_longer-5",
    "href": "slides/02-slides.html#pivot_longer-5",
    "title": "Data manipulation basics",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\n\n# A tibble: 3 × 3\n  id      bp1   bp2\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A       100   120\n2 B       140   115\n3 C       120   125\n\n\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n\n# A tibble: 6 × 3\n  id    measurement value\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 A     bp1           100\n2 A     bp2           120\n3 B     bp1           140\n4 B     bp2           115\n5 C     bp1           120\n6 C     bp2           125\n\n\n\nThere are three key arguments:\n\ncols specifies which columns need to be pivoted, i.e. which columns aren’t variables. This argument uses the same syntax as select()\nnames_to names the variable in which column names should be stored\nvalues_to names the variable in which cell values should be stored"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-7-pivoting",
    "href": "slides/02-slides.html#your-turn-7-pivoting",
    "title": "Data manipulation basics",
    "section": "Your turn #7: Pivoting",
    "text": "Your turn #7: Pivoting\nThe billboard dataset which comes with the tidyverse package records the billboard rank of songs in the year 2000.\n\nhead(billboard)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\n\nIn this dataset, each observation is a song.\nThe first three columns (artist, track and date.entered) are variables that describe the song.\nThen we have 76 columns (wk1-wk76) that describe the rank of the song in each week."
  },
  {
    "objectID": "slides/02-slides.html#your-turn-7-pivoting-1",
    "href": "slides/02-slides.html#your-turn-7-pivoting-1",
    "title": "Data manipulation basics",
    "section": "Your turn #7: Pivoting",
    "text": "Your turn #7: Pivoting\n\nUse pivot_longer() to tidy the data (Tip: Create the new variables week and rank). Assign the resulting data frame to a new data frame called tidy_billboard.\nUse the new tidy_billboard data frame to calculate which song has been the longest on rank 1 (Tip: use filter(), group_by() and summarize())\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#your-turn-7-pivoting-2",
    "href": "slides/02-slides.html#your-turn-7-pivoting-2",
    "title": "Data manipulation basics",
    "section": "Your turn #7: Pivoting",
    "text": "Your turn #7: Pivoting\n\nUse pivot_longer() to tidy the data (Tip: Create the new variables week and rank). Assign the resulting data frame to a new data frame called tidy_billboard.\n\n\ntidy_billboard &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  ) \n\n\nUse the new tidy_billboard data frame to calculate which song has been the longest on rank 1 (Tip: use filter(), group_by() and summarize())\n\n\ntidy_billboard |&gt; \n  filter(rank == 1) |&gt; \n  group_by(track) |&gt; \n  summarize(weeks_on_rank_1 = n()) |&gt; \n  arrange(desc(weeks_on_rank_1)) \n\n# alternative solution\ntidy_billboard |&gt; \n  group_by(track) |&gt; \n  summarize(weeks_on_rank_1 = sum(rank == 1, na.rm = TRUE)) |&gt; \n  arrange(desc(weeks_on_rank_1))"
  },
  {
    "objectID": "slides/02-slides.html#thats-it-for-today",
    "href": "slides/02-slides.html#thats-it-for-today",
    "title": "Data manipulation basics",
    "section": "That’s it for today :)",
    "text": "That’s it for today :)"
  },
  {
    "objectID": "problem_sets/07-solution.html",
    "href": "problem_sets/07-solution.html",
    "title": "Problem set 7",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)"
  },
  {
    "objectID": "problem_sets/07-solution.html#procedure",
    "href": "problem_sets/07-solution.html#procedure",
    "title": "Problem set 7",
    "section": "Procedure",
    "text": "Procedure\n\nDescribe the experimental procedure, and in particular your treatment. How would you run the experiment?\n\nWe could imagine a design similar to the reference study, in which patients in clinics get offered the possibility to acquire ITNs. We randomize whether a clinic offers the bed nets for free (treatment condition), or at a small price (control condition)."
  },
  {
    "objectID": "problem_sets/07-solution.html#measures",
    "href": "problem_sets/07-solution.html#measures",
    "title": "Problem set 7",
    "section": "Measures",
    "text": "Measures\n\nBriefly describe your outcome measure. Use a binary outcome (you could, e.g., call it “uptake”, with values “uptake” vs. “no_update”).\n\nOur outcome measure is “uptake”, with values “uptake”, in case a patient acquired an ITN, or “no_update”, in case a patient did not."
  },
  {
    "objectID": "problem_sets/07-solution.html#analystical-procedure",
    "href": "problem_sets/07-solution.html#analystical-procedure",
    "title": "Problem set 7",
    "section": "Analystical Procedure",
    "text": "Analystical Procedure\n\nDescribe exactly which statistical model you will use to evaluate your hypothesis. Insert this model in the below code chunk (the option “evaluate: false” ensures that when rendering the dokument, R inores this code - otherwise it would yield an error, since you haven’t specified any data. Use a linear regression, with the treatment as predictor variable, and uptake as the outcome variable. Since we have a binary outcome, there are other, often more appropriate models than a simple linear regression, but for simplicity, we stick to what you have learned.\n\n\nlm(uptake ~ condition, data = sample)"
  },
  {
    "objectID": "problem_sets/07-solution.html#pariticipants",
    "href": "problem_sets/07-solution.html#pariticipants",
    "title": "Problem set 7",
    "section": "Pariticipants",
    "text": "Pariticipants\n\nIn this section, you describe your participants (where will they be from, how will you recruit them? Be creative, and keep in mind that you want to have a different population than pregnant women in Kenya, as in the reference paper). Importantly, determine your sample size. Assume that the minimal effect you care about is a difference in uptake of 10 percentage points (remember that in the reference study in Kenya, it was 60%, so that seems a conservative lower bound). You want to be able to detect such an effect with a power of 0.8, given a significance threshold of 0.05. Run a power simulation. Refer to the different steps in the guide on power simulation, and the lecture slides of the exercise in the class on linear regression. Take the sample generating function below as a starting point. The final result should be a figure with a power curve. Reference the figure in your text following the Quarto cross-references guidelines.\n\nTo have a different, more generalizable sample, we could try to run our experiment in general (not only prenatal) clinics, on all patients (not only pregnant women), in several countries in sub-Saharan Africa (not only Kenya)1.\n\n# set a seed for reproducibility\nset.seed(239875)\n\n\ngenerate_sample &lt;- function(sample_size){\n  tibble(\n    # an id for each participant\n    id = 1:sample_size,\n      # randomly assign a treatment\n    condition = sample(c(\"free\", \"small_price\"), size = sample_size, replace = TRUE)\n  ) |&gt;\n    # calculate the outcome\n    mutate(\n      # We assume a treatment effect of 10 percentage points, \n      # 95% in the free group and 85% in the control group.\n      # We add a little bit of noise to these average probabilities for each \n      # individual\n      prob = case_when(\n        condition == \"free\" ~ rnorm(sample_size, mean = 0.95, sd = 0.5),\n        condition == \"small_price\" ~ rnorm(sample_size, mean = 0.85, sd = 0.5)\n      ),\n      # Because of the noise, some values might be out of the bounds (probabilites can only range from 0 to 1). \n      # The next line ensures to keep probabilities within [0, 1] bounds. \n      prob = pmin(pmax(prob, 0), 1),\n      # Finally, we can simulate our binary uptake variable based on the noisy probabilities\n      uptake = rbinom(n(), size = 1, prob = prob)\n    )\n}\n\n\nFor the power analysis, you will need to write several functions. Remember to test your function after each step.\n\n\nsample &lt;- generate_sample(sample_size = 1000) \n\nhead(sample)\n\n# A tibble: 6 × 4\n     id condition    prob uptake\n  &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;int&gt;\n1     1 free        0.693      1\n2     2 free        1          1\n3     3 free        0.305      0\n4     4 free        1          1\n5     5 small_price 0.628      1\n6     6 free        1          1\n\n\nNext, we write a function to run our regression model on the sample.\n\ncalculate_regression &lt;- function(sample){\n  \n  # run a regression on the sample \n  p.value &lt;- lm(uptake ~ condition, data = sample) |&gt; \n    tidy() |&gt; \n    filter(term == \"conditionsmall_price\") |&gt; \n    pull(p.value)\n  \n  return(p.value)\n}\n\n# test\n# test_sample &lt;- generate_sample(sample_size = 100)\n# calculate_regression(sample = test_sample)\n\nWe then write a function to simulate multiple samples.\n\ngenerate_samples &lt;- function(n_simulations, sample_size) {\n  \n  # Make an empty vector\n  p.values &lt;- numeric(n_simulations)\n  \n  for (i in 1:n_simulations) {\n    # Draw a sample with the specified size\n    sample &lt;- generate_sample(sample_size) \n    \n    # Get an estimate\n    p.values[i] &lt;-  calculate_regression(sample)\n  }\n  \n  return(p.values)\n}\n# test\n# generate_samples(n_simulations = 100, sample_size = 10)\n\nFor a given sample size, we can calculate statistical power with this funciton.\nFirst, we need a function to calculate power.\n\ncalculate_power &lt;- function(p.values){\n  \n  # get statistical power \n  power &lt;- data.frame(p.values) |&gt; \n    mutate(significant = ifelse(p.values &lt;= 0.5, TRUE, FALSE)) |&gt; \n    summarize(share_significant = sum(significant) / n()) |&gt; \n    pull(share_significant)\n  \n  return(power)\n}\n# test\n# some_p.values &lt;- generate_samples(n_simulations = 100, sample_size = 10)\n# calculate_power(p.values = some_p.values)\n\nWe write a function to run the power analysis for different sample sizes.\n\npower_simulation &lt;- function(sample_size, n_simulations = 1000) {\n  \n  # Generate multiple samples and compute estimates\n  sampled_p.values &lt;- generate_samples(n_simulations, sample_size)\n  \n  # Calculate statistical power\n  power &lt;- calculate_power(sampled_p.values)\n  \n  # Return results\n  return(tibble(\n    sample_size = sample_size,\n    n_simulations = n_simulations,\n    estimated_power = power\n  ))\n}\n# test\n# power_simulation(sample_size = 30, n_simulations = 100)\n\nWe then run the power simulation for a bunch of sample sizes.\n\nsample_sizes &lt;- c(30, 50, 100, 200, 300, 500)\n\n# make an empty data frame\npower_data &lt;- tibble()\n\nfor (i in sample_sizes) {\n  # run power simulation\n  power &lt;- power_simulation(sample_size = i, n_simulations = 1000)\n  \n  power_data &lt;- bind_rows(power_data, power)\n}\n\nWe can then plot the power curve.\n\nggplot(power_data, \n       aes(x = sample_size, y = estimated_power)) +\n  geom_point(color = 'red', size = 1.5) +\n  geom_line(color = 'red', size = 1) + \n  # add a horizontal line at 80%\n  geom_hline(aes(yintercept = .8), linetype = 'dashed') + \n  # Prettify!\n  theme_minimal() + \n  scale_y_continuous(labels = scales::percent, limits = c(0,1)) + \n  labs(title = \"Power Simulation for the treatment effect\",\n       x = 'Sample Size', y = 'Power')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nFigure 1: The Figure statistical power as a function of sample size, given an effect of 10 percentage points, random noise, and an alpha level of 0.05 for statistical significance. We simulated 1000 samples per sample size.\n\n\n\n\n\nOur power simulation (Figure 1) suggests that with 500 participants, we reach our desired power level of 80%."
  },
  {
    "objectID": "problem_sets/07-solution.html#footnotes",
    "href": "problem_sets/07-solution.html#footnotes",
    "title": "Problem set 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOf course, this is quite a bit of wishful thinking, since these things cost a lot of money and are hard to administer. Just take it as an example of the different factors that you might want to think about, in terms of who your population is.↩︎"
  },
  {
    "objectID": "problem_sets/05-solution.html",
    "href": "problem_sets/05-solution.html",
    "title": "Problem set 5",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\n\nRead the survey data.\n\n# Load the survey data from class\npenguins &lt;- read_csv(\"../data/penguins.csv\")\n\nRows: 342 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nGraphs\nWhat is the relationship between penguin weight and bill depth? This plot shows some initial trends:\n\nggplot(data = penguins, \n       aes(x = bill_depth_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\nMake a new plot that colors these points by species. What can you tell about the relationship between bill depth and penguin weight?\n\nggplot(data = penguins, \n       aes(x = bill_depth_mm, y = body_mass_g, color = species)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nIt seems like the longer the bill, the greater the body mass, but only within species. If we ignore the species it looks like greater bill depth is associated with lower body mass.\n\nAdd a geom_smooth() layer to the plot and make sure it uses a straight line (hint: include method=\"lm\" in the function). What does this tell you about the relationship between bill depth and body mass?\n\nggplot(data = penguins, \n       aes(x = bill_depth_mm, y = body_mass_g, color = species)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThis confirms that within different species, there is a positive relationship.\n\nChange the plot so that there’s a single line for all the points instead of one line per species. How does the slope of this single line differ from the slopes of the species specific lines? Why??\n\nggplot(data = penguins, \n       aes(x = bill_depth_mm, y = body_mass_g)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nBy removing the color layer, geom_smooth only draws one line considering all of the data. Glancing over species, there is actually a negative association between bill depth and body mass in the data.\n\nWhat is the relationship between flipper length and body mass? Make another plot with flipper_length_mm on the x-axis, body_mass_g on the y-axis, and points colored by species.\n\nggplot(data = penguins, \n       aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThere is a positive relationship between flipper length and body mass, both within and across species.\n\nFacet (facet_wrap) the plot by island (island). What does this graph tell you ?\n\nggplot(data = penguins,\n       aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  facet_wrap(vars(island))\n\n\n\n\n\n\n\n\n\nThere is a positive relationship between flipper length and body mass, for all species. However, not all species are present on all islands. Of the Gentoo, the penguins with the smalles flipper length still have flipper lengths of the size as the biggest once of the Chinstrap and Adelie.\n\n\n\nRegression\nDoes bill depth predict penguin weight? Run a linear regression (lm()) and interpret the estimate and the p.value. Interpret the result in light of previous plots that you have generated.\n\nmodel_depth_weight &lt;- lm(body_mass_g ~ bill_depth_mm,\n                         data = penguins)\n\ntidy(model_depth_weight)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)      7489.     335.      22.3  1.13e-68\n2 bill_depth_mm    -192.      19.4     -9.87 2.28e-20\n\n\n\nYes, bill depth does predict penguin weight, negatively. A one mm increase in bill depth is associated with approximately 191 gramms less body weight. However, as we saw earlier in the plots, this is only true when comparing across species. Within species the opposite is true. This result is statistically significant, as indicated by the low p-value (smaller than 0.05).\n\nRun different regression analyses for the different species (use filter()) to subset the data frame.\n\n# check different species\ntable(penguins$species)\n\n\n   Adelie Chinstrap    Gentoo \n      151        68       123 \n\n\n\nregression_adelie &lt;- lm(body_mass_g ~ bill_depth_mm, \n                        data = penguins |&gt; \n                          filter(species == \"Adelie\")) \n\nregression_chinstrap &lt;- lm(body_mass_g ~ bill_depth_mm, \n                        data = penguins |&gt; \n                          filter(species == \"Chinstrap\"))\n\nregression_gentoo &lt;- lm(body_mass_g ~ bill_depth_mm, \n                        data = penguins |&gt; \n                          filter(species == \"Gentoo\"))\n\n# we can use the modelsummary package to display the results of all three regressions at once\nmodelsummary::modelsummary(list(\"Adelie\" = regression_adelie, \n                  \"Chinstrap\" = regression_chinstrap, \n                  \"Gentoo\" = regression_gentoo), \n                  statistic = \"p.value\", \n                  stars = TRUE)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Adelie\n                Chinstrap\n                Gentoo\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  -283.279\n                  -36.219\n                  -458.985\n                \n                \n                  \n                  (0.542)\n                  (0.953)\n                  (0.348)\n                \n                \n                  bill_depth_mm\n                  217.152***\n                  204.625***\n                  369.441***\n                \n                \n                  \n                  (&lt;0.001)\n                  (&lt;0.001)\n                  (&lt;0.001)\n                \n                \n                  Num.Obs.\n                  151\n                  68\n                  123\n                \n                \n                  R2\n                  0.332\n                  0.365\n                  0.517\n                \n                \n                  R2 Adj.\n                  0.327\n                  0.356\n                  0.513\n                \n                \n                  AIC\n                  2223.3\n                  976.4\n                  1795.3\n                \n                \n                  BIC\n                  2232.3\n                  983.1\n                  1803.8\n                \n                \n                  Log.Lik.\n                  -1108.647\n                  -485.224\n                  -894.666\n                \n                \n                  RMSE\n                  373.57\n                  303.90\n                  348.89\n                \n        \n      \n    \n\n\n\n\nAs observered earlier in the plots, we find a positive association between bill depth and body mass for all species when analyzed seperately. These results are statistically significant, as indicated by the low p-values (smaller than 0.05)."
  },
  {
    "objectID": "problem_sets/03-solution.html",
    "href": "problem_sets/03-solution.html",
    "title": "Problem set 3",
    "section": "",
    "text": "Read in the separate data files. Make sure you have the tidyverse package loaded.\n\n\n# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# Load the separate datasets\nfellowship &lt;- read_csv(\"../data/The_Fellowship_Of_The_Ring.csv\")\n\nRows: 3 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Film, Species\ndbl (2): Female, Male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntt &lt;- read_csv(\"../data/The_Two_Towers.csv\")\n\nRows: 3 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Film, Species\ndbl (2): Female, Male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrotk &lt;- read_csv(\"../data/The_Return_Of_The_King.csv\")\n\nRows: 3 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Film, Species\ndbl (2): Female, Male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nUse the bind_rows function to merge the three data sets into a single data set. We haven’t seen this function yet, look it up. Call the new merged data frame lotr (for “lord of the rings”).\n\n\n# bind_rows() stacks data frames on top of each other\nlotr &lt;- bind_rows(fellowship, tt, rotk) \n\n\nWe later want to plot gender differences. Have a look at the data. Why is it not yet in a tidy format? Explain. Then use pivot_longer to reshape the data frame by adding two new variables, Gender and Words, to the data frame.\n\n\n# Make this wide data tidy\nlotr &lt;- lotr |&gt; \n  # This is the new way to make data long\n  pivot_longer(cols = c(Female, Male), \n               names_to = \"Gender\", values_to = \"Words\")\n\n\nDoes a certain gender dominate a movie? (Hint: Make a new summary data frame for which you group by Gender and then count sum the words.)\n\n\nsummary_data &lt;- lotr |&gt; \n  group_by(Gender) |&gt; \n  summarise(Words = sum(Words))\n\n\nGraph your summarized data. (Hint: use geom_col and the Words and Gender variables.)\n\n\nggplot(summary_data, \n       aes(x = Gender, y = Words)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nYou’ve just plotted the averages across films. (Hint: Make a new summary data frame for which you group by both Gender and Film and then count sum the words.)\n\n\nsummary_data &lt;- lotr |&gt; \n  group_by(Gender, Film) |&gt; \n  summarise(Words = sum(Words))\n\n`summarise()` has grouped output by 'Gender'. You can override using the\n`.groups` argument.\n\n\n\nTry to make a new plot in which you differentiate between the different films (Hint: use faceting by Gender or Film).\n\n\nggplot(summary_data, \n       aes(x = Gender, y = Words)) +\n  geom_col() + \n  facet_wrap(vars(Film))\n\n\n\n\n\n\n\n\n\nHow about species? Does the dominant species differ on average (don’t differentiate between the three movies here)? (Hint: Proceed just as for Gender in the beginning: make a new summary data frame for which you group by Species and then count sum the words.)\n\n\nsummary_data &lt;- lotr |&gt; \n  group_by(Species) |&gt; \n  summarise(Words = sum(Words))\n\n\nggplot(summary_data, \n       aes(x = Species, y = Words)) +\n  geom_col() \n\n\n\n\n\n\n\n\n\nCreate a plot that visualizes the number of words spoken by species, gender, and film simultaneously. Use the complete tidy lotr data frame. You don’t need to create a new summarized dataset (with group_by(Species, Gender, Film)) because the original data already has a row for each of those (you could make a summarized dataset, but it would be identical to the full version).\n\nYou need to show Species, Gender, and Film at the same time, but you only have two possible aesthetics (x and fill), so you’ll also need to facet by the third. Play around with different combinations (e.g. try x = Species, then x = Film) until you find one that tells the clearest story. For fun, add a labs() layer to add a title and subtitle and caption.\n\nggplot(lotr, \n       aes(x = Species, y = Words, fill = Gender)) +\n  geom_col() + \n  facet_wrap(vars(Film))"
  },
  {
    "objectID": "problem_sets/01-solution.html",
    "href": "problem_sets/01-solution.html",
    "title": "Problem set 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nLearning R\n\n\nRead the data\n\nRead the cars.csv data into R. Make sure to use the correct path (“data/cars.csv”). Name the data frame “cars” when reading it in. You don’t need to understand what all the variables mean.\n\n\ncars &lt;- read_csv(\"../data/cars.csv\")\n\nRows: 234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): manufacturer, model, trans, drv, fl, class\ndbl (5): displ, year, cyl, cty, hwy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nWhat’s the class of the model and the year variable?\n\nclass(cars$model)\n\n[1] \"character\"\n\nclass(cars$year)\n\n[1] \"numeric\"\n\n\n\nSubset the cars data by selecting only rows that correspond to the manufacturer “honda” and that shows only the columns for models and the year. Name that subset “honda_data” and print it.\n\n\nhonda_data &lt;- cars[cars$manufacturer == \"honda\", c(\"model\", \"year\")]\n\n# alternative\nhonda_data &lt;- cars %&gt;%\n  filter(manufacturer == \"honda\") %&gt;%\n  select(model, year)\n\n\n\nMy first plots\n\nYou haven’t learned about plots yet. But to give you a taste for what’s coming, execute the code chunk below and let the magic happen. Make sure your data frame is named “cars” for this to work\n\nA plot on the distance that cars can travel per gallon. Note that we will hide the code when rendering by setting echo: false.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "guides/zotero.html",
    "href": "guides/zotero.html",
    "title": "Citing stuff",
    "section": "",
    "text": "In this guide, I will briefly outline a workflow on citing literature based on RStudio, Quarto and Zotero. It is a workflow that I find very convenient, but there are (many) other possible workflows using the same tools. In contexts outside of this class, you might not want to use Markdown and instead work with Zotero in Word, or GoogleDocs. Luckily, Zotero works very well with these, too, and you find more information on that on the Zotero homepage.\nZotero is a free, open-source citation manager. It makes citing stuff (scientific journal articles, blog posts, news articles, websites, videos and more) a lot easier. It also helps you organize content for research projects. I highly recommend using Zotero for your academic works, even if it is only for a term paper.",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/zotero.html#via-zotero-connector",
    "href": "guides/zotero.html#via-zotero-connector",
    "title": "Citing stuff",
    "section": "Via Zotero Connector",
    "text": "Via Zotero Connector\nOne option is to obtain a reference with one click from a journal website (Figure 1). Imagine, e.g., that you have searched for a scientific article (e.g. via google scholar) and have landed on the journal website. You can try clicking on the Zotero connecter, which will store the elements on the website as a reference in the project folder that you have currently open in Zotero. If you are luck and the journal website provides the relevant meta data, that’s a super easy way to add you reference. If you are even luckier and the article is openly accessible (i.e. not behind a paywall) this method directly adds a pdf, which you can then view in Zotero.\n\n\n\n\n\n\nFigure 1: An examle of using the connector on a journal webiste\n\n\n\nSometimes you might already have a pdf. If that pdf is open in your browser, you can use the connector to store a copy in Zotero (Figure 2). If you are lucky, the pdf comes with the relevant meta-data for Zotero to add a proper citation. If not, this will only add the pdf and you need to rely on another method to add the meta-data.\n\n\n\n\n\n\nFigure 2: An examle of using the connector on a pdf\n\n\n\nWhile often the most convenient option, the connector doesn’t always work, it depends a lot on which meta-data specific websites/pdfs offer.",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/zotero.html#via-google-scholar",
    "href": "guides/zotero.html#via-google-scholar",
    "title": "Citing stuff",
    "section": "Via Google scholar",
    "text": "Via Google scholar\nWhen searching an article on google scholar, the search results often come with pre-formated meta-data for citation. You can export this meta-data as an “EndNote” file (Figure 3). This will be recognized by the Zotero Connector, which then asks you if you want to add it to your library.\n\n\n\n\n\n\nFigure 3: An examle of using the citation export function of Google Scholar",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/zotero.html#via-an-identifier",
    "href": "guides/zotero.html#via-an-identifier",
    "title": "Citing stuff",
    "section": "Via an identifier",
    "text": "Via an identifier\nJust as books have ISBNs (International Standard Book Numbers), scientific research articles have DOIs (Digital Object Identifiers). These numbers uniquely identify a piece of content (not only articles, also e.g., data bases). In Zotero, you can copy-paste these numbers into the respective search bar (Figure 9), and Zotero will access the relevant meta-data.\n\n\n\n\n\n\nFigure 4: An examle of using the Zotero identifier search bar",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/zotero.html#more-details",
    "href": "guides/zotero.html#more-details",
    "title": "Citing stuff",
    "section": "More details",
    "text": "More details\nFor more information on how to cite in quarto, you can also check out these guides:\n\nhttps://posit.co/blog/rstudio-1-4-preview-citations/\nhttps://quarto.org/docs/authoring/citations.html\nhttps://quarto.org/docs/visual-editor/technical.html#citations",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/zotero.html#footnotes",
    "href": "guides/zotero.html#footnotes",
    "title": "Citing stuff",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPersonally, this is the only case in which I use the “Visual” editor. Once I’m done with citing I switch back to the “Source” editor.↩︎\nIt’s great and I use it, but for this class, honestly, don’t bother.↩︎",
    "crumbs": [
      "Guides",
      "Citing stuff"
    ]
  },
  {
    "objectID": "guides/r_projects.html",
    "href": "guides/r_projects.html",
    "title": "RStudio Projects",
    "section": "",
    "text": "One of the most powerful and useful aspects of RStudio is its ability to manage projects.\nWhen you first open R, it is “pointed” at some folder on your computer, and anything you do will be relative to that folder. The technical term for this is a “working directory.”\nWhen you first open RStudio, look in the area right at the top of the Console pane to see your current working directory. Most likely you’ll see something cryptic: ~/\n\n\n\n\n\n\n\n\n\nThat tilde sign (~) is a shortcut that stands for your user directory. On Windows this is C:\\Users\\your_user_name\\; on macOS this is /Users/your_user_name/. With the working directory set to ~/, R is “pointed” at that folder, and anything you save will end up in that folder, and R will expect any data that you load to be there too.\nIt’s always best to point R at some other directory. If you don’t use RStudio, you need to manually set the working directory to where you want it with setwd(), and many R scripts in the wild include something like setwd(\"C:\\\\Users\\\\bill\\\\Desktop\\\\Important research project\") at the beginning to change the directory. THIS IS BAD THOUGH (see here for an explanation). If you ever move that directory somewhere else, or run the script on a different computer, or share the project with someone, the path will be wrong and nothing will run and you will be sad.\nThe best way to deal with working directories with RStudio is to use RStudio Projects. These are special files that RStudio creates for you that end in a .Rproj extension. When you open one of these special files, a new RStudio instance will open up and be pointed at the correct directory automatically. If you move the folder later or open it on a different computer, it will work just fine and you will not be sad.\nRead this super short chapter on RStudio projects to learn how to create and use them\nIn general, you can create a new project by going to File &gt; New Project &gt; New Directory &gt; Empty Project, which will create a new folder on your computer that is empty except for a single .Rproj file. Double click on that file to open an RStudio instance that is pointed at the correct folder.",
    "crumbs": [
      "Guides",
      "RStudio Projects"
    ]
  },
  {
    "objectID": "guides/install.html",
    "href": "guides/install.html",
    "title": "Installing R, RStudio, {tidyverse}, and TinyTeX",
    "section": "",
    "text": "You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.",
    "crumbs": [
      "Guides",
      "Installing R, RStudio, {tidyverse}, and TinyTeX"
    ]
  },
  {
    "objectID": "guides/install.html#posit.cloud",
    "href": "guides/install.html#posit.cloud",
    "title": "Installing R, RStudio, {tidyverse}, and TinyTeX",
    "section": "Posit.cloud",
    "text": "Posit.cloud\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free Posit.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in Posit.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://posit.cloud/ and create a free account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you.",
    "crumbs": [
      "Guides",
      "Installing R, RStudio, {tidyverse}, and TinyTeX"
    ]
  },
  {
    "objectID": "guides/install.html#rstudio-on-your-computer",
    "href": "guides/install.html#rstudio-on-your-computer",
    "title": "Installing R, RStudio, {tidyverse}, and TinyTeX",
    "section": "RStudio on your computer",
    "text": "RStudio on your computer\nPosit.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of Posit.cloud and install all these things locally. This is also important if you want to customize fonts, since Posit.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\n\nInstall R\nFirst you need to install R itself (the engine).\n\nGo to the CRAN (Collective R Archive Network) website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\n\n\n\n\n\n\n\n\n\n\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is 4.3.2) and download it.\n\n\n\n\n\n\n\n\n\n\n\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\n\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\n\n\n\n\n\n\n\n\n\n\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall {tidyverse}\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\n\n\n\n\n\n\n\n\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including {ggplot2}) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\n\n\n\n\n\n\n\n\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall TinyTeX\nWhen you render to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s a smaller version named TinyTeX that automatically deals with differences between macOS and Windows and automatically installs any missing LaTeX packages as needed.\nHere’s how to install TinyTeX so you can create pretty PDFs:\n\nOpen the Terminal panel in RStudio (down in the bottom left corner where the Console panel is; there’s a tab named “Terminal” there)\nType this:\n\nquarto install tinytex",
    "crumbs": [
      "Guides",
      "Installing R, RStudio, {tidyverse}, and TinyTeX"
    ]
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Class 12: Meta Analyses",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "12 - Meta-Analyses"
    ]
  },
  {
    "objectID": "content/12-content.html#slides",
    "href": "content/12-content.html#slides",
    "title": "Class 12: Meta Analyses",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "12 - Meta-Analyses"
    ]
  },
  {
    "objectID": "content/12-content.html#readings",
    "href": "content/12-content.html#readings",
    "title": "Class 12: Meta Analyses",
    "section": "Readings",
    "text": "Readings\nIn case you are curious to learn more about meta-analysis, check out this great (and free) book:\n\nHarrer et al. (2021)\n\nOther things:\n\nInterpreting Cohen’s d Effect Size by Kristoffer Magnusson\nthe PRISMA guidelines for systematic reviews and meta-analyses",
    "crumbs": [
      "Content",
      "12 - Meta-Analyses"
    ]
  },
  {
    "objectID": "content/12-content.html#assignment",
    "href": "content/12-content.html#assignment",
    "title": "Class 12: Meta Analyses",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this session 🎉",
    "crumbs": [
      "Content",
      "12 - Meta-Analyses"
    ]
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Class 10: Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "10 - Scientific Publishing and the Replication Crisis"
    ]
  },
  {
    "objectID": "content/10-content.html#slides",
    "href": "content/10-content.html#slides",
    "title": "Class 10: Scientific Publishing and the Replication Crisis",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "10 - Scientific Publishing and the Replication Crisis"
    ]
  },
  {
    "objectID": "content/10-content.html#readings",
    "href": "content/10-content.html#readings",
    "title": "Class 10: Scientific Publishing and the Replication Crisis",
    "section": "Readings",
    "text": "Readings\nI don’t expect you to read all these, but in case you’re curious, here are some papers mentioned in class:\n\nOpen Science Collaboration (2015)\nSimmons, Nelson, and Simonsohn (2011)\nGould et al. (2025)\nTurner et al. (2008)\n\nFor a refresher on hypothesis testing and statistical power, you could can have a look at the begging of chapter 2 in Lakens (2022)\nSince the lecture did not really cover this, if you want to know what’s wrong with scientific publishing, this old (but gold!) article of the Guardian is a good read. It’s also available as a podcast.",
    "crumbs": [
      "Content",
      "10 - Scientific Publishing and the Replication Crisis"
    ]
  },
  {
    "objectID": "content/10-content.html#data",
    "href": "content/10-content.html#data",
    "title": "Class 10: Scientific Publishing and the Replication Crisis",
    "section": "Data",
    "text": "Data\n\n imaginary_beatle_experiment.csv",
    "crumbs": [
      "Content",
      "10 - Scientific Publishing and the Replication Crisis"
    ]
  },
  {
    "objectID": "content/10-content.html#assignment",
    "href": "content/10-content.html#assignment",
    "title": "Class 10: Scientific Publishing and the Replication Crisis",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this session 🎉",
    "crumbs": [
      "Content",
      "10 - Scientific Publishing and the Replication Crisis"
    ]
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Class 8: Colliders and Confounders",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "08 - Colliders and Confounders"
    ]
  },
  {
    "objectID": "content/08-content.html#slides",
    "href": "content/08-content.html#slides",
    "title": "Class 8: Colliders and Confounders",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "08 - Colliders and Confounders"
    ]
  },
  {
    "objectID": "content/08-content.html#readings",
    "href": "content/08-content.html#readings",
    "title": "Class 8: Colliders and Confounders",
    "section": "Readings",
    "text": "Readings\n\nRohrer (2018)",
    "crumbs": [
      "Content",
      "08 - Colliders and Confounders"
    ]
  },
  {
    "objectID": "content/08-content.html#assignment",
    "href": "content/08-content.html#assignment",
    "title": "Class 8: Colliders and Confounders",
    "section": "Assignment",
    "text": "Assignment\n\nDo the assigned reading from the article above.\nFollow instructions below.\n\nFor this weeks assignment, no coding needs to be done. You can upload your answers as a pdf on Moodle.\n\n\n\n\n\n\nNote\n\n\n\nThe following is a (slightly modified) excerpt from Bergstrom and West (2020):\n\n\n\nIn the 1980s, American university administrators and policy makers were concerned about the prevalence of binge drinking on university campuses. Psychologists, epidemiologists, public health experts, and others searched for ways to stem this epidemic of intemperance. And why not? There are worse places to do fieldwork.\nIn an influential 1986 paper titled “Naturalistic Observations of Beer Drinking among College Students,” psychologist Scott Geller and colleagues looked at factors associated with greater consumption of beer at college pubs.\nWhat are “naturalistic observations”? They are the observations you make of a subject, in this case the college students, in their natural habitat, in this case the pub. We are amused by this detail from the methods section of the paper: “The observers attempted to remain as inconspicuous as possible by sitting at tables and behaving as normal patrons” (emphasis added). Does this mean drinking beer themselves? One must take pains to blend in, after all.\nThe researchers observed the number of beers that each student consumed and recorded whether each was purchased by the glass, the bottle, or the pitcher. Students who drank beer from pitchers drank roughly two to four times as much beer as those who drank their beer by the glass or by the bottle.\n\nAs reports of the study filtered through the popular press and into the broader discussion about alcohol abuse on college campuses, the results were quickly interpreted as “People drink more because beer is consumed in pitchers.” Based on this, people started making prescriptive claims: “We should ban pitchers so that students will drink less.”\n\nExplain why those claims are not warranted, based on the evidence of this study. Make sure to propose an alternative explanation. (If you want to make me really happy, frame things in terms of the vocabulary that we learned in class 😄)\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "08 - Colliders and Confounders"
    ]
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Class 6: Statistical Power",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "06 - Statistical power"
    ]
  },
  {
    "objectID": "content/06-content.html#slides",
    "href": "content/06-content.html#slides",
    "title": "Class 6: Statistical Power",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "06 - Statistical power"
    ]
  },
  {
    "objectID": "content/06-content.html#readings",
    "href": "content/06-content.html#readings",
    "title": "Class 6: Statistical Power",
    "section": "Readings",
    "text": "Readings\n\nThis guide on power simulation",
    "crumbs": [
      "Content",
      "06 - Statistical power"
    ]
  },
  {
    "objectID": "content/06-content.html#assignment",
    "href": "content/06-content.html#assignment",
    "title": "Class 6: Statistical Power",
    "section": "Assignment",
    "text": "Assignment\nThis week’s assignment consists only in replicating all computations done in the guide. Upload your assignment as usual on Moodle.",
    "crumbs": [
      "Content",
      "06 - Statistical power"
    ]
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Class 4: Data visualization",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "04 - Data visualization"
    ]
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Class 4: Data visualization",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "04 - Data visualization"
    ]
  },
  {
    "objectID": "content/04-content.html#readings",
    "href": "content/04-content.html#readings",
    "title": "Class 4: Data visualization",
    "section": "Readings",
    "text": "Readings\n\nChapter 1 in Wickham, Çetinkaya-Rundel, and Grolemund (2023)\nThis short primer by Andrew Heiss on on data visualization basics",
    "crumbs": [
      "Content",
      "04 - Data visualization"
    ]
  },
  {
    "objectID": "content/04-content.html#assignment",
    "href": "content/04-content.html#assignment",
    "title": "Class 4: Data visualization",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nDo the lesson first!\n\n\n\nBefore starting this exercise, make sure you complete the short primer mentioned in the Readings section.\n\n\nFor this exercise you’ll practice grouping, summarizing, and plotting data using the counts of words spoken in the Lord of the Rings trilogy across movie, sex, and fictional species.\n\nAs always, make a new or use an existing R Studio project for your assignment.\nYou’ll need to download these CSV files and put preferably put them in a folder named data in your project folder:\n\n\n The_Fellowship_Of_The_Ring.csv\n The_Return_Of_The_King.csv\n The_Two_Towers.csv\n\n\nRead in the separate data files. Make sure you have the tidyverse package loaded.\nUse the bind_rows function to merge the three data sets into a single data set. We haven’t seen this function yet, look it up. Call the new merged data frame lotr (for “lord of the rings”).\nWe later want to plot gender differences. Have a look at the data. Why is it not yet in a tidy format? Explain. Then use pivot_longer to reshape the data frame by adding two new variables, Gender and Words, to the data frame.\nDoes a certain gender dominate a movie? (Hint: Make a new summary data frame for which you group by Gender and then count sum the words.)\nGraph your summarized data. (Hint: use geom_col and the Words and Gender variables.)\nYou’ve just plotted the averages across films. (Hint: Make a new summary data frame for which you group by both Gender and Film and then count sum the words.)\nTry to make a new plot in which you differentiate between the different films (Hint: use faceting by Gender or Film).\nHow about species? Does the dominant species differ on average (don’t differentiate between the three movies here)? (Hint: Proceed just as for Gender in the beginning: make a new summary data frame for which you group by Species and then count sum the words.)\nCreate a plot that visualizes the number of words spoken by species, gender, and film simultaneously. Use the complete tidy lotr data frame. You don’t need to create a new summarized dataset (with group_by(Species, Gender, Film)) because the original data already has a row for each of those (you could make a summarized dataset, but it would be identical to the full version). You need to show Species, Gender, and Film at the same time, but you only have two possible aesthetics (x and fill), so you’ll also need to facet by the third. Play around with different combinations (e.g. try x = Species, then x = Film) until you find one that tells the clearest story. For fun, add a labs() layer to add a title and subtitle and caption.\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "04 - Data visualization"
    ]
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Class 2: Data manipulation basics",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "02 - Data Manipulation"
    ]
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Class 2: Data manipulation basics",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "02 - Data Manipulation"
    ]
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "Class 2: Data manipulation basics",
    "section": "Readings",
    "text": "Readings\n\nChapters 3 and 5 in Wickham, Çetinkaya-Rundel, and Grolemund (2023)",
    "crumbs": [
      "Content",
      "02 - Data Manipulation"
    ]
  },
  {
    "objectID": "content/02-content.html#assignment",
    "href": "content/02-content.html#assignment",
    "title": "Class 2: Data manipulation basics",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nNote\n\n\n\nIMPORTANT: This looks super long and like a lot of work, but it’s mostly repeating and applying things we’ve seen in the lecture. Much of it is just reading along.\nRemember, if you’re struggling, please talk to me. Otherwise I can’t know. Work with classmates too. Don’t suffer in silence!\n\n\n\nGetting started\nYou’ll be doing all your R work in Quarto this time (and from now on). You should use an RStudio Project to keep your files well organized (either on your computer or on Posit.cloud). Either create a new project for this exercise only, or make a project for all your work in this class (revisit the guide on Rprojects for a refresher).\nYou’ll need to download these two CSV files and put preferably put them in a folder named data in your project folder:\n\n breed_rank.csv\n breed_traits.csv\n\nCreate a quarto file for your assignment. Use separate code chunks for each task and explain before each code chunk what the task was.\nIn the end, the structure of your project directory should look something like this:\nyour-project-name\n├── data\n│   ├── breed_rank.csv\n│   └── breed_traits.csv\n├── your-project-name.Rproj\n└── your-name_problem-set-2.qmd\nThe data we’re using for today’s workshop comes from #TidyTuesday, a weekly social data project based on the tidyverse ecosystem. The GitHub repo hosts many interesting data sets to practice with, and this particular data set comes from the American Kennel Club.\nThe first data set, breed_rank, lists the popularity rankings over time for 195 different dog breeds (many of the snippets shown throughout are truncated for the purposes of display).\n\nbreed_rank\n\n\n\n\n\n\n\nBreed\n2013 Rank\n2014 Rank\n2015 Rank\n2016 Rank\n2017 Rank\n2018 Rank\n2019 Rank\n2020 Rank\n\n\n\n\nRetrievers (Labrador)\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFrench Bulldogs\n11\n9\n6\n6\n4\n4\n4\n2\n\n\nGerman Shepherd Dogs\n2\n2\n2\n2\n2\n2\n2\n3\n\n\nRetrievers (Golden)\n3\n3\n3\n3\n3\n3\n3\n4\n\n\n\n\n\n\n\n\nThe second data set, breed_traits, has information on 16 different traits, classified from 1 to 5, for those 195 dog breeds.\n\nbreed_traits\n\n\n\n\n\n\n\nBreed\nAffectionate With Family\nGood With Young Children\nGood With Other Dogs\nShedding Level\n\n\n\n\nRetrievers (Labrador)\n5\n5\n5\n4\n\n\nFrench Bulldogs\n5\n5\n4\n3\n\n\nGerman Shepherd Dogs\n5\n5\n3\n4\n\n\nRetrievers (Golden)\n5\n5\n5\n4\n\n\n\n\n\n\n\n\n\n\nRead the data\nIt is good coding practice to load all required packages at the top of your quarto file (but below the yaml header), in a separate codechunk. For this problem set, you’ll need to load only the tidyverse package. Make a code-chunk in which you read the data, using the read_csv() function from the readr package (loaded as part of the tidyverse!).\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\n\n\nClean the data\nCheck the names of the data sets, using the names() function\nPer the tidyverse style guide, variable names should use snake case—lower case with underscores between words. This helps with consistency and readability, but it’s also technically easier, as any variable names that start with numbers and/or have spaces need to be referred to within `back ticks`. It’s easier to refer to a variable with shedding_level instead of `Shedding Level`, and thankfully we have a function to easily rename all of those variables instead of doing it by hand.\nUnfortunately…that function does not live within the tidyverse! It’s the only such function we’ll be highlighting during this workshop, but it is so helpful that it has to be included. The function comes from the janitor package. Use the console to install the package (remember, this needs to be done only once per computer!). Alternatively, you can also use the “Packages” panel in RStudio to install it. Load the package in the same way you loaded the tidyverse package before.\n\nlibrary(janitor)\n\nCopy-paste the code below into your quarto file. In the code, the first line uses the assignment operator &lt;- to “save as” our breed_traits data set. We could give it another name and save it as something else, but for this purpose we’re going to overwrite it. The second line applies the clean_names() function.\n\n\n\n\n\n\nNote!\n\n\n\nA helpful tip on notation: once a package has been loaded with library, you can use the function by itself, like you see here with clean_names(). If you don’t want to load the package, you can eliminate that line and instead refer to the function along with its package name, such as janitor::clean_names(). (The package still has to be installed, however.)\n\n\n\nbreed_traits &lt;- breed_traits |&gt; \n  clean_names()\n\nThe clean_names() function neatly converts all variable names to snake case, as shown below.\n\n\n\n\n\n\nbreed\naffectionate_with_family\ngood_with_young_children\n\n\n\n\nRetrievers (Labrador)\n5\n5\n\n\nFrench Bulldogs\n5\n5\n\n\n\n\n\n\n\n\n\n\nManipulate the data using dplyr\nUse group_by(), summarize() and n() on the cleaned (!) breed_traits data frame to find out how many observations there are per different value of shedding_level.\nYour output should look like this:\n\n\n# A tibble: 6 × 2\n  shedding_level     n\n           &lt;dbl&gt; &lt;int&gt;\n1              0     1\n2              1    27\n3              2    41\n4              3   109\n5              4    16\n6              5     1\n\n\nFor this kind of easy summary, there is even a built-in dplyr function that achieves the same result: count()\n\nbreed_traits |&gt; \n  count(shedding_level)\n\nNote that this piece of code does not have an assignment operator! We are applying the count() function to the breed_traits data set, but the results would appear in your console and would not be saved anywhere. This is useful whenever you don’t need to save the output.\nThe output suggests that 109 breeds have a value of 3, 41 breeds have a value of 2, etc. Unfortunately, we have a value of zero, and we know that these variables should have a value of 1, 2, 3, 4, or 5. This is likely an error in the data that should be removed.\nUse the filter() function, which keeps or discards observations (rows), to remove all records with a shedding_level value of zero (and we know from our count() output above that there should be only one such observation). As above, overwrite the breed_traits data frame with the new, filtered version.\nYou can check if your operation was successful by running breed_traits |&gt; count(shedding_level) again: You should now see that zero is no longer a value of that variable.\nLet’s make a combined score of how untidy each of the dog breeds is and use three variables for that score: shedding_level, coat_grooming_frequency and drooling_level. Since those traits are classified from 1 to 5 for each breed, with a higher score denoting a higher level of untidiness, we can add up the scores for all three traits to create a new variable. Use the mutate() function to create a new variable, untidy_score, which is the sum of our three traits of interest. Store the results in a new data frame called untidy_scores (using the assignment operator &lt;- ). Use the select() function, another dplyr verb, to only select two variables into this new data frame: untidy_scores and breed\nThe new data set now consists of the untidy_score for 194 breeds (we had 195 until we dropped the Plott Hounds) and looks like this:\n\n\n\n\n\n\nbreed\nuntidy_score\n\n\n\n\nRetrievers (Labrador)\n8\n\n\nFrench Bulldogs\n7\n\n\nGerman Shepherd Dogs\n8\n\n\nRetrievers (Golden)\n8\n\n\nBulldogs\n9\n\n\n\n\n\n\n\n\nThe arrange() function can be useful to quickly sort your data set based on the value of any selected variable(s). arrange() defaults to ascending order, but you can specify descending order by wrapping the variable name within desc(), as seen in the code on the right. Try to order the data frame such that the untidiest breed is on the top, and the tidiest on the bottom.\nThe result should look like this:\n\n\n\n\n\n\nbreed\nuntidy_score\n\n\n\n\nBernese Mountain Dogs\n11\n\n\nLeonbergers\n11\n\n\nNewfoundlands\n10\n\n\nBloodhounds\n10\n\n\nSt. Bernards\n10\n\n\nOld English Sheepdogs\n10\n\n\n\n\n\n\n\n\n\n\nTidying the data\nWe now know that Bernese Mountain Dogs are among the untidiest of all: they have the highest score of 11. So far, we’ve been working with the breed_traits data, but we have a whole other data set, breed_ranks, showing the popularity of different breeds across several years.\n\n\n\n\n\n\nBreed\n2013 Rank\n2014 Rank\n2015 Rank\n2016 Rank\n2017 Rank\n2018 Rank\n2019 Rank\n2020 Rank\n\n\n\n\nBernese Mountain Dogs\n32\n32\n29\n27\n25\n22\n23\n22\n\n\n\n\n\n\n\n\nRemember from the class that the tidyverse is opinionated on the topic of tidy data. How does this this data set fail to meet the criteria for tidy data? Explain.\n\nThere are three interrelated rules which make a dataset tidy:\n\n1. Each variable must have its own column.\n2. Each observation must have its own row.\n3. Each value must have its own cell.\n\nWe have a year and a rank variable, but neither of these variables have their own column. Shown above is one observation, by dog breed. But that \"one\" observation is actually eight separate observations: the rank in 2013, the rank in 2014, etc. Each observation needs to have its own row.\n\nThe current structure of breed_ranks is in a wide format, and we need it to be in a long format. Create a new data frame called ranks_pivoted based on breed_rank. Use pivot_longer() to create two new variables, year and rank. Remember that the function has three arguments: the columns we want to pivot (remember we need to use back ticks because these variable names have spaces in them), the name for the new column consisting of the previous column headers, and the name for the new column consisting of the previous column values.\nThe output should look like below. This data is now tidy, with each observation (e.g., the rank in 2013) in its own row and separate columns for each variable.\n\n\n\n\n\n\nBreed\nyear\nrank\n\n\n\n\nBernese Mountain Dogs\n2013 Rank\n32\n\n\nBernese Mountain Dogs\n2014 Rank\n32\n\n\nBernese Mountain Dogs\n2015 Rank\n29\n\n\nBernese Mountain Dogs\n2016 Rank\n27\n\n\nBernese Mountain Dogs\n2017 Rank\n25\n\n\nBernese Mountain Dogs\n2018 Rank\n22\n\n\nBernese Mountain Dogs\n2019 Rank\n23\n\n\nBernese Mountain Dogs\n2020 Rank\n22\n\n\n\n\n\n\n\n\nLet’s do some more cleaning. The rename() function makes it easy to change the names of variables (the new name comes first, followed by the original)—we can change Breed to breed to match our other data set. And the parse_number() function from readr allows us to pull out the integer from our year column. This is an example of how you can use mutate() to rewrite existing variables in addition to creating new ones. Just copy-paste this code into your project.\n\nranks_pivoted &lt;- ranks_pivoted |&gt; \n  rename(breed = Breed) |&gt; \n  mutate(year = parse_number(year))\n\n\n\n\n\n\n\nbreed\nyear\nrank\n\n\n\n\nBernese Mountain Dogs\n2013\n32\n\n\nBernese Mountain Dogs\n2014\n32\n\n\nBernese Mountain Dogs\n2015\n29\n\n\nBernese Mountain Dogs\n2016\n27\n\n\nBernese Mountain Dogs\n2017\n25\n\n\nBernese Mountain Dogs\n2018\n22\n\n\nBernese Mountain Dogs\n2019\n23\n\n\nBernese Mountain Dogs\n2020\n22\n\n\n\n\n\n\n\n\nOkay but..what was that all that tidying good for?\nImagine you have this research question: How has the popularity ranking of Bernese Mountain Dogs has shifted over time? Our mew, appropriately tidy data allows us to plot an answer to that question. You haven’t learned how to make plots with R yet, but there are some explanations to accompany the example below.\nFirst, we want to filter() our data, because we’re only interested in Bernese Mountain Dogs, and our new ranks_pivoted data frame contains all the breeds, the code below starts with a filter() statement. You could use filter(breed == \"Bernese Mountain Dogs\"), but perhaps you don’t want to type all that out. The stringr package (part of the core tidyverse) has many functions for dealing with string (text) data, and str_detect() is among the most useful. It returns TRUE or FALSE as to whether the variable you select (the first argument of the function) contains the string you provide (the second argument of the function). This function within a function will filter to only the observations for which our str_detect expression is TRUE. Use a combination of filter() and str_detect() to reduce the data set to only Bernese Mountain Dogs.\nThe ggplot function assigns year to the x-axis and rank to the y-axis. The label = rank argument indicates that we want the rank variable to appear as a label. Then, to define the plot, we add a geom_point layer for dots as well as a geom_text layer to add the labels. The vjust argument within that function specifies the desired vertical justification for the labels to place them below the dots. Copy-paste the code below into your project.\n\nranks_pivoted |&gt;\n  ggplot(aes(x = year, y = rank, label = rank)) +\n  geom_point(size = 3) +\n  geom_text(vjust = 2)\n\n\n\n\n\n\n\n\nMore on plots next week. That’s it, time to render your assignment, either as a .pdf or a .html file. Use the “Render” menu:\n\n\n\n\n\n\n\n\n\nUpload the rendered document in the Homework section on Moodle, under “Assignment 2”.\n🎉 Party! 🎉\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "02 - Data Manipulation"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Class 1: Introduction to R, Rstudio and Quarto",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "01 - Introduction to R, RStudio and Quarto"
    ]
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Class 1: Introduction to R, Rstudio and Quarto",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "01 - Introduction to R, RStudio and Quarto"
    ]
  },
  {
    "objectID": "content/01-content.html#data",
    "href": "content/01-content.html#data",
    "title": "Class 1: Introduction to R, Rstudio and Quarto",
    "section": "Data",
    "text": "Data\n\n ligue1.csv",
    "crumbs": [
      "Content",
      "01 - Introduction to R, RStudio and Quarto"
    ]
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "Class 1: Introduction to R, Rstudio and Quarto",
    "section": "Readings",
    "text": "Readings\n\nChapters 2, 6 and 7 in Wickham, Çetinkaya-Rundel, and Grolemund (2023)",
    "crumbs": [
      "Content",
      "01 - Introduction to R, RStudio and Quarto"
    ]
  },
  {
    "objectID": "content/01-content.html#assignment",
    "href": "content/01-content.html#assignment",
    "title": "Class 1: Introduction to R, Rstudio and Quarto",
    "section": "Assignment",
    "text": "Assignment\n\nTask 1\nGet familiar with the syllabus of this course.\n\n\nTask 2\nRead the guide “Welcome to R, RStudio, and the tidyverse” on installation and install R, Rstudio, tidyverse (we’ll talk more about that soon) and tinytex.\n\n\nTask 3\nRead the guide on Rprojects, including the reference to this short chapter.\n\n\nTask 4\n\nCreate an RStudio Project.\nCreate a folder named “data” in the project folder you just made.\nDownload this CSV file and place it in that folder:\n\n\n cars.csv\n\n\nIn RStudio, go to “File” &gt; “New File…” &gt; “Quarto Document…” and click “OK” in the dialog without changing anything.\nDelete all the placeholder text in that new file and replace it by copy-pasting this:\n\n---\ntitle: \"Problem set 1\"\nauthor: \"Put your name here\"\nformat: \n  html:\n    toc: true\n  pdf:\n    toc: true\n  docx:\n    toc: true\n---\n\n```{r packages}\nlibrary(tidyverse)\n```\n\n# Learning R\n\n[Give me some Feedback on how the this first class went.]\n\n[WRITE SOMETHING HERE LIKE \"It was not so hard and I managed to get it all done\" or whatever.]\n\n# Read the data\n\n&gt; Read the `cars.csv` data into R. Make sure to use the correct path (\"data/cars.csv\"). Name the data frame \"cars\" when reading it in. You don't need to understand what all the variables mean. \n\n[PUT CHUNK HERE]\n\n# What's the class of the `model` and the `year` variable?\n\n[PUT CHUNK HERE]\n\n&gt; Subset the cars data by selecting only rows that correspond to the manufacturer \"honda\" and that shows only the columns for models and the year. Name that subset \"honda_data\" and print it. \n\n[PUT CHUNK HERE] \n\n# My first plots\n\n&gt; You haven't learned about plots yet. But to give you a taste for what's coming, execute the code chunk below and let the magic happen. Make sure your data frame is named \"cars\" for this to work\n\nA plot on the distance that cars can travel per gallon. Note that we will hide the code when rendering by setting `echo: false`.\n\n```{r plot-data}\n#| echo: false\nggplot(cars, aes(x = hwy)) +\ngeom_histogram() +\nlabs(\ntitle = \"A Histogram\",\nx = \"Higway MPG*\", \ncaption = \"*miles per gallon, is the distance, measured in miles, that a car can travel per gallon of fuel.\"\n)\n```\n\nSave the Quarto file with some sort of name (without any spaces!)\nYour project folder should look something like this:\n\n\n\n\n\n\n\n\n\n\n\n\nTask 5\nWork with R:\n\nRemove all the place holder text indicated by [ ].\n\n\n\n\n\n\n\n\n\n\n\nFollow the instructions for the three chunks of code.\nRender your document, either as a .pdf or a .html file. Use the “Render” menu:\n\n\n\n\n\n\n\n\n\n\n\nUpload the rendered document in the Homework section on Moodle, under “Assignment 1”.\n🎉 Party! 🎉\n\n\n\n\n\n\n\nTip\n\n\n\nYou’ll be doing this same process for all your future problem sets. Each problem set will involve a Quarto file. You can either create a new RStudio Project directory for all your work:\n\n\n\n\n\n\n\n\n\nOr you can create individual projects for each assignment and project:\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "01 - Introduction to R, RStudio and Quarto"
    ]
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Class 3: Variables, Distributions and Summary Statistics",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "03 - Variables, Distributions, Summary Statistics"
    ]
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Class 3: Variables, Distributions and Summary Statistics",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "03 - Variables, Distributions, Summary Statistics"
    ]
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Class 5: Statistical Inference",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "05 - Statistical inference"
    ]
  },
  {
    "objectID": "content/05-content.html#slides",
    "href": "content/05-content.html#slides",
    "title": "Class 5: Statistical Inference",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "05 - Statistical inference"
    ]
  },
  {
    "objectID": "content/05-content.html#readings",
    "href": "content/05-content.html#readings",
    "title": "Class 5: Statistical Inference",
    "section": "Readings",
    "text": "Readings\n\nThis short guide on simulating data",
    "crumbs": [
      "Content",
      "05 - Statistical inference"
    ]
  },
  {
    "objectID": "content/05-content.html#assignment",
    "href": "content/05-content.html#assignment",
    "title": "Class 5: Statistical Inference",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nImportant\n\n\n\nBefore starting this exercise, make sure you read the guide on simulations.\n\n\n\nFill out this spreadsheet with your name, distance to school, and whether you prefer cats or dogs\n\n\n\n\n\n\n\nWarning\n\n\n\nBe very careful in how you fill out the sheet as in the first example row (otherwise it will be a point to analyze later for everyone).\n\ndistance to school: use the exact value in kilometers, with decimals indicated by .\npreference for cats/dogs: write either “cats” or “dogs”, nothing else (got to make a choice, sorry)\n\n\n\nAre people who prefer cats living further away from University? This will be your research question for the assignment.\n\nOnce everyone has filled out the spreadsheet, download the data and read it into R. As always, make a new or use an existing R Studio project for your assignment.\nComplete the following steps\n\n\nStep 1: Calculate an estimate based on your sample\nStep 2: Use simulation to invent a world where the true effect is null.\n\nSimulate 1000 samples with the same sample size that your estimate is based on. Store the estimates of this simulation in a vector called sampling_distribution.\n\nStep 3: Plot how well this estimate fits into your null world.\nStep 4: Calculate the probability that your estimate could exist in the null world.\nUse the standard deviation of your sampling_distribution to transform your initial estimate in a z-value. Based on this, calculate the p-value.\nStep 5: Decide if your estimate is statistically significant.\nUse a significance threshold (the value at which you consider your estimate sufficiently unlikely to have occurred in the Null World) of 0.05\n\n\nIs this result surprising to you or not? Explain.\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "05 - Statistical inference"
    ]
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Class 7: Linear Regression",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "07 - Linear Regression"
    ]
  },
  {
    "objectID": "content/07-content.html#slides",
    "href": "content/07-content.html#slides",
    "title": "Class 7: Linear Regression",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "07 - Linear Regression"
    ]
  },
  {
    "objectID": "content/07-content.html#readings",
    "href": "content/07-content.html#readings",
    "title": "Class 7: Linear Regression",
    "section": "Readings",
    "text": "Readings\n\nWatch this video on the main ideas of Linear Regression and Least Squares",
    "crumbs": [
      "Content",
      "07 - Linear Regression"
    ]
  },
  {
    "objectID": "content/07-content.html#assignment",
    "href": "content/07-content.html#assignment",
    "title": "Class 7: Linear Regression",
    "section": "Assignment",
    "text": "Assignment\nFor this week’s assignment you’ll be working with penguin data.\n\n\n\nCute penguins\n\n\nBetween 2007 and 2009, researchers collected data on penguins in three islands in the Palmer Archipelago in Antarctica: Biscoe, Dream, and Torgersen. The penguins dataset has data for 342 penguins from 3 different species: Chinstrap, Gentoo, and Adélie. It includes the following variables:\n\nspecies: The penguin’s species (Chinstrap, Gentoo, and Adélie)\nisland: The island where the penguin lives (Biscoe, Dream, and Torgersen)\nbill_length_mm: The length of the penguin’s bill, in millimeters (distance from the penguin’s face to the tip of the bill)\nbill_depth_mm: The depth of the penguin’s bill, in millimeters (height of the bill; distance from the bottom of the bill to the top of the bill)\nflipper_length_mm: The length of the penguin’s flippers, in millimeters\nbody_mass_g: The weight of the penguin, in grams\nsex: The sex of the penguin\nyear: The year the observation was made\n\n\nAs always, make a new or use an existing R Studio project for your assignment.\nDownload the penguin data set and load it into your quarto script.\n\n\n penguins.csv\n\n\nGraphs\n\n#|echo: false\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nWhat is the relationship between penguin weight and bill depth? Plot bill depth (bill_depth_mm) on the x-axis and body mass (body_mass_g) on the y-axis. Use geom_point()\nMake a new plot that colors these points by species. What can you tell about the relationship between bill depth and penguin weight?\nAdd a geom_smooth() layer to the plot and make sure it uses a straight line (hint: include method=\"lm\" in the function). What does this tell you about the relationship between bill depth and body mass?\nChange the plot so that there’s a single line for all the points instead of one line per species. How does the slope of this single line differ from the slopes of the species specific lines? Why??\nWhat is the relationship between flipper length and body mass? Make another plot with flipper_length_mm on the x-axis, body_mass_g on the y-axis, and points colored by species.\nFacet (facet_wrap) the plot by island (island). What does this graph tell you ?\n\n\n\nRegression\n\nDoes bill depth predict penguin weight? Run a linear regression (lm()) and interpret the estimate and the p.value. Interpret the result in light of previous plots that you have generated.\nRun different regression analyses for the different species (use filter()) to subset the data frame.\n\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "07 - Linear Regression"
    ]
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Class 9: RCTs and Validity",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "09 - RCTs and Validity"
    ]
  },
  {
    "objectID": "content/09-content.html#slides",
    "href": "content/09-content.html#slides",
    "title": "Class 9: RCTs and Validity",
    "section": "",
    "text": "The slides are available online as an HTML file. You can also download them in a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides",
    "crumbs": [
      "Content",
      "09 - RCTs and Validity"
    ]
  },
  {
    "objectID": "content/09-content.html#readings",
    "href": "content/09-content.html#readings",
    "title": "Class 9: RCTs and Validity",
    "section": "Readings",
    "text": "Readings\n\nDattani (2022)",
    "crumbs": [
      "Content",
      "09 - RCTs and Validity"
    ]
  },
  {
    "objectID": "content/09-content.html#data",
    "href": "content/09-content.html#data",
    "title": "Class 9: RCTs and Validity",
    "section": "Data",
    "text": "Data\n\n village_randomized.csv",
    "crumbs": [
      "Content",
      "09 - RCTs and Validity"
    ]
  },
  {
    "objectID": "content/09-content.html#assignment",
    "href": "content/09-content.html#assignment",
    "title": "Class 9: RCTs and Validity",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this session 🎉",
    "crumbs": [
      "Content",
      "09 - RCTs and Validity"
    ]
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Class 11: Writing a Preregistration",
    "section": "",
    "text": "There are no slides for this class. You’ll have the in-class hours to work on this week’s assignment. To be able to write your preregistration as a reproducible report, the guides listed below will help you with citations and cross-references for figures.",
    "crumbs": [
      "Content",
      "11 - Writing a Preregistration"
    ]
  },
  {
    "objectID": "content/11-content.html#readings",
    "href": "content/11-content.html#readings",
    "title": "Class 11: Writing a Preregistration",
    "section": "Readings",
    "text": "Readings\n\nGuide on using Zotero\nA Guide by Posit on how to cross-reference in Quarto\n\nNote that there are many different templates for preregistrations, see for example templates on the Open Science Framework (OSF). You won’t need these for the assignment below, but might want to come back to them when one day you conduct research and want to write a preregistration.",
    "crumbs": [
      "Content",
      "11 - Writing a Preregistration"
    ]
  },
  {
    "objectID": "content/11-content.html#assignment",
    "href": "content/11-content.html#assignment",
    "title": "Class 11: Writing a Preregistration",
    "section": "Assignment",
    "text": "Assignment\nThis week’s assignment is about Malaria and draws on materials from J-PAL (Abdul Latif Jameel Poverty Action Lab)1, a well-known research institution that seeks to reduce poverty around the globe.\n\nIntroduction\nMalaria is one of the world’s foremost public health concerns. In 2023, there were almost 263 million estimated malaria cases, of which 569,000 resulted in death. While there are 83 malaria endemic countries, the majority of cases occur in sub-Saharan Africa (see the 2024 WHO Malaria report). Malaria is associated with poverty: the poor are most affected, potentially because they have reduced access to medical services and information, and can’t avoid working in malaria epidemic areas. Even if it does no lead to death, malaria can have serious consequences, both in terms of health and economic situation. Fighting Malaria is therefor an important public policy goal. One “core intervention” to prevent Malaria infections are insecticide-treated nets (ITNs).\nEconomists have debated whether ITNs should be distributed for free, or at a small price. Charging a small price, according to some theories, might be expected to encourage the use of malaria bed nets–a bit as if paying a gym membership makes you go to the gym, simply because you paid for it (see e.g. Thaler 1980). However, past research has shown that it is more effective to distribute the nets for free: In an RCT, Cohen and Dupas (2010) let prenatal clinics distribute ITNs to pregnant women. In some of clinics–randomly selected–the bed nets were for free. In others, they were charged a small price. Contrary to what proponents of pricing would have predicted, the study found that those who paid a little did not use bed nets more than those who got it for free, nor were there any differences in health. There was, however, a crucial difference: Making the bed nets available even at a small price drastically reduced the number of women who got one (by almost 60 percentage points, from 99% in the free group to 41 percent in the small price group).\nThe aim of your study is to test whether this effect of reducing uptake replicates in a slightly different context (say, another country, and not only pregnant women but a larger population). Your treatment consists in handing out ITNs for free (treatment group), compared to making them available for people to purchase at a small cost (control group).\n\n\nYour task: Write a preregistration for an RCT\nAs for all homework assignments, make an R Studio project. Copy-paste this quarto template for your preregistration. The template already includes the relevant sections that you will have to fill out. You’ll find more detailed instructions within each section.\n\n\n\n\n\n\nTip\n\n\n\nOne general tip for your assignments: Note how the yaml header of the template contains the line self-contained: true. Without this line, figures and tables only display when the file is opened from inside your project. With this option enabled, you can just share the file by itself and everything will display.\n\n\n\n\nSolution\n\n\n\n\n\n\nTip\n\n\n\nHere is a solution for the assignment",
    "crumbs": [
      "Content",
      "11 - Writing a Preregistration"
    ]
  },
  {
    "objectID": "content/11-content.html#footnotes",
    "href": "content/11-content.html#footnotes",
    "title": "Class 11: Writing a Preregistration",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nsee e.g. here for a summary on malaria prevention↩︎",
    "crumbs": [
      "Content",
      "11 - Writing a Preregistration"
    ]
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Class 13: How to Read and Present a Scientific Paper",
    "section": "",
    "text": "There are no slides for this class. You will need to work on your group presentations (more information to come)",
    "crumbs": [
      "Content",
      "13 - How to Read and Present a Scientific Paper"
    ]
  },
  {
    "objectID": "content/13-content.html#readings",
    "href": "content/13-content.html#readings",
    "title": "Class 13: How to Read and Present a Scientific Paper",
    "section": "Readings",
    "text": "Readings\nFor your presentations, you need to read the papers you have been assigne (see next section). You can find PDFs for all papers on Moodle.",
    "crumbs": [
      "Content",
      "13 - How to Read and Present a Scientific Paper"
    ]
  },
  {
    "objectID": "content/13-content.html#assignment",
    "href": "content/13-content.html#assignment",
    "title": "Class 13: How to Read and Present a Scientific Paper",
    "section": "Assignment",
    "text": "Assignment\nFor this week’s assignment, you have been randomly assigned to read one of 5 papers (see below). Your assignment is to prepare group a presentation on your paper.\n\n\nCode\nnames &lt;- c(\n  \"Jiwoo\", \"Arthur\", \"Justin\", \"Tom\", \"Alice C.\", \"Agathe\", \"Lisa\", \"Jeanne\",\n  \"Valentine\", \"Micaela\", \"Assya\", \"Cyriac\", \"Alice G.\", \"Thelma\", \"Titouan\",\n  \"Maho\", \"Selma\", \"Lucas\", \"Olga\", \"Eloïse\", \"Josephine\", \"Rivka\", \"Damian\",\n  \"Candice\", \"Marie\", \"Mael\", \"Ariane\", \"Camille\", \"Etienne\", \"Anitha\"\n)\n\n# define groups\ntexts &lt;- tribble(~group, ~text,\n                  1, \"Simonsohn, U., Simmons, J., & Nelson, L. D. (2022). \\n Above averaging in literature reviews. \\n + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43. \n\", \n                  2, \"Mertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). \\n The effectiveness of nudging.\n\", \n                  3, \"dos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., \\n Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). \\n Impact of a nudging intervention and factors associated with vegetable dish choice.\n\", \n                  4, \"Bacon, L., & Krpan, D. (2018). \\n (Not) Eating for the environment. \n\", \n                  5, \"Tavernier, R., & Adam, E. K. (2017). \\n Text message intervention improves objective sleep hours among adolescents.\n\", \n                  6, \"Diliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). \\n Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal. \n\")\n\n\n# build data frame to which names can be assigned\ngroups_empty &lt;- crossing(texts, spot_by_group = 1:5) %&gt;% \n  mutate(row_number = 1:nrow(.))\n\n# random group allocation\n\n## make reproducible\nset.seed(2025)\n\n# randomly shuffle order of names \nnames_random_order &lt;- tibble(name = sample(names, length(names))) %&gt;% \n  mutate(row_number = 1:nrow(.))\n\n# pair with groups\nrandom_groups &lt;- right_join(groups_empty, names_random_order, by = \"row_number\") %&gt;% \n  select(group, name, text, -c(spot_by_group, row_number))\n\nrandom_groups %&gt;%\n  kable(escape = FALSE, col.names = c(\"Group\", \"Name\", \"Text\")) %&gt;%\n  kable_styling(full_width = FALSE, position = \"left\", font_size = 11)\n\n\n\n\n\nGroup\nName\nText\n\n\n\n\n1\nAlice G.\nSimonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43.\n\n\n1\nCyriac\nSimonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43.\n\n\n1\nTom\nSimonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43.\n\n\n1\nMael\nSimonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43.\n\n\n1\nJiwoo\nSimonsohn, U., Simmons, J., & Nelson, L. D. (2022). Above averaging in literature reviews. + [105] Meaningless Means #1: The Average Effect of Nudging Is d = .43.\n\n\n2\nDamian\nMertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging.\n\n\n2\nMicaela\nMertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging.\n\n\n2\nAnitha\nMertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging.\n\n\n2\nSelma\nMertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging.\n\n\n2\nEtienne\nMertens, S., Herberz, M., Hahnel, U. J. J., & Brosch, T. (2022). The effectiveness of nudging.\n\n\n3\nCamille\ndos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). Impact of a nudging intervention and factors associated with vegetable dish choice\n\n\n3\nAssya\ndos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). Impact of a nudging intervention and factors associated with vegetable dish choice\n\n\n3\nThelma\ndos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). Impact of a nudging intervention and factors associated with vegetable dish choice\n\n\n3\nAlice C.\ndos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). Impact of a nudging intervention and factors associated with vegetable dish choice\n\n\n3\nMaho\ndos Santos, Q., Perez-Cueto, F. J. A., Rodrigues, V. M., Appleton, K., Giboreau, A., Saulais, L., Monteleone, E., Dinnella, C., Brugarolas, M., & Hartwell, H. (2020). Impact of a nudging intervention and factors associated with vegetable dish choice\n\n\n4\nTitouan\nBacon, L., & Krpan, D. (2018). (Not) Eating for the environment.\n\n\n4\nMarie\nBacon, L., & Krpan, D. (2018). (Not) Eating for the environment.\n\n\n4\nAriane\nBacon, L., & Krpan, D. (2018). (Not) Eating for the environment.\n\n\n4\nJosephine\nBacon, L., & Krpan, D. (2018). (Not) Eating for the environment.\n\n\n4\nValentine\nBacon, L., & Krpan, D. (2018). (Not) Eating for the environment.\n\n\n5\nAgathe\nTavernier, R., & Adam, E. K. (2017). Text message intervention improves objective sleep hours among adolescents.\n\n\n5\nJeanne\nTavernier, R., & Adam, E. K. (2017). Text message intervention improves objective sleep hours among adolescents.\n\n\n5\nJustin\nTavernier, R., & Adam, E. K. (2017). Text message intervention improves objective sleep hours among adolescents.\n\n\n5\nCandice\nTavernier, R., & Adam, E. K. (2017). Text message intervention improves objective sleep hours among adolescents.\n\n\n5\nEloïse\nTavernier, R., & Adam, E. K. (2017). Text message intervention improves objective sleep hours among adolescents.\n\n\n6\nOlga\nDiliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal.\n\n\n6\nArthur\nDiliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal.\n\n\n6\nRivka\nDiliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal.\n\n\n6\nLucas\nDiliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal.\n\n\n6\nLisa\nDiliberti, N., Bordi, P. L., Conklin, M. T., Roe, L. S., & Rolls, B. J. (2004). Increased Portion Size Leads to Increased Energy Intake in a Restaurant Meal.",
    "crumbs": [
      "Content",
      "13 - How to Read and Present a Scientific Paper"
    ]
  },
  {
    "objectID": "guides/power_simulation.html",
    "href": "guides/power_simulation.html",
    "title": "Power Simulation",
    "section": "",
    "text": "Warning\n\n\n\nYou don’t have much experience with writing your own functions yet. Don’t despair, try to follow along as best as you can.\nWe start, as always, by loading the libraries we’ll use.\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(truncnorm)\nSince we’re running a simulation, we will also set a seed to make it all reproducible.\nThis guide picks up from where lecture 6 on power analysis ends.\nIn a power simulation, for a given effect size, we would like to know at which sample size we achieve our desired statistical power.\nImagine we want to know how big a sample we need, to detect a difference of -0.5 between action and comedy movies, assuming we want at least a power of 80%.",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-1-generate-a-single-sample-and-calculate-the-outcome",
    "href": "guides/power_simulation.html#step-1-generate-a-single-sample-and-calculate-the-outcome",
    "title": "Power Simulation",
    "section": "Step 1: Generate a single sample and calculate the outcome",
    "text": "Step 1: Generate a single sample and calculate the outcome\n\n# set some sample size\nsample_size = 1000\n\n# generate a single random sample\nsample &lt;- tibble(\n  movie_id = 1:sample_size,\n  genre = sample(c(\"Comedy\", \"Action\"), size = sample_size, replace = TRUE),\n  rating = ifelse(\n    genre == \"Comedy\",\n    rtruncnorm(sample_size, a = 1, b = 10, mean = 6.0, sd = 2), \n    rtruncnorm(sample_size, a = 1, b = 10, mean = 5.5, sd = 2)   \n  )\n)\n\n\nhead(sample)\n\n# A tibble: 6 × 3\n  movie_id genre  rating\n     &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;\n1        1 Comedy   6.15\n2        2 Action   6.68\n3        3 Comedy   3.63\n4        4 Comedy   6.02\n5        5 Action   2.66\n6        6 Comedy   9.19\n\n\nTo be able to use this later, we turn it into a function.\n\ngenerate_sample &lt;- function(sample_size){\n  sample &lt;- tibble(\n  movie_id = 1:sample_size,\n  genre = sample(c(\"Comedy\", \"Action\"), size = sample_size, replace = TRUE),\n  rating = ifelse(\n    genre == \"Comedy\",\n    rtruncnorm(sample_size, a = 1, b = 10, mean = 6.0, sd = 2), \n    rtruncnorm(sample_size, a = 1, b = 10, mean = 5.5, sd = 2)   \n  )\n)\n  \n  return(sample)\n}\n\nNow we can call this function.\n\nsample &lt;- generate_sample(sample_size = 1000) \n\nhead(sample)\n\n# A tibble: 6 × 3\n  movie_id genre  rating\n     &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;\n1        1 Action   6.47\n2        2 Action   3.80\n3        3 Comedy   3.95\n4        4 Comedy   9.39\n5        5 Comedy   5.91\n6        6 Comedy   6.82",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-2-get-an-estimate",
    "href": "guides/power_simulation.html#step-2-get-an-estimate",
    "title": "Power Simulation",
    "section": "Step 2: Get an estimate",
    "text": "Step 2: Get an estimate\n\nestimate &lt;- sample |&gt; \n  group_by(genre) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %&gt;%\n  pull(diff)\n\nestimate\n\n[1] -0.5484191\n\n\nAgain, let’s put this in a function\n\ngenerate_estimate &lt;- function(sample){\n  estimate &lt;- sample |&gt; \n    group_by(genre) |&gt; \n    summarize(avg_rating = mean(rating)) |&gt; \n    summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %&gt;%\n    pull(diff)\n  \n  return(estimate)\n}\n\nAgain, we can now call this function.\n\ngenerate_estimate(sample = sample)\n\n[1] -0.5484191",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-3-repeat",
    "href": "guides/power_simulation.html#step-3-repeat",
    "title": "Power Simulation",
    "section": "Step 3: Repeat",
    "text": "Step 3: Repeat\nLet’s say we want to have 1000 samples for our sampling distribution, so we repeat the above process 1000 times.\n\nn_simulations &lt;- 1000\n\n# make an empty vector\nestimates &lt;- c()\n\nfor (i in 1:n_simulations) {\n  # draw a sample \n  sample &lt;- generate_sample(sample_size = 1000) \n  \n  # get an estimate\n  estimate &lt;- generate_estimate(sample = sample)\n  \n  estimates[i] &lt;- estimate\n}\n\nWe can plot the results to see if it worked as we expected.\n\nggplot(data.frame(estimates), aes(x = estimates)) +\n  geom_histogram() +\n  labs(title = \"Sampling Distribution of Estimates\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nSeems good.\nAgain, let’s put this into a function\n\ngenerate_samples &lt;- function(n_simulations, sample_size) {\n  \n  # Make an empty vector\n  estimates &lt;- numeric(n_simulations)\n  \n  for (i in 1:n_simulations) {\n    # Draw a sample with the specified size\n    sample &lt;- generate_sample(sample_size) \n    \n    # Get an estimate\n    estimates[i] &lt;- generate_estimate(sample)\n  }\n  \n  return(estimates)\n}\n\n\nestimates &lt;- generate_samples(n_simulations = 500, sample_size = 500)\n\n\nggplot(data.frame(estimates), aes(x = estimates)) +\n  geom_histogram() +\n  labs(title = \"Sampling Distribution of Estimates\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWorks fine again.",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-4-calculate-power",
    "href": "guides/power_simulation.html#step-4-calculate-power",
    "title": "Power Simulation",
    "section": "Step 4: Calculate power",
    "text": "Step 4: Calculate power\nTo calculate the power, we first test the statistical significance for each of our 1000 estimates.\nTo do so, we bring our estimate to the scale of the standard normal distribution and check if it’s smaller than -1.96.\n\ncalculate_power &lt;- function(estimates){\n  \n  # bring on standard normal distribution scale\n  estimates_standardized &lt;- estimates/sd(estimates)\n  \n  # get statistical power \n  power &lt;- data.frame(estimates_standardized) |&gt; \n    mutate(significant = ifelse(estimates_standardized &lt;= -1.96, TRUE, FALSE)) |&gt; \n    summarize(share_significant = sum(significant) / n()) |&gt; \n    pull(share_significant)\n  \n  return(power)\n}\n\n\ncalculate_power(estimates = estimates)\n\n[1] 0.736",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-5-bring-it-all-together",
    "href": "guides/power_simulation.html#step-5-bring-it-all-together",
    "title": "Power Simulation",
    "section": "Step 5: Bring it all together",
    "text": "Step 5: Bring it all together\nWe now put all the above functions into a final power_simulation function.\n\npower_simulation &lt;- function(sample_size, n_simulations = 1000) {\n  \n  # Generate multiple samples and compute estimates\n  estimates &lt;- generate_samples(n_simulations, sample_size)\n  \n  # Calculate statistical power\n  power &lt;- calculate_power(estimates)\n  \n  # Return results\n  return(tibble(\n    sample_size = sample_size,\n    n_simulations = n_simulations,\n    estimated_power = power,\n    mean_effect = mean(estimates),\n    sd_effect = sd(estimates)\n  ))\n}\n\nLet’s test this function\n\n# run a power simulation for sample size 1000\npower_simulation(sample_size = 1000, n_simulations = 1000)\n\n# A tibble: 1 × 5\n  sample_size n_simulations estimated_power mean_effect sd_effect\n        &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1        1000          1000           0.935      -0.422     0.121\n\n\n🎉 Seems to have worked just fine.",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/power_simulation.html#step-6-repeat-the-whole-process",
    "href": "guides/power_simulation.html#step-6-repeat-the-whole-process",
    "title": "Power Simulation",
    "section": "Step 6: Repeat the whole process",
    "text": "Step 6: Repeat the whole process\nWe write a for loop, for different sample sizes we would like to test. Remember that the output of our power_data() function is a data frame, so we initialize an empty data frame where we can store the results of all iterations.\nNote that running the code chunk below takes a couple of seconds.\n\nsample_sizes &lt;- c(50, 100, 500, 1000)\n\n# make an empty data frame\npower_data &lt;- tibble()\n\nfor (i in sample_sizes) {\n  # run power simulation\n  power &lt;- power_simulation(sample_size = i, n_simulations = 1000)\n  \n  power_data &lt;- bind_rows(power_data, power)\n}\n\npower_data\n\n# A tibble: 4 × 5\n  sample_size n_simulations estimated_power mean_effect sd_effect\n        &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1          50          1000           0.127      -0.432     0.518\n2         100          1000           0.208      -0.423     0.371\n3         500          1000           0.751      -0.436     0.169\n4        1000          1000           0.971      -0.431     0.111\n\n\n🎉 Worked!\nWe can plot the results.\n\nggplot(power_data, \n       aes(x = sample_size, y = estimated_power)) +\n  geom_line(color = 'red', size = 1.5) + \n  # add a horizontal line at 80%\n  geom_hline(aes(yintercept = .8), linetype = 'dashed') + \n  # Prettify!\n  theme_minimal() + \n  scale_y_continuous(labels = scales::percent, limits = c(0,1)) + \n  labs(title = \"Power Simulation for a difference of -0.5 between action and comedy movies\",\n       x = 'Sample Size', y = 'Power')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nFrom the curve, we can read that we reach our desired power level somewhere between a sample size of 500 and 1000, but a lot closer to 500.",
    "crumbs": [
      "Guides",
      "Power Simulation"
    ]
  },
  {
    "objectID": "guides/random_numbers.html",
    "href": "guides/random_numbers.html",
    "title": "Generating Random Numbers",
    "section": "",
    "text": "Credit\n\n\n\nThis guide is a minimally adapted version of Andrew Heiss’ guide on generating random numbers. The reason I don’t simply link his guide, besides the minimal adaptations, is to ensure it doesn’t disappear from the internet for whatever reason.\nIn many situations, it is helpful to generate synthetic (i.e. not real) data sets, e.g. when you want to simulate Null worlds, or do a power analysis for planning the sample size of a future study.\nThis guide shows you how to simulate variables, i.e. generating random numbers, based on different distributions.\nTo follow through with the examples, make sure you load the libraries we’ll use throughout:\nlibrary(tidyverse)\nlibrary(patchwork)",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "guides/random_numbers.html#summary",
    "href": "guides/random_numbers.html#summary",
    "title": "Generating Random Numbers",
    "section": "Summary",
    "text": "Summary\nYou will probably regularly get back to this guide on several occasions, so upfront, here is a quick overview of the main distributions and functions that we’ll cover:\n\n\n\n\n\nDistribution\nDescription\nSituations\nParameters\nCode\n\n\n\n\nUniform\nNumbers between a minimum and maximum; everything equally likely\nID numbers, age\nmin, max\nsample() or runif()\n\n\nNormal\nNumbers bunched up around an average with a surrounding spread; numbers closer to average more likely\nIncome, education, most types of numbers that have some sort of central tendency\nmean, sd\nrnorm()\n\n\nTruncated normal\nNormal distribution + constraints on minimum and/or maximum values\nAnything with a normal distribution\nmean, sd, a (minimum), b (maximum)\ntruncnorm::rtruncnorm()\n\n\nBeta\nNumbers constrained between 0 and 1\nAnything with percents; anything on a 0–1(00) scale; anything, really, if you use rescale() to rescale it\nshape1 ($\\alpha$), shape2 ($\\beta$) ($\\frac{\\alpha}{\\alpha + \\beta}$)\nrbeta()\n\n\nBinomial\nBinary variables\nTreatment/control, yes/no, true/false, 0/1\nsize, prob\nsample(..., prob = 0.5) or rbinom()",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "guides/random_numbers.html#seeds",
    "href": "guides/random_numbers.html#seeds",
    "title": "Generating Random Numbers",
    "section": "Seeds",
    "text": "Seeds\nWhen R (or any computer program, really) generates random numbers, it uses an algorithm to simulate randomness. This algorithm always starts with an initial number, or seed. Typically it will use something like the current number of milliseconds since some date, so that every time you generate random numbers they’ll be different. Look at this, for instance:\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 9 4 7\n\n\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 5 6 9\n\n\nThey’re different both times.\nThat’s ordinarily totally fine, but if you care about reproducibility (like having a synthetic dataset with the same random values, or having jittered points in a plot be in the same position every time you render), it’s a good idea to set your own seed. This ensures that the random numbers you generate are the same every time you generate them.\nDo this by feeding set.seed() some numbers. It doesn’t matter what number you use—it just has to be a whole number. People have all sorts of favorite seeds:\n\n1\n13\n42\n1234\n12345\n8675309\n\nYou could even go to random.org and use atmospheric noise to generate a seed, and then use that in R.\nHere’s what happens when you generate random numbers after setting a seed:\n\n# Set a seed\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 10  6  5\n\n# Set a seed\nset.seed(1234)\n\n# Choose another 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 10  6  5\n\n\nThey’re the same!\nOnce you set a seed, it influences any function that does anything random, but it doesn’t reset. For instance, if you set a seed once and then run sample() twice, you’ll get different numbers the second time, but you’ll get the same different numbers every time:\n\n# Set a seed\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 10  6  5\n\nsample(1:10, 3)  # This will be different!\n\n[1] 9 5 6\n\n# Set a seed again\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n\n[1] 10  6  5\n\nsample(1:10, 3)  # This will be different, but the same as before!\n\n[1] 9 5 6\n\n\nTypically it’s easiest to just include set.seed(SOME_NUMBER) at the top of your script after you load all the libraries. Some functions have a seed argument, and it’s a good idea to use it: position_jitter(..., seed = 1234).",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "guides/random_numbers.html#distributions",
    "href": "guides/random_numbers.html#distributions",
    "title": "Generating Random Numbers",
    "section": "Distributions",
    "text": "Distributions\nWhen you ask someone to choose a number between 1 and 10, any of those numbers should be equally likely. 1 isn’t really less common than 5 or anything. In some situations, though, there are numbers that are more likely to appear than others (i.e. when you roll two dice, it’s pretty rare to get a 2, but pretty common to get a 7). These different kinds of likelihood change the shape of the distribution of possible values. There are hundreds of different distributions, but for the sake of generating data, there are only a few that you need to know.\n\nUniform distribution\nIn a uniform distribution, every number is equally likely. This is the “pick a number between 1 and 10” scenario, or rolling a single die. There are a couple ways to work with a uniform distribution in R: (1) sample() and (2) runif().\n\nsample()\nThe sample() function chooses an element from a list.\nFor instance, let’s pretend we have six possible numbers (like a die, or like 6 categories on a survey), like this:\n\npossible_answers &lt;- c(1, 2, 3, 4, 5, 6)  # We could also write this as 1:6 instead\n\nIf we want to randomly choose from this list, you’d use sample(). The size argument defines how many numbers to choose.\n\n# Choose 1 random number\nsample(possible_answers, size = 1)\n\n[1] 4\n\n# Choose 3 random numbers\nsample(possible_answers, size = 3)\n\n[1] 2 6 5\n\n\nOne important argument you can use is replace, which essentially puts the number back into the pool of possible numbers. Imagine having a bowl full of ping pong balls with the numbers 1–6 on them. If you take the number “3” out, you can’t draw it again. If you put it back in, you can pull it out again. The replace argument puts the number back after it’s drawn:\n\n# Choose 10 random numbers, with replacement\nsample(possible_answers, size = 10, replace = TRUE)\n\n [1] 6 4 6 6 6 4 4 5 4 3\n\n\nIf you don’t specify replace = TRUE, and you try to choose more numbers than are in the set, you’ll get an error:\n\n# Choose 8 numbers between 1 and 6, but don't replace them.\n# This won't work!\nsample(possible_answers, size = 8)\n\nError in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\nIt’s hard to see patterns in the outcomes when generating just a handful of numbers, but easier when you do a lot. Let’s roll a die 1,000 times:\n\nset.seed(1234)\ndie &lt;- tibble(value = sample(possible_answers,\n                             size = 1000,\n                             replace = TRUE))\ndie |&gt;\n  count(value)\n\n# A tibble: 6 × 2\n  value     n\n  &lt;dbl&gt; &lt;int&gt;\n1     1   161\n2     2   153\n3     3   188\n4     4   149\n5     5   157\n6     6   192\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"1,000 rolls of a single die\")\n\n\n\n\n\n\n\n\nIn this case, 3 and 6 came up more often than the others, but that’s just because of randomness. If we rolled the die 100,000 times, the bars should basically be the same:\n\nset.seed(1234)\ndie &lt;- tibble(value = sample(possible_answers,\n                             size = 100000,\n                             replace = TRUE))\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"100,000 rolls of a single die\")\n\n\n\n\n\n\n\n\n\n\nrunif()\nAnother way to generate uniformly distributed numbers is to use the runif() function (which is short for “random uniform”, and which took me years to realize, and for years I wondered why people used a function named “run if” when there’s no if statement anywhere??)\nrunif() will choose numbers between a minimum and a maximum. These numbers will not be whole numbers. By default, the min and max are 0 and 1:\n\nrunif(5)\n\n[1] 0.09862408 0.96294192 0.88655414 0.05623182 0.44451637\n\n\nHere are 5 numbers between 35 and 56:\n\nrunif(5, min = 35, max = 56)\n\n[1] 46.82529 42.88636 37.74566 53.22182 46.13240\n\n\nSince these aren’t whole numbers, you can round them to make them look more realistic (like, if you were generating a column for age, you probably don’t want people who are 21.5800283 years old):\n\n# Generate 5 people between the ages of 18 and 35\nround(runif(5, min = 18, max = 35), 0)\n\n[1] 21 28 33 34 31\n\n\nYou can confirm that each number has equal probability if you make a histogram. Here are 5,000 random people between 18 and 35:\n\nset.seed(1234)\nlots_of_numbers &lt;- tibble(x = runif(5000, min = 18, max = 35))\n\nggplot(lots_of_numbers, aes(x = x)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 18)\n\n\n\n\n\n\n\n\n\n\n\nNormal distribution\nThe whole “choose a number between 1 and 10” idea of a uniform distribution is neat and conceptually makes sense, but most numbers that exist in the world tend to have higher probabilities around certain values—almost like gravity around a specific point. For instance, income in the United States is not uniformly distributed—a handful of people are really really rich, lots are very poor, and most are kind of clustered around an average.\nThe idea of having possible values clustered around an average is how the rest of these distributions work (uniform distributions don’t have any sort of central gravity point; all these others do). Each distribution is defined by different things called parameters, or values that determine the shape of the probabilities and locations of the clusters.\nA super common type of distribution is the normal distribution. This is the famous “bell curve” you learn about in earlier statistics classes. A normal distribution has two parameters:\n\nA mean (the center of the cluster)\nA standard deviation (how much spread there is around the mean).\n\nIn R, you can generate random numbers from a normal distribution with the rnorm() function. It takes three arguments: the number of numbers you want to generate, the mean, and the standard deviation. It defaults to a mean of 0 and a standard deviation of 1, which means most numbers will cluster around 0, with a lot between −1 and 1, and some going up to −2 and 2 (technically 67% of numbers will be between −1 and 1, while 95% of numbers will be between −2–2ish)\n\nrnorm(5)\n\n[1] -1.3662376  0.5392093 -1.3219320 -0.2812887 -2.1049469\n\n# Cluster around 10, with an SD of 4\nrnorm(5, mean = 10, sd = 4)\n\n[1]  3.529581  7.105072 11.226964 10.902385 13.742864\n\n\nWhen working with uniform distributions, it’s easy to know how high or low your random values might go, since you specify a minimum and maximum number. With a normal distribution, you don’t specify starting and ending points—you specify a middle and a spread, so it’s harder to guess the whole range. Plotting random values is thus essential. Here’s 1,000 random numbers clustered around 10 with a standard deviation of 4:\n\nset.seed(1234)\n\nplot_data &lt;- tibble(x = rnorm(1000, mean = 10, sd = 4))\nhead(plot_data)\n\n# A tibble: 6 × 1\n       x\n   &lt;dbl&gt;\n1  5.17 \n2 11.1  \n3 14.3  \n4  0.617\n5 11.7  \n6 12.0  \n\nggplot(plot_data, aes(x = x)) +\n  geom_histogram(binwidth = 1, boundary = 0, color = \"white\")\n\n\n\n\n\n\n\n\nNeat. Most numbers are around 10; lots are between 5 and 15; some go as high as 25 and as low as −5.\nWatch what happens if you change the standard deviation to 10 to make the spread wider:\n\nset.seed(1234)\n\nplot_data &lt;- tibble(x = rnorm(1000, mean = 10, sd = 10))\nhead(plot_data)\n\n# A tibble: 6 × 1\n       x\n   &lt;dbl&gt;\n1  -2.07\n2  12.8 \n3  20.8 \n4 -13.5 \n5  14.3 \n6  15.1 \n\nggplot(plot_data, aes(x = x)) +\n  geom_histogram(binwidth = 1, boundary = 0, color = \"white\")\n\n\n\n\n\n\n\n\nIt’s still centered around 10, but now you get values as high as 40 and as low as −20. The data is more spread out now.\nWhen simulating data, you’ll most often use a normal distribution just because it’s easy and lots of things follow that pattern in the real world. Incomes, ages, education, etc. all have a kind of gravity to them, and a normal distribution is a good way of showing that gravity. For instance, here are 1,000 simulated people with reasonable random incomes, ages, and years of education:\n\nset.seed(1234)\n\nfake_people &lt;- tibble(income = rnorm(1000, mean = 40000, sd = 15000),\n                      age = rnorm(1000, mean = 25, sd = 8),\n                      education = rnorm(1000, mean = 16, sd = 4))\nhead(fake_people)\n\n# A tibble: 6 × 3\n  income   age education\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 21894. 15.4      12.1 \n2 44161. 27.4      15.6 \n3 56267. 12.7      15.6 \n4  4815. 30.1      20.8 \n5 46437. 30.6       9.38\n6 47591.  9.75     11.8 \n\nfake_income &lt;- ggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated income\")\n\nfake_age &lt;- ggplot(fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated age\")\n\nfake_education &lt;- ggplot(fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated education\")\n\nfake_income + fake_age + fake_education\n\n\n\n\n\n\n\n\nThese three columns all have different centers and spreads. Income is centered around $45,000, going up to almost $100,000 and as low as −$10,000; age is centered around 25, going as low as 0 and as high as 50; education is centered around 16, going as low as 3 and as high as 28. Cool.\nAgain, when generating these numbers, it’s really hard to know how high or low these ranges will be, so it’s a good idea to plot them constantly. I settled on sd = 4 for education only because I tried things like 1 and 10 and got wild looking values (everyone basically at 16 with little variation, or everyone ranging from −20 to 50, which makes no sense when thinking about years of education). Really it’s just a process of trial and error until the data looks good and reasonable.\n\n\nTruncated normal distribution\nSometimes you’ll end up with negative numbers that make no sense. Look at income in the plot above, for instance. Some people are earning −$10,000 year. The rest of the distribution looks okay, but those negative values are annoying.\nTo fix this, you can use something called a truncated normal distribution, which lets you specify a mean and standard deviation, just like a regular normal distribution, but also lets you specify a minimum and/or maximum so you don’t get values that go too high or too low.\nR doesn’t have a truncated normal function built-in, but you can install the {truncnorm} package and use the rtruncnorm() function. A truncated normal distribution has four parameters:\n\nA mean (mean)\nA standard deviation (sd)\nA minimum (optional) (a)\nA maximum (optional) (b)\n\nFor instance, let’s pretend you have a youth program designed to target people who are between 12 and 21 years old, with most around 14. You can generate numbers with a mean of 14 and a standard deviation of 5, but you’ll create people who are too old, too young, or even negatively aged!\n\nset.seed(1234)\n\nplot_data &lt;- tibble(fake_age = rnorm(1000, mean = 14, sd = 5))\nhead(plot_data)\n\n# A tibble: 6 × 1\n  fake_age\n     &lt;dbl&gt;\n1     7.96\n2    15.4 \n3    19.4 \n4     2.27\n5    16.1 \n6    16.5 \n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\nTo fix this, truncate the range at 12 and 21:\n\nlibrary(truncnorm)  # For rtruncnorm()\n\nset.seed(1234)\n\nplot_data &lt;- tibble(fake_age = rtruncnorm(1000, mean = 14, sd = 5, a = 12, b = 21))\nhead(plot_data)\n\n# A tibble: 6 × 1\n  fake_age\n     &lt;dbl&gt;\n1     15.4\n2     19.4\n3     16.1\n4     16.5\n5     14.3\n6     18.8\n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\nAnd voila! A bunch of people between 12 and 21, with most around 14, with no invalid values.\n\n\nBeta distribution\nNormal distributions are neat, but they’re symmetrical around the mean (unless you truncate them). What if your program involves a test with a maximum of 100 points where most people score around 85, but a sizable portion score below that. In other words, it’s not centered at 85, but is skewed left.\nTo simulate this kind of distribution, we can use a Beta distribution. Beta distributions are neat because they naturally only range between 0 and 1—they’re perfect for things like percentages or proportions or or 100-based exams.\nUnlike a normal distribution, where you use the mean and standard deviation as parameters, Beta distributions take two non-intuitive parameters:\n\nshape1\nshape2\n\nWhat the heck are these shapes though?! This answer at Cross Validated does an excellent job of explaining the intuition behind Beta distributions and it’d be worth it to read it.\nBasically, Beta distributions are good at modeling probabilities of things, and shape1 and shape2 represent specific parts of a probability formula.\nLet’s say that there’s an exam with 10 points where most people score a 6/10. Another way to think about this is that an exam is a collection of correct answers and incorrect answers, and that the percent correct follows this equation:\n\\[\n\\frac{\\text{Number correct}}{\\text{Number correct} + \\text{Number incorrect}}\n\\]\nIf you scored a 6, you could write that as:\n\\[\n\\frac{6}{6 + 4}\n\\]\nTo make it more general, we can use Greek variable names: \\(\\alpha\\) for the number correct and \\(\\beta\\) for the number incorrect, leaving us with this:\n\\[\n\\frac{\\alpha}{\\alpha + \\beta}\n\\]\nNeat.\nIn a Beta distribution, the \\(\\alpha\\) and \\(\\beta\\) in that equation correspond to shape1 and shape2. If we want to generate random scores for this test where most people get 6/10, we can use rbeta():\n\nset.seed(1234)\n\nplot_data &lt;- tibble(exam_score = rbeta(1000, shape1 = 6, shape2 = 4)) |&gt;\n  # rbeta() generates numbers between 0 and 1, so multiply everything by 10 to\n  # scale up the exam scores\n  mutate(exam_score = exam_score * 10)\n\nggplot(plot_data, aes(x = exam_score)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 0:10)\n\n\n\n\n\n\n\n\nMost people score around 6, with a bunch at 5 and 7, and fewer in the tails. Importantly, it’s not centered at 6—the distribution is asymmetric.\nThe magic of—and most confusing part about—Beta distributions is that you can get all sorts of curves by just changing the shape parameters. To make this easier to see, we can make a bunch of different Beta distributions. Instead of plotting them with histograms, we’ll use density plots (and instead of generating random numbers, we’ll plot the actual full range of the distribution (that’s what dbeta and geom_function() do in all these examples)).\nHere’s what we saw before, with \\(\\alpha\\) (shape1) = 6 and \\(\\beta\\) (shape2) = 4:\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 6, shape2 = 4))\n\n\n\n\n\n\n\n\nAgain, there’s a peak at 0.6 (or 6), which is what we expected.\nWe can make the distribution narrower if we scale the shapes up. Here pretty much everyone scores around 50% and 75%.\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 60, shape2 = 40))\n\n\n\n\n\n\n\n\nSo far all these curves look like normal distributions, just slightly skewed. But when if most people score 90–100%? Or most fail? A Beta distribution can handle that too:\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 9, shape2 = 1), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 1, shape2 = 9), color = \"red\")\n\n\n\n\n\n\n\n\nWith shape1 = 9 and shape2 = 1 (or \\(\\frac{9}{9 + 1}\\)) we get most around 90%, while shape1 = 1 and shape2 = 9 (or \\(\\frac{1}{1 + 9}\\)) gets us most around 10%.\nCheck out all these other shapes too:\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 5, shape2 = 5), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5), color = \"red\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 80, shape2 = 23), color = \"orange\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 13, shape2 = 17), color = \"brown\")\n\n\n\n\n\n\n\n\nIn real life, if I don’t want to figure out the math behind the \\(\\frac{\\alpha}{\\alpha + \\beta}\\) shape values, I end up just choosing different numbers until it looks like the shape I want, and then I use rbeta() with those parameter values. Like, how about we generate some numbers based on the red line above, with shape1 = 2 and shape2 = 5, which looks like it should be centered around 0.2ish (\\(\\frac{2}{2 + 5} = 0.2857\\)):\n\nset.seed(1234)\n\nplot_data &lt;- tibble(thing = rbeta(1000, shape1 = 2, shape2 = 5)) |&gt;\n  mutate(thing = thing * 100)\nhead(plot_data)\n\n# A tibble: 6 × 1\n  thing\n  &lt;dbl&gt;\n1 10.1 \n2 34.5 \n3 55.3 \n4  2.19\n5 38.0 \n6 39.9 \n\nggplot(plot_data, aes(x = thing)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\nIt worked! Most values are around 20ish, but some go up to 60–80.\n\n\nBinomial distribution\nOften you’ll want to generate a column that only has two values: yes/no, treated/untreated, before/after, big/small, red/blue, etc. You’ll also likely want to control the proportions (25% treated, 62% blue, etc.). You can do this in two different ways: (1) sample() and (2) rbinom().\n\nsample()\nWe already saw sample() when we talked about uniform distributions. To generate a binary variable with sample(), just feed it a list of two possible values:\n\nset.seed(1234)\n\n# Choose 5 random T/F values\npossible_things &lt;- c(TRUE, FALSE)\nsample(possible_things, 5, replace = TRUE)\n\n[1] FALSE FALSE FALSE FALSE  TRUE\n\n\nR will choose these values with equal/uniform probability by default, but you can change that in sample() with the prob argument. For instance, pretend you want to simulate an election. According to the latest polls, one candidate has an 80% chance of winning. You want to randomly choose a winner based on that chance. Here’s how to do that with sample():\n\nset.seed(1234)\ncandidates &lt;- c(\"Person 1\", \"Person 2\")\nsample(candidates, size = 1, prob = c(0.8, 0.2))\n\n[1] \"Person 1\"\n\n\nPerson 1 wins!\nIt’s hard to see the weighted probabilities when you just choose one, so let’s pretend there are 1,000 elections:\n\nset.seed(1234)\nfake_elections &lt;- tibble(winner = sample(candidates,\n                                         size = 1000,\n                                         prob = c(0.8, 0.2),\n                                         replace = TRUE))\nfake_elections |&gt;\n  count(winner)\n\n# A tibble: 2 × 2\n  winner       n\n  &lt;chr&gt;    &lt;int&gt;\n1 Person 1   792\n2 Person 2   208\n\nggplot(fake_elections, aes(x = winner)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nPerson 1 won 792 of the elections. Neat.\n(This is essentially what election forecasting websites like FiveThirtyEight do! They just do it with way more sophisticated simulations.)\n\n\nrbinom()\nInstead of using sample(), you can use a formal distribution called the binomial distribution. This distribution is often used for things that might have “trials” or binary outcomes that are like success/failure or yes/no or true/false\nThe binomial distribution takes two parameters:\n\nsize: The number of “trials”, or times that an event happens\nprob: The probability of success in each trial\n\nIt’s easiest to see some examples of this. Let’s say you have a program that has a 60% success rate and it is tried on groups of 20 people 5 times. The parameters are thus size = 20 (since there are twenty people per group) and prob = 0.6 (since there is a 60% chance of success):\n\nset.seed(1234)\n\nrbinom(5, size = 20, prob = 0.6)\n\n[1] 15 11 11 11 10\n\n\nThe results here mean that in group 1, 15/20 (75%) people had success, in group 2, 11/20 (55%) people had success, and so on. Not every group will have exactly 60%, but they’re all kind of clustered around that.\nHOWEVER, I don’t like using rbinom() like this, since this is all group-based, and when you’re generating fake people you generally want to use individuals, or groups of 1. So instead, I assume that size = 1, which means that each “group” is only one person large. This forces the generated numbers to either be 0 or 1:\n\nset.seed(1234)\n\nrbinom(5, size = 1, prob = 0.6)\n\n[1] 1 0 0 0 0\n\n\nHere, only 1 of the 5 people were 1/TRUE/yes, which is hardly close to a 60% chance overall, but that’s because we only generated 5 numbers. If we generate lots, we can see the probability of yes emerge:\n\nset.seed(12345)\n\nplot_data &lt;- tibble(thing = rbinom(2000, 1, prob = 0.6)) |&gt;\n  # Make this a factor since it's basically a yes/no categorical variable\n  mutate(thing = factor(thing))\n\nplot_data |&gt;\n  count(thing) |&gt;\n  mutate(proportion = n / sum(n))\n\n# A tibble: 2 × 3\n  thing     n proportion\n  &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;\n1 0       840       0.42\n2 1      1160       0.58\n\nggplot(plot_data, aes(x = thing)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n58% of the 2,000 fake people here were 1/TRUE/yes, which is close to the goal of 60%. Perfect.",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "guides/random_numbers.html#rescaling-numbers",
    "href": "guides/random_numbers.html#rescaling-numbers",
    "title": "Generating Random Numbers",
    "section": "Rescaling numbers",
    "text": "Rescaling numbers\nAll these different distributions are good at generating general shapes:\n\nUniform: a bunch of random numbers with no central gravity\nNormal: an average ± some variation\nBeta: different shapes and skews and gravities between 0 and 1\nBinomial: yes/no outcomes that follow some probability\n\nThe shapes are great, but you also care about the values of these numbers. This can be tricky. As we saw earlier with a normal distribution, sometimes you’ll get values that go below zero or above some value you care about. We fixed that with a truncated normal distribution, but not all distributions have truncated versions. Additionally, if you’re using a Beta distribution, you’re stuck in a 0–1 scale (or 0–10 or 0–100 if you multiply the value by 10 or 100 or whatever).\nWhat if you want a fun skewed Beta shape for a variable like income or some other value that doesn’t fit within a 0–1 range? You can rescale any set of numbers after-the-fact using the rescale() function from the {scales} library and rescale things to whatever range you want.\nFor instance, let’s say that income isn’t normally distributed, but is right-skewed with a handful of rich people. This might look like a Beta distribution with shape1 = 2 and shape2 = 5:\n\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5))\n\n\n\n\n\n\n\n\nIf we generate random numbers from this distribution, they’ll all be stuck between 0 and 1:\n\nset.seed(1234)\n\nfake_people &lt;- tibble(income = rbeta(1000, shape1 = 2, shape2 = 5))\n\nggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 0.1, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\nWe can take those underling 0–1 values and rescale them to some other range using the rescale() function. We can specify the minimum and maximum values in the to argument. Here we’ll scale it up so that 0 = $10,000 and 1 = $100,000. Our rescaled version follows the same skewed Beta distribution shape, but now we’re using better values!\n\nlibrary(scales)\n\nfake_people_scaled &lt;- fake_people |&gt;\n  mutate(income_scaled = rescale(income, to = c(10000, 100000)))\nhead(fake_people_scaled)\n\n# A tibble: 6 × 2\n  income income_scaled\n   &lt;dbl&gt;         &lt;dbl&gt;\n1 0.101         21154.\n2 0.345         49014.\n3 0.553         72757.\n4 0.0219        12176.\n5 0.380         53036.\n6 0.399         55162.\n\nggplot(fake_people_scaled, aes(x = income_scaled)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\nThis works for anything, really. For instance, instead of specifying a mean and standard deviation for a normal distribution and hoping that the generated values don’t go too high or too low, you can generate a normal distribution with a mean of 0 and standard deviation of 1 and then rescale it to the range you want:\n\nset.seed(1234)\n\nfake_data &lt;- tibble(age_not_scaled = rnorm(1000, mean = 0, sd = 1)) |&gt;\n  mutate(age = rescale(age_not_scaled, to = c(18, 65)))\nhead(fake_data)\n\n# A tibble: 6 × 2\n  age_not_scaled   age\n           &lt;dbl&gt; &lt;dbl&gt;\n1         -1.21   33.6\n2          0.277  44.2\n3          1.08   49.9\n4         -2.35   25.5\n5          0.429  45.3\n6          0.506  45.8\n\nplot_unscaled &lt;- ggplot(fake_data, aes(x = age_not_scaled)) +\n  geom_histogram(binwidth = 0.5, color = \"white\", boundary = 0)\n\nplot_scaled &lt;- ggplot(fake_data, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0)\n\nplot_unscaled + plot_scaled\n\n\n\n\n\n\n\n\nThis gives you less control over the center of the distribution (here it happens to be 40 because that’s in the middle of 18 and 65), but it gives you more control over the edges of the distribution.\nRescaling things is really helpful when building in effects and interacting columns with other columns, since multiplying variables by different coefficients can make the values go way out of the normal range. You’ll see a lot more of that in the synthetic data example.",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "guides/random_numbers.html#example",
    "href": "guides/random_numbers.html#example",
    "title": "Generating Random Numbers",
    "section": "Example",
    "text": "Example\nAnd here’s an example dataset of 1,000 fake people and different characteristics. One shortcoming of this fake data is that each of these columns is completely independent—there’s no relationship between age and education and family size and income. You can see how to make these columns correlated (and make one cause another!) in the example for synthetic data.\n\nset.seed(1234)\n\n# Set the number of people here once so it's easier to change later\nn_people &lt;- 1000\n\nexample_fake_people &lt;- tibble(\n  id = 1:n_people,\n  opinion = sample(1:5, n_people, replace = TRUE),\n  age = runif(n_people, min = 18, max = 80),\n  income = rnorm(n_people, mean = 50000, sd = 10000),\n  education = rtruncnorm(n_people, mean = 16, sd = 6, a = 8, b = 24),\n  happiness = rbeta(n_people, shape1 = 2, shape2 = 1),\n  treatment = sample(c(TRUE, FALSE), n_people, replace = TRUE, prob = c(0.3, 0.7)),\n  size = rbinom(n_people, size = 1, prob = 0.5)\n) |&gt;\n  # Adjust some of these columns\n  mutate(opinion = recode(opinion, \"1\" = \"Strongly disagree\",\n                          \"2\" = \"Disagree\", \"3\" = \"Neutral\",\n                          \"4\" = \"Agree\", \"5\" = \"Strongly agree\")) |&gt;\n  mutate(size = recode(size, \"0\" = \"Small\", \"1\" = \"Large\")) |&gt;\n  mutate(happiness = rescale(happiness, to = c(1, 8)))\n\nhead(example_fake_people)\n\n# A tibble: 6 × 8\n     id opinion             age income education happiness treatment size \n  &lt;int&gt; &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;     &lt;chr&gt;\n1     1 Agree              31.7 43900.      18.3      7.20 TRUE      Large\n2     2 Disagree           52.9 34696.      17.1      4.73 TRUE      Large\n3     3 Strongly agree     45.3 43263.      17.1      7.32 FALSE     Large\n4     4 Agree              34.9 40558.      11.7      4.18 FALSE     Small\n5     5 Strongly disagree  50.3 41392.      13.3      2.61 TRUE      Small\n6     6 Strongly agree     63.6 69917.      11.2      4.36 FALSE     Small\n\n\n\nplot_opinion &lt;- ggplot(example_fake_people, aes(x = opinion)) +\n  geom_bar() +\n  guides(fill = \"none\") +\n  labs(title = \"Opinion (uniform with sample())\")\n\nplot_age &lt;- ggplot(example_fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0) +\n  labs(title = \"Age (uniform with runif())\")\n\nplot_income &lt;- ggplot(example_fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Income (normal)\")\n\nplot_education &lt;- ggplot(example_fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Education (truncated normal)\")\n\nplot_happiness &lt;- ggplot(example_fake_people, aes(x = happiness)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:8) +\n  labs(title = \"Happiness (Beta, rescaled to 1-8)\")\n\nplot_treatment &lt;- ggplot(example_fake_people, aes(x = treatment)) +\n  geom_bar() +\n  labs(title = \"Treatment (binary with sample())\")\n\nplot_size &lt;- ggplot(example_fake_people, aes(x = size)) +\n  geom_bar() +\n  labs(title = \"Size (binary with rbinom())\")\n\n\n(plot_opinion + plot_age) / (plot_income + plot_education)\n\n\n\n\n\n\n\n\n\n(plot_happiness + plot_treatment) / (plot_size)",
    "crumbs": [
      "Guides",
      "Generating Random Numbers"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Epistémologie et Esprit Critique ",
    "section": "",
    "text": "Jan Pfänder |  Institut Jean Nicod, ENS-PSL |  jan.pfander@psl.eu |  Bluesky",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Epistémologie et Esprit Critique ",
    "section": "",
    "text": "Jan Pfänder |  Institut Jean Nicod, ENS-PSL |  jan.pfander@psl.eu |  Bluesky",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Epistémologie et Esprit Critique ",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nDate\nTime\nPlace*\n\n\nI Data Analysis\n\n\n0\nWelcome and Installation Party\n30/01/2025\n10h15 - 12h15\nSalle 3\n\n\n1\nIntroduction to R, RStudio and Quarto\n06/02/25\n10h15 - 12h15\nSalle 3\n\n\n2\nData Manipulation\n13/02/25\n10h15 - 12h15\nSalle 3\n\n\n3\nVariables, Distributions and Summary Statistics\n20/02/25\n10h15 - 12h15\nSalle 3\n\n\n4\nData Visualization\n06/03/25\n10h15 - 12h15\nSalle 3\n\n\nII Statistics\n\n\n5\nStatistical Inference\n13/03/25\n10h15 - 12h15\nSalle 3\n\n\n6\nStatistical Power\n20/03/25\n10h15 - 12h15\nSalle 3\n\n\n7\nLinear Regression\n27/03/25\n10h15 - 12h15\nSalle 3\n\n\nIII Causal Inference\n\n\n8\nColliders and Confounders\n02/04/25\n10h15 - 12h15\nSalle 5\n\n\n9\nRCTs and Validity\n03/04/25\n10h15 - 12h15\nSalle 3\n\n\nIV Science\n\n\n10\nScientific Publishing and the Replication Crisis\n10/04/25\n10h15 - 12h15\nSalle 3\n\n\n11\nWriting a Preregistration\n17/04/25\n10h15 - 12h15\nSalle 3\n\n\n12\nMeta-Analyses\n15/05/25\n10h15 - 12h15\nSalle 3\n\n\n13\nHow to Read and Present a Scientific Paper\n22/05/25\n10h15 - 12h15\nSalle 3\n\n\n14\nPresentations Group Project\n05/06/25\n10h15 - 12h15\nSalle 3\n\n\n\nNote:\n\n\n\n\n\n\n* 48 blvd Jourdan, Paris 14ème",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "problem_sets/02-solution.html",
    "href": "problem_sets/02-solution.html",
    "title": "Problem set 2",
    "section": "",
    "text": "Getting started\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\nRead the data\n\n\nRows: 195 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Breed\ndbl (8): 2013 Rank, 2014 Rank, 2015 Rank, 2016 Rank, 2017 Rank, 2018 Rank, 2...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 195 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Breed, Coat Type, Coat Length\ndbl (14): Affectionate With Family, Good With Young Children, Good With Othe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nbreed_rank &lt;- read_csv(\"data/breed_rank.csv\")\nbreed_traits &lt;- read_csv(\"data/breed_traits.csv\")\n\n\n\nClean the data\nDisplay variables.\n\nnames(breed_rank)\n\n[1] \"Breed\"     \"2013 Rank\" \"2014 Rank\" \"2015 Rank\" \"2016 Rank\" \"2017 Rank\"\n[7] \"2018 Rank\" \"2019 Rank\" \"2020 Rank\"\n\nnames(breed_traits)\n\n [1] \"Breed\"                      \"Affectionate With Family\"  \n [3] \"Good With Young Children\"   \"Good With Other Dogs\"      \n [5] \"Shedding Level\"             \"Coat Grooming Frequency\"   \n [7] \"Drooling Level\"             \"Coat Type\"                 \n [9] \"Coat Length\"                \"Openness To Strangers\"     \n[11] \"Playfulness Level\"          \"Watchdog/Protective Nature\"\n[13] \"Adaptability Level\"         \"Trainability Level\"        \n[15] \"Energy Level\"               \"Barking Level\"             \n[17] \"Mental Stimulation Needs\"  \n\n\nMake better names.\n\nbreed_traits &lt;- breed_traits |&gt; \n  clean_names()\n\n\n\nManipulate the data using dplyr\nMaka a summary.\n\nbreed_traits |&gt; \n  group_by(shedding_level) |&gt; \n  summarise(n = n())\n\n# A tibble: 6 × 2\n  shedding_level     n\n           &lt;dbl&gt; &lt;int&gt;\n1              0     1\n2              1    27\n3              2    41\n4              3   109\n5              4    16\n6              5     1\n\n\nFilter the shedding_level 0.\n\nbreed_traits &lt;- breed_traits |&gt; \n  filter(shedding_level != 0)\n\nCheck if manipulation was successful.\n\nbreed_traits |&gt; count(shedding_level)\n\n# A tibble: 5 × 2\n  shedding_level     n\n           &lt;dbl&gt; &lt;int&gt;\n1              1    27\n2              2    41\n3              3   109\n4              4    16\n5              5     1\n\n\nMake an untidy data frame.\n\nuntidy_scores &lt;- breed_traits |&gt; \n  mutate(untidy_score = shedding_level + \n           coat_grooming_frequency + drooling_level) |&gt; \n  select(breed, untidy_score)\n\nArrange scores in descending order.\n\nuntidy_scores |&gt; \n  arrange(desc(untidy_score))\n\n# A tibble: 194 × 2\n   breed                  untidy_score\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 Bernese Mountain Dogs            11\n 2 Leonbergers                      11\n 3 Newfoundlands                    10\n 4 Bloodhounds                      10\n 5 St. Bernards                     10\n 6 Old English Sheepdogs            10\n 7 Dogues de Bordeaux               10\n 8 Neapolitan Mastiffs              10\n 9 Black Russian Terriers           10\n10 Tibetan Mastiffs                 10\n# ℹ 184 more rows\n\n\n\n\nTidying the data\nHow does this this data set fail to meet the criteria for tidy data?\nThere are three interrelated rules which make a dataset tidy:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nWe have a year and a rank variable, but neither of these variables have their own column. Shown above is one observation, by dog breed. But that “one” observation is actually eight separate observations: the rank in 2013, the rank in 2014, etc. Each observation needs to have its own row.\nMake pivoted data with a year and a rank variable.\n\nranks_pivoted &lt;- breed_rank |&gt; \n  pivot_longer(`2013 Rank`:`2020 Rank`,\n               names_to = \"year\",\n               values_to = \"rank\")\n\nRename breed and make the year variable numeric.\n\nranks_pivoted &lt;- ranks_pivoted |&gt; \n  rename(breed = Breed) |&gt; \n  mutate(year = parse_number(year))\n\nFilter data to only Bernese Mountain Dogs.\n\nranks_pivoted &lt;- ranks_pivoted |&gt; \n  filter(str_detect(breed, \"Bernese\")) \n\nPlot rankings across time.\n\nranks_pivoted |&gt;\n  ggplot(aes(x = year, y = rank, label = rank)) +\n  geom_point(size = 3) +\n  geom_text(vjust = 2)"
  },
  {
    "objectID": "problem_sets/04-solution.html",
    "href": "problem_sets/04-solution.html",
    "title": "Problem set 4",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nset.seed(1234) # For reproducibility\n\nRead the survey data.\n\n# Load the survey data from class\nsurvey &lt;- read_csv(\"../data/distance-to-school_pet-preferences.csv\")\n\nIn this solution, we’ll use simulated data.\n\n# simulate survey data\nsample_size &lt;- 30\n\nsurvey &lt;- tibble(\n  name = 1:sample_size,\n  distance = round(runif(sample_size, min = 0.3, max = 20), 1),\n  pet_preference = sample(c(\"dogs\", \"cats\"), size = sample_size, replace = TRUE)\n)\n\nStep 1: Calculate an estimate based on your sample\n\n# compute rating difference in the sample\nsurvey_estimate &lt;- survey |&gt; \n  group_by(pet_preference) |&gt; \n  summarize(avg_distance = mean(distance)) |&gt; \n  summarise(diff = avg_distance[pet_preference == \"dogs\"] - avg_distance[pet_preference == \"cats\"]) %&gt;%\n  pull(diff)\n\nsurvey_estimate\n\n[1] -0.6533333\n\n\nIn our sample, cat people live further away, on average.\nStep 2: Use simulation to invent a world where the true effect is null.\nSimulate a population, say all students in Paris, i.e. 700’000 students.\n\n# simulate survey data\npopulation_size &lt;- 700000\n\npopulation &lt;- tibble(\n  name = 1:population_size,\n  distance = round(runif(population_size, min = 0.3, max = 20), 1),\n  pet_preference = sample(c(\"dogs\", \"cats\"), size = population_size, replace = TRUE)\n)\n\nSimulate 1000 samples with the same sample size that your estimate is based on. Store the estimates of this simulation in a vector called sampling_distribution.\n\nn_simulations &lt;- 1000\nsample_size &lt;- 30\ndifferences &lt;- c() # make an empty vector\n\nfor (i in 1:n_simulations) {\n  # draw a sample of 20'000 films\n  sample &lt;- population |&gt; \n    sample_n(sample_size)\n  # compute rating difference in the sample\n  estimate &lt;- sample |&gt; \n    group_by(pet_preference) |&gt; \n    summarize(avg_distance = mean(distance)) |&gt; \n    summarise(diff = avg_distance[pet_preference == \"dogs\"] - avg_distance[pet_preference == \"cats\"]) %&gt;%\n    pull(diff)\n  \n  differences[i] &lt;- estimate\n}\n\nStep 3: Plot how well this estimate fits into your null world.\n\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  geom_vline(xintercept = survey_estimate, color = \"red\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Sampling distribution based on simulated data\",\n       x = \"Distance to school\",\n       y = \"Frequency\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nStep 4: Calculate the probability that your estimate could exist in the null world.\nUse the standard deviation of your sampling_distribution to transform your initial estimate in a z-value.\n\nsd_sampling_distribution &lt;- sd(differences)\n\nz_scaled_estimate = survey_estimate / sd_sampling_distribution\n\nz_scaled_estimate\n\n[1] -0.3074499\n\n\nBased on this, calculate the p-value.\n\n# the pnorm() function gives the cumulative probability from the standard normal distribution \n\n# Two-tailed (i.e. a value \"at least as extreme as\", in both directions)\nprobability &lt;- 2 * (1 - pnorm(z_scaled_estimate)) \n\n# in our case, the probability is reeaally low (practically 0)\nprobability\n\n[1] 1.241499\n\n\nStep 5: Decide if your estimate is statistically significant.\nUse a significance threshold (the value at which you consider your estimate sufficiently unlikely to have occurred in the Null World) of 0.05\n\n# significance levels are often called \"alpha\"\nalpha &lt;- 0.05\n\nprobability &lt; alpha\n\n[1] FALSE\n\n\nNo, our estimate is not statistically significant: We cannot cannot reject the Null hypothesis that in fact, in the population, there is no true effect. In other words, in a world where there is no effect, it does not appear sufficiently unlikely to randomly sample an estimate at least as big as the one we found.\n\nIs this result surprising to you or not? Explain.\n\nThis result is probably not surprising, since we would hardly expect a relationship between pet preferences and distance to school a priori."
  },
  {
    "objectID": "problem_sets/06-solution.html",
    "href": "problem_sets/06-solution.html",
    "title": "Problem set 6",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  # For dplyr, ggplot, and friends\nlibrary(ggdag)      # For plotting DAGs\nlibrary(dagitty)    # For working with DAG logic\n\nThe news article implies the causal claim that that it’s the size of the beverage container that causes students to drink more. However, this conclusion is problematic for reasons of internal and external validity.\nFirst, there are issues with internal validity: This claim is based on observational evidence only, and there are other potential causal explanations that can explain the observed data. For example, it might be that students who intend to drink more a priori both (i) order a pitcher (e.g. because it’s cheaper, or because it avoids having to get up often and order again) and (ii) consume more alcohol. In this case, drinking intentions would be a confounder variable (see Figure below).\nSecond, there are probably issues with external validity: We don’t know exactly how many bars/students these researchers observed in their study. But the claim “People drink more because beer is consumed in pitchers” is definitely an overgeneralization, since the researchers looked only at college students, not people in general.\n\n# Some code to illustrate the point (you don't need to understand whats happening)\ndag_with_coords_and_labels &lt;- dagify(\n  y ~ z,\n  x ~ z,\n  exposure = \"x\",\n  outcome = \"y\",\n  labels = c(y = \"Alcohol consumption\", x = \"Beverage container (pitcher/bottle)\",\n             z = \"Drinking intentions\"),\n  coords = list(x = c(x = 1, z = 2, y = 3),\n                y = c(x = 1, z = 2, y = 1))\n)\n\nggdag_status(dag_with_coords_and_labels,\n             use_labels = \"label\", text = FALSE) +\n  guides(fill = \"none\", color = \"none\") +  # Disable the legend\n  theme_dag()"
  },
  {
    "objectID": "slides/01-slides.html#overview",
    "href": "slides/01-slides.html#overview",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Overview",
    "text": "Overview\n\n\n\nGetting Started\n\nAbout R\nThe R Studio IDE\nImport and eyeball data\n\nAnatomy of a data.frame\n\nData structure\nClasses\nVectors\nSubsetting\n\nWrap Up\n\nSummary and key takeaways\n\n\n\n\nMarkdown and universal writing\n\nOffice Model vs. Engineering Model\nExcel failures\nMarkdown\n\nWriting reports in Quarto\n\nWhat is Quarto?\nYAML header\nCode chunks\nText formatting\nRun and render your code\nInline code\nTables\nPreset themes\nReport parameters"
  },
  {
    "objectID": "slides/01-slides.html#about-r",
    "href": "slides/01-slides.html#about-r",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "About R",
    "text": "About R\n\n\n\nR is a programming language and free software environment for statistical computing and graphics.\nThe R language is widely (and increasingly) used in academic and non-academic research in fields like:\n\nEconomics\nStatistics\nBiostatistics"
  },
  {
    "objectID": "slides/01-slides.html#the-r-studio-ide",
    "href": "slides/01-slides.html#the-r-studio-ide",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "The R Studio IDE",
    "text": "The R Studio IDE"
  },
  {
    "objectID": "slides/01-slides.html#import-and-eyeball-data",
    "href": "slides/01-slides.html#import-and-eyeball-data",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Import and Eyeball Data",
    "text": "Import and Eyeball Data\n\nWe now know how to use R as a calculator, but our goal is to analyze data!\n\nTake for instance the statistics from the last season of Ligue 1 available at fbref.com"
  },
  {
    "objectID": "slides/01-slides.html#import-and-eyeball-data-1",
    "href": "slides/01-slides.html#import-and-eyeball-data-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Import and Eyeball Data",
    "text": "Import and Eyeball Data\n\nYou can download the dataset for the 2021/22 season by clicking here or from the course webpage.\n\nNote that the file extension is .csv (for Comma Separated Values).\nLet’s take a look at the first 5 lines of the raw .csv file:\n\n\n\nWk,Day,Date,Time,Home,xG,Score,xG,Away,Attendance,Venue,Referee,Match Report,Notes\n1,Fri,2021-08-06,21:00,Monaco,2.0,1–1,0.3,Nantes,7500,Stade Louis II.,Antony Gautier,Match Report,\n1,Sat,2021-08-07,17:00,Lyon,1.4,1–1,0.8,Brest,29018,Groupama Stadium,Mikael Lesage,Match Report,\n1,Sat,2021-08-07,21:00,Troyes,0.8,1–2,1.2,Paris S-G,15248,Stade de l'Aube,Amaury Delerue,Match Report,\n1,Sun,2021-08-08,13:00,Rennes,0.6,1–1,2.0,Lens,22567,Roazhon Park,Bastien Dechepy,Match Report,\n\n\n\nThe .csv format is very common and follows a specific structure:\n\nEach line corresponds to a row (the first row typically contains column names).\nFor each row, values of each column are separated by commas.\n\nBut how do we get it into our RStudio environment?"
  },
  {
    "objectID": "slides/01-slides.html#import-and-eyeball-data-2",
    "href": "slides/01-slides.html#import-and-eyeball-data-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Import and Eyeball Data",
    "text": "Import and Eyeball Data\n\nTo import stuff in R we use read functions\n\nThey take the file directory as an input\nAnd give the file content as an output\n\nThe read function dedicated to .csv files is read.csv (later we will mostly use read_csv)\nRemember we use the arrow (&lt;-) to create objects in R\n\n\ndata &lt;- read.csv(\"/Users/jan/Downloads/ligue1.csv\")\n\n\n\n\n\n\n\n\nImportant\n\n\nMake sure you have the right path to your data file. Also, make sure you use correct backlashes “/”. Do NOT use “\\”.\n\n\n\n\n\n\nLet’s inspect this new object"
  },
  {
    "objectID": "slides/01-slides.html#overview-1",
    "href": "slides/01-slides.html#overview-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nGetting Started\n\nAbout R\nThe R Studio IDE\nImport and eyeball data\n\n\n\n\n\nAnatomy of a data.frame\n\nData structure\nClasses\nVectors\nSubsetting"
  },
  {
    "objectID": "slides/01-slides.html#data-structure",
    "href": "slides/01-slides.html#data-structure",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nNow that we imported the data properly, we can check out its str()ucture in more details\n\n\nstr(data)"
  },
  {
    "objectID": "slides/01-slides.html#data-structure-1",
    "href": "slides/01-slides.html#data-structure-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nDon’t be scared of the output!\n\n\nstr(data)\n\n'data.frame':   380 obs. of  14 variables:\n $ Wk          : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day         : chr  \"Fri\" \"Sat\" \"Sat\" \"Sun\" ...\n $ Date        : chr  \"2021-08-06\" \"2021-08-07\" \"2021-08-07\" \"2021-08-08\" ...\n $ Time        : chr  \"21:00\" \"17:00\" \"21:00\" \"13:00\" ...\n $ Home        : chr  \"Monaco\" \"Lyon\" \"Troyes\" \"Rennes\" ...\n $ xG          : num  2 1.4 0.8 0.6 0.7 0.4 0.8 2.1 0.7 0.5 ...\n $ Score       : chr  \"1-1\" \"1-1\" \"1-2\" \"1-1\" ...\n $ xG.1        : num  0.3 0.8 1.2 2 3.3 0.9 0.2 1.3 1.4 2 ...\n $ Away        : chr  \"Nantes\" \"Brest\" \"Paris S-G\" \"Lens\" ...\n $ Attendance  : int  7500 29018 15248 22567 18748 23250 18030 20461 15551 13500 ...\n $ Venue       : chr  \"Stade Louis II.\" \"Groupama Stadium\" \"Stade de l'Aube\" \"Roazhon Park\" ...\n $ Referee     : chr  \"Antony Gautier\" \"Mikael Lesage\" \"Amaury Delerue\" \"Bastien Dechepy\" ...\n $ Match.Report: chr  \"Match Report\" \"Match Report\" \"Match Report\" \"Match Report\" ...\n $ Notes       : logi  NA NA NA NA NA NA ..."
  },
  {
    "objectID": "slides/01-slides.html#data-structure-2",
    "href": "slides/01-slides.html#data-structure-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nstr() says that data is a data.frame, and gives its numbers of observations (rows) and variables (columns)\n\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:"
  },
  {
    "objectID": "slides/01-slides.html#data-structure-3",
    "href": "slides/01-slides.html#data-structure-3",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nIt also gives the variables names\n\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:\n##  $ Wk          \n##  $ Day         \n##  $ Date        \n##  $ Time        \n##  $ Home        \n##  $ xG          \n##  $ Score       \n##  $ xG.1        \n##  $ Away        \n##  $ Attendance  \n##  $ Venue       \n##  $ Referee     \n##  $ Match.Report\n##  $ Notes"
  },
  {
    "objectID": "slides/01-slides.html#data-structure-4",
    "href": "slides/01-slides.html#data-structure-4",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nThe first values of each variable\n\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:\n##  $ Wk          :      1 1 1 1 1 1 1 1 1 1 ...\n##  $ Day         :      \"Fri\" \"Sat\" \"Sat\" \"Sun\" ...\n##  $ Date        :      \"2021-08-06\" \"2021-08-07\" \"2021-08-07\" \"2021-08-08\" ...\n##  $ Time        :      \"21:00\" \"17:00\" \"21:00\" \"13:00\" ...\n##  $ Home        :      \"Monaco\" \"Lyon\" \"Troyes\" \"Rennes\" ...\n##  $ xG          :      2 1.4 0.8 0.6 0.7 0.4 0.8 2.1 0.7 0.5 ...\n##  $ Score       :      \"1–1\" \"1–1\" \"1–2\" \"1–1\" ...\n##  $ xG.1        :      0.3 0.8 1.2 2 3.3 0.9 0.2 1.3 1.4 2 ...\n##  $ Away        :      \"Nantes\" \"Brest\" \"Paris S-G\" \"Lens\" ...\n##  $ Attendance  :      7500 29018 15248 22567 18748 23250 18030 20461 15551 13500 ...\n##  $ Venue       :      \"Stade Louis II.\" \"Groupama Stadium\" \"Stade de l'Aube\" \"Roazhon Park\" ...\n##  $ Referee     :      \"Antony Gautier\" \"Mikael Lesage\" \"Amaury Delerue\" \"Bastien Dechepy\" ...\n##  $ Match.Report:      \"Match Report\" \"Match Report\" \"Match Report\" \"Match Report\" ...\n##  $ Notes       :       NA NA NA NA NA NA ..."
  },
  {
    "objectID": "slides/01-slides.html#data-structure-5",
    "href": "slides/01-slides.html#data-structure-5",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nAs well as the class of each variable\n\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:\n##  $ Wk          : int  1 1 1 1 1 1 1 1 1 1 ...\n##  $ Day         : chr  \"Fri\" \"Sat\" \"Sat\" \"Sun\" ...\n##  $ Date        : chr  \"2021-08-06\" \"2021-08-07\" \"2021-08-07\" \"2021-08-08\" ...\n##  $ Time        : chr  \"21:00\" \"17:00\" \"21:00\" \"13:00\" ...\n##  $ Home        : chr  \"Monaco\" \"Lyon\" \"Troyes\" \"Rennes\" ...\n##  $ xG          : num  2 1.4 0.8 0.6 0.7 0.4 0.8 2.1 0.7 0.5 ...\n##  $ Score       : chr  \"1–1\" \"1–1\" \"1–2\" \"1–1\" ...\n##  $ xG.1        : num  0.3 0.8 1.2 2 3.3 0.9 0.2 1.3 1.4 2 ...\n##  $ Away        : chr  \"Nantes\" \"Brest\" \"Paris S-G\" \"Lens\" ...\n##  $ Attendance  : int  7500 29018 15248 22567 18748 23250 18030 20461 15551 13500 ...\n##  $ Venue       : chr  \"Stade Louis II.\" \"Groupama Stadium\" \"Stade de l'Aube\" \"Roazhon Park\" ...\n##  $ Referee     : chr  \"Antony Gautier\" \"Mikael Lesage\" \"Amaury Delerue\" \"Bastien Dechepy\" ...\n##  $ Match.Report: chr  \"Match Report\" \"Match Report\" \"Match Report\" \"Match Report\" ...\n##  $ Notes       : logi  NA NA NA NA NA NA ..."
  },
  {
    "objectID": "slides/01-slides.html#data-structure-6",
    "href": "slides/01-slides.html#data-structure-6",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Data Structure",
    "text": "Data Structure\n\nBut what does the class correspond to?\n\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:\n##  $ Wk          : int  ?\n##  $ Day         : chr  ?\n##  $ Date        : chr  ?\n##  $ Time        : chr  ?\n##  $ Home        : chr  ?\n##  $ xG          : num  ?\n##  $ Score       : chr  ?\n##  $ xG.1        : num  ?\n##  $ Away        : chr  ?\n##  $ Attendance  : int  ?\n##  $ Venue       : chr  ?\n##  $ Referee     : chr  ?\n##  $ Match.Report: chr  ?\n##  $ Notes       : logi  ?"
  },
  {
    "objectID": "slides/01-slides.html#classes",
    "href": "slides/01-slides.html#classes",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Classes",
    "text": "Classes\n\n\nNumeric\nThese are simply numbers:\n\nclass(3)\n\n[1] \"numeric\"\n\n\n\nclass(-1.89278)\n\n[1] \"numeric\"\n\n\n\nNumeric variable classes include:\n\nint for round numbers\ndbl for 2-decimal numbers\n\n\n\nCharacter\nThey must be surrounded by \" or ':\n\nclass(\"Paris Saint-Germain\")\n\n[1] \"character\"\n\n\n\nclass(\"35\")\n\n[1] \"character\"\n\n\n\nWe also call these values:\n\nCharacter strings\nOr just strings\n\n\n\nLogical\nSomething either TRUE of FALSE:\n\n3 &gt;= 4\n\n[1] FALSE\n\n\n\nclass(3 &gt;= 4)\n\n[1] \"logical\"\n\n\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nEqual to\n\n\n&gt;\nGreater than\n\n\n&lt;\nLess than\n\n\n&gt;=\nGreater than or equal to\n\n\n&lt;=\nLess than or equal to\n\n\n&\nAnd\n\n\n|\nOr\n\n\n!\nOpposite"
  },
  {
    "objectID": "slides/01-slides.html#classes-1",
    "href": "slides/01-slides.html#classes-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Classes",
    "text": "Classes\n\nGuess the output!\n\nas.numeric(\"2022\")\n\n\n\n[1] 2022\n\n\n\n\nWhat about this one?\n\nas.character(2022-2023)\n\n\n\n[1] \"-1\"\n\n\n\n\nAnd a final one.\n\nas.character(2022&gt;2023)\n\n\n\n[1] \"FALSE\""
  },
  {
    "objectID": "slides/01-slides.html#classes-2",
    "href": "slides/01-slides.html#classes-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Classes",
    "text": "Classes\n\n\n\n\n\n\n\n\n\n\n\n\nnumeric\ncharacter\nlogical\n\n\n\n\nas.numeric()\nNo effect\nConverts strings of numbers into numeric values\nReturns NA if characters in the string\nReturns 1 if TRUE\nReturns 0 if FALSE\n\n\nas.character()\nConverts numeric values\ninto strings of numbers\nNo effect\nReturns \"TRUE\" if TRUE\nReturns \"FALSE\" if FALSE\n\n\nas.logical()\nReturns TRUE if != 0\nReturns FALSE if 0\nReturns TRUE if \"T\" or\"TRUE\"\nReturns FALSE if \"F\" or \"FALSE\"\nReturns NA otherwise\nNo effect\n\n\n\n\n\n\n\nNA stands for ‘Not Available’, it corresponds to a missing value"
  },
  {
    "objectID": "slides/01-slides.html#classes-3",
    "href": "slides/01-slides.html#classes-3",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Classes",
    "text": "Classes\nOne last mystery…\n\nstr(data)\n\n'data.frame':   380 obs. of  14 variables:\n $ Wk          : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day         : chr  \"Fri\" \"Sat\" \"Sat\" \"Sun\" ...\n $ Date        : chr  \"2021-08-06\" \"2021-08-07\" \"2021-08-07\" \"2021-08-08\" ...\n $ Time        : chr  \"21:00\" \"17:00\" \"21:00\" \"13:00\" ...\n $ Home        : chr  \"Monaco\" \"Lyon\" \"Troyes\" \"Rennes\" ...\n $ xG          : num  2 1.4 0.8 0.6 0.7 0.4 0.8 2.1 0.7 0.5 ...\n $ Score       : chr  \"1-1\" \"1-1\" \"1-2\" \"1-1\" ...\n $ xG.1        : num  0.3 0.8 1.2 2 3.3 0.9 0.2 1.3 1.4 2 ...\n $ Away        : chr  \"Nantes\" \"Brest\" \"Paris S-G\" \"Lens\" ...\n $ Attendance  : int  7500 29018 15248 22567 18748 23250 18030 20461 15551 13500 ...\n $ Venue       : chr  \"Stade Louis II.\" \"Groupama Stadium\" \"Stade de l'Aube\" \"Roazhon Park\" ...\n $ Referee     : chr  \"Antony Gautier\" \"Mikael Lesage\" \"Amaury Delerue\" \"Bastien Dechepy\" ...\n $ Match.Report: chr  \"Match Report\" \"Match Report\" \"Match Report\" \"Match Report\" ...\n $ Notes       : logi  NA NA NA NA NA NA ..."
  },
  {
    "objectID": "slides/01-slides.html#classes-4",
    "href": "slides/01-slides.html#classes-4",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Classes",
    "text": "Classes\nAre these dollar signs here for a reason?\n\nstr(data)\n\n\n## 'data.frame':    380 obs. of  14 variables:\n##  $ Wk          \n##  $ Day         \n##  $ Date        \n##  $ Time        \n##  $ Home        \n##  $ xG          \n##  $ Score       \n##  $ xG.1        \n##  $ Away        \n##  $ Attendance  \n##  $ Venue       \n##  $ Referee     \n##  $ Match.Report\n##  $ Notes"
  },
  {
    "objectID": "slides/01-slides.html#vectors",
    "href": "slides/01-slides.html#vectors",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Vectors",
    "text": "Vectors\nIt’s actually just a reference to the fact that $ allows to extract a variable from a dataset\n\ndata$Home\n\n  [1] \"Monaco\"        \"Lyon\"          \"Troyes\"        \"Rennes\"       \n  [5] \"Bordeaux\"      \"Strasbourg\"    \"Nice\"          \"Saint-Étienne\"\n  [9] \"Metz\"          \"Montpellier\"   \"Lorient\"       \"Lille\"        \n [13] \"Paris S-G\"     \"Angers\"        \"Clermont Foot\" \"Brest\"        \n [17] \"Nantes\"        \"Reims\"         \"Lens\"          \"Marseille\"    \n [21] \"Brest\"         \"Monaco\"        \"Saint-Étienne\" \"Lyon\"         \n [25] \"Strasbourg\"    \"Metz\"          \"Montpellier\"   \"Bordeaux\"     \n [29] \"Rennes\"        \"Nantes\"        \"Nice\"          \"Marseille\"    \n [33] \"Troyes\"        \"Strasbourg\"    \"Angers\"        \"Lens\"         \n [37] \"Clermont Foot\" \"Lille\"         \"Reims\"         \"Lorient\"      \n [41] \"Paris S-G\"     \"Monaco\"        \"Montpellier\"   \"Rennes\"       \n [45] \"Bordeaux\"      \"Brest\"         \"Metz\"          \"Nantes\"       \n [49] \"Lyon\"          \"Strasbourg\"    \"Lens\"          \"Saint-Étienne\"\n [53] \"Nice\"          \"Troyes\"        \"Clermont Foot\" \"Reims\"        \n [57] \"Angers\"        \"Marseille\"     \"Paris S-G\"     \"Rennes\"       \n [61] \"Nantes\"        \"Lille\"         \"Montpellier\"   \"Monaco\"       \n [65] \"Lyon\"          \"Lens\"          \"Lorient\"       \"Angers\"       \n [69] \"Metz\"          \"Saint-Étienne\" \"Strasbourg\"    \"Paris S-G\"    \n [73] \"Lyon\"          \"Bordeaux\"      \"Troyes\"        \"Brest\"        \n [77] \"Reims\"         \"Clermont Foot\" \"Marseille\"     \"Lens\"         \n [81] \"Montpellier\"   \"Nice\"          \"Rennes\"        \"Lorient\"      \n [85] \"Monaco\"        \"Angers\"        \"Nantes\"        \"Lille\"        \n [89] \"Saint-Étienne\" \"Paris S-G\"     \"Clermont Foot\" \"Lyon\"         \n [93] \"Troyes\"        \"Brest\"         \"Bordeaux\"      \"Metz\"         \n [97] \"Strasbourg\"    \"Montpellier\"   \"Marseille\"     \"Saint-Étienne\"\n[101] \"Nantes\"        \"Lille\"         \"Nice\"          \"Rennes\"       \n[105] \"Lens\"          \"Lorient\"       \"Reims\"         \"Monaco\"       \n[109] \"Marseille\"     \"Nice\"          \"Paris S-G\"     \"Metz\"         \n[113] \"Lyon\"          \"Angers\"        \"Bordeaux\"      \"Troyes\"       \n[117] \"Montpellier\"   \"Strasbourg\"    \"Brest\"         \"Clermont Foot\"\n[121] \"Lens\"          \"Lille\"         \"Bordeaux\"      \"Marseille\"    \n[125] \"Saint-Étienne\" \"Lorient\"       \"Reims\"         \"Nantes\"       \n[129] \"Nice\"          \"Rennes\"        \"Monaco\"        \"Paris S-G\"    \n[133] \"Rennes\"        \"Brest\"         \"Metz\"          \"Angers\"       \n[137] \"Troyes\"        \"Strasbourg\"    \"Clermont Foot\" \"Lens\"         \n[141] \"Lille\"         \"Nice\"          \"Saint-Étienne\" \"Reims\"        \n[145] \"Lorient\"       \"Bordeaux\"      \"Monaco\"        \"Montpellier\"  \n[149] \"Marseille\"     \"Angers\"        \"Troyes\"        \"Strasbourg\"   \n[153] \"Brest\"         \"Metz\"          \"Rennes\"        \"Nantes\"       \n[157] \"Paris S-G\"     \"Lyon\"          \"Clermont Foot\" \"Marseille\"    \n[161] \"Lille\"         \"Lens\"          \"Saint-Étienne\" \"Montpellier\"  \n[165] \"Monaco\"        \"Reims\"         \"Lorient\"       \"Nice\"         \n[169] \"Bordeaux\"      \"Nantes\"        \"Brest\"         \"Reims\"        \n[173] \"Lille\"         \"Angers\"        \"Rennes\"        \"Troyes\"       \n[177] \"Metz\"          \"Strasbourg\"    \"Paris S-G\"     \"Lyon\"         \n[181] \"Saint-Étienne\" \"Lorient\"       \"Nice\"          \"Monaco\"       \n[185] \"Marseille\"     \"Montpellier\"   \"Troyes\"        \"Bordeaux\"     \n[189] \"Bordeaux\"      \"Lens\"          \"Brest\"         \"Metz\"         \n[193] \"Clermont Foot\" \"Nantes\"        \"Lyon\"          \"Nice\"         \n[197] \"Saint-Étienne\" \"Paris S-G\"     \"Rennes\"        \"Reims\"        \n[201] \"Monaco\"        \"Lorient\"       \"Strasbourg\"    \"Troyes\"       \n[205] \"Marseille\"     \"Clermont Foot\" \"Montpellier\"   \"Lille\"        \n[209] \"Lyon\"          \"Brest\"         \"Lens\"          \"Metz\"         \n[213] \"Clermont Foot\" \"Nantes\"        \"Angers\"        \"Bordeaux\"     \n[217] \"Montpellier\"   \"Paris S-G\"     \"Angers\"        \"Lyon\"         \n[221] \"Marseille\"     \"Saint-Étienne\" \"Monaco\"        \"Lorient\"      \n[225] \"Reims\"         \"Nice\"          \"Troyes\"        \"Strasbourg\"   \n[229] \"Rennes\"        \"Lille\"         \"Paris S-G\"     \"Montpellier\"  \n[233] \"Lyon\"          \"Monaco\"        \"Angers\"        \"Brest\"        \n[237] \"Nantes\"        \"Clermont Foot\" \"Lens\"          \"Metz\"         \n[241] \"Lille\"         \"Lens\"          \"Nantes\"        \"Nice\"         \n[245] \"Saint-Étienne\" \"Reims\"         \"Rennes\"        \"Lorient\"      \n[249] \"Bordeaux\"      \"Marseille\"     \"Montpellier\"   \"Strasbourg\"   \n[253] \"Paris S-G\"     \"Monaco\"        \"Angers\"        \"Metz\"         \n[257] \"Clermont Foot\" \"Brest\"         \"Troyes\"        \"Lyon\"         \n[261] \"Lorient\"       \"Lens\"          \"Nice\"          \"Saint-Étienne\"\n[265] \"Nantes\"        \"Reims\"         \"Rennes\"        \"Bordeaux\"     \n[269] \"Lille\"         \"Marseille\"     \"Lille\"         \"Montpellier\"  \n[273] \"Troyes\"        \"Paris S-G\"     \"Strasbourg\"    \"Clermont Foot\"\n[277] \"Metz\"          \"Angers\"        \"Lyon\"          \"Brest\"        \n[281] \"Saint-Étienne\" \"Lens\"          \"Nantes\"        \"Monaco\"       \n[285] \"Angers\"        \"Rennes\"        \"Bordeaux\"      \"Lorient\"      \n[289] \"Reims\"         \"Marseille\"     \"Nice\"          \"Lille\"        \n[293] \"Strasbourg\"    \"Metz\"          \"Saint-Étienne\" \"Troyes\"       \n[297] \"Montpellier\"   \"Clermont Foot\" \"Lyon\"          \"Paris S-G\"    \n[301] \"Lorient\"       \"Reims\"         \"Clermont Foot\" \"Bordeaux\"     \n[305] \"Monaco\"        \"Angers\"        \"Brest\"         \"Lens\"         \n[309] \"Strasbourg\"    \"Marseille\"     \"Rennes\"        \"Saint-Étienne\"\n[313] \"Lille\"         \"Nice\"          \"Nantes\"        \"Metz\"         \n[317] \"Montpellier\"   \"Troyes\"        \"Lyon\"          \"Paris S-G\"    \n[321] \"Reims\"         \"Monaco\"        \"Bordeaux\"      \"Lorient\"      \n[325] \"Troyes\"        \"Angers\"        \"Strasbourg\"    \"Lens\"         \n[329] \"Brest\"         \"Marseille\"     \"Lyon\"          \"Saint-Étienne\"\n[333] \"Paris S-G\"     \"Rennes\"        \"Metz\"          \"Nantes\"       \n[337] \"Nice\"          \"Clermont Foot\" \"Lille\"         \"Reims\"        \n[341] \"Strasbourg\"    \"Lens\"          \"Rennes\"        \"Troyes\"       \n[345] \"Brest\"         \"Monaco\"        \"Montpellier\"   \"Lorient\"      \n[349] \"Bordeaux\"      \"Marseille\"     \"Lille\"         \"Brest\"        \n[353] \"Metz\"          \"Clermont Foot\" \"Angers\"        \"Reims\"        \n[357] \"Lorient\"       \"Paris S-G\"     \"Nice\"          \"Nantes\"       \n[361] \"Nice\"          \"Bordeaux\"      \"Montpellier\"   \"Rennes\"       \n[365] \"Monaco\"        \"Troyes\"        \"Strasbourg\"    \"Metz\"         \n[369] \"Lyon\"          \"Saint-Étienne\" \"Lille\"         \"Brest\"        \n[373] \"Nantes\"        \"Clermont Foot\" \"Angers\"        \"Lorient\"      \n[377] \"Paris S-G\"     \"Reims\"         \"Marseille\"     \"Lens\""
  },
  {
    "objectID": "slides/01-slides.html#vectors-1",
    "href": "slides/01-slides.html#vectors-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Vectors",
    "text": "Vectors\n\n\nVariables are basically objects that we call vectors\n\nVectors are sequences of values that have the same class\nR won’t let you create a vector containing elements of different classes\n\n\n\nWe make our own vectors using the c()oncatenate function\n\nsome_vector &lt;- c(\"Hello world\", 35, FALSE)\nsome_vector \n\n[1] \"Hello world\" \"35\"          \"FALSE\"      \n\n\n\n\nNote that R will coerce the different elements into the same class when we create a vector (in this case character)\n\nclass(some_vector)\n\n[1] \"character\"\n\n\n\n\nThe fact that vectors are homogeneous in class allows that operations apply to all their elements\n\n\n\n\n\nc(1, 2, 3) / 3\n\n[1] 0.3333333 0.6666667 1.0000000\n\n\n\n\n3 / c(1, 2, 3) \n\n[1] 3.0 1.5 1.0"
  },
  {
    "objectID": "slides/01-slides.html#subsetting",
    "href": "slides/01-slides.html#subsetting",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Subsetting",
    "text": "Subsetting\n\nWith $, you can extract a single variable from a dataset\nYou can extract several variables and specific observations from a data frame using []\n\n\\[\\text{data}[\\text{row(s)}, \\:\\:\\text{column(s)}]\\]\n\n\n\n\n\nInside the brackets, indicate what you want to keep using:\n\nIndices: e.g., the third column has index 3\nLogical: A vector of TRUE and FALSE\nNames: They must be in quotation marks\n\n\n\n\n\nExample:\n\ndata[1, c(\"Venue\", \"Attendance\")]\n\n            Venue Attendance\n1 Stade Louis II.       7500\n\n\nWe can also subset single vectors:\n\nvector &lt;- c(3, 2, 1)\nvector[c(TRUE, TRUE, FALSE)]\n\n[1] 3 2"
  },
  {
    "objectID": "slides/01-slides.html#overview-2",
    "href": "slides/01-slides.html#overview-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nGetting Started\n\nAbout R\nThe R Studio IDE\nImport and eyeball data\n\n\n\n\n\nAnatomy of a data.frame\n\nData structure\nClasses\nVectors\nSubsetting\n\n\n\n\n\nWrap Up\n\nSummary and key take-aways"
  },
  {
    "objectID": "slides/01-slides.html#wrap-up",
    "href": "slides/01-slides.html#wrap-up",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nImport data\n\ndata &lt;- read.csv(\"/Users/jan/Downloads/ligue1.csv\")\n\n\n\nClass\n\nis.numeric(\"1.6180339\") # What would be the output?\n\n\n\n[1] FALSE\n\n\n\n\nSubsetting\n\ndata$Home[3] # What would be the output?\n\n\n\n[1] \"Troyes\""
  },
  {
    "objectID": "slides/01-slides.html#overview-3",
    "href": "slides/01-slides.html#overview-3",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nGetting Started\n\nAbout R\nThe R Studio IDE\nImport and eyeball data\n\n\n\n\n\nAnatomy of a data.frame\n\nData structure\nClasses\nVectors\nSubsetting\n\n\n\n\n\nWrap Up\n\nSummary and key take-aways\n\n\n\n\n\n\nMarkdown and universal writing\n\nOffice Model vs. Engineering Model\nExcel failures\nMarkdown"
  },
  {
    "objectID": "slides/01-slides.html#office-model-vs.-engineering-model",
    "href": "slides/01-slides.html#office-model-vs.-engineering-model",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Office Model vs. Engineering Model",
    "text": "Office Model vs. Engineering Model\nWriting up research is a complicated, messy process!"
  },
  {
    "objectID": "slides/01-slides.html#office-model-vs.-engineering-model-1",
    "href": "slides/01-slides.html#office-model-vs.-engineering-model-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Office Model vs. Engineering Model",
    "text": "Office Model vs. Engineering Model\n\nLoads of puzzle pieces:\n\nData\nStatistical results\nFieldwork\nAnalysis\nFigures\nTables\nCitations\nText\n\nEach of these comes from a different place"
  },
  {
    "objectID": "slides/01-slides.html#office-model-vs.-engineering-model-2",
    "href": "slides/01-slides.html#office-model-vs.-engineering-model-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Office Model vs. Engineering Model",
    "text": "Office Model vs. Engineering Model\nTwo general approaches for this mess:\n\n\nThe Office model\n\nManually put everything in one document (and repeat often)\n\n\nThe Engineering model\n\nWork with the raw pieces and compile it all in the end"
  },
  {
    "objectID": "slides/01-slides.html#the-office-model",
    "href": "slides/01-slides.html#the-office-model",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "The Office Model",
    "text": "The Office Model\n\n\nEverything lives in one .docx file\n\nDrag images in\nCopy/paste stats from R\nConnect Word to Zotero or Endnote\nTrack versions with filenames:\n\nms.docx, ms2_final.docx, ms2_final_final.docx\n\n\n\nFinal output = .docx file"
  },
  {
    "objectID": "slides/01-slides.html#the-engineering-model",
    "href": "slides/01-slides.html#the-engineering-model",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "The Engineering Model",
    "text": "The Engineering Model\n\n\nEverything lives separately and is combined in the end\n\nType text in a plain text document\nImport images automatically\nImport stats automatically from R scripts (.R or .qmd) or .do files\nStore citations in reference manager\nTrack versions with git\n\n\nFinal output = whatever you want (Word, PDF, HTML)"
  },
  {
    "objectID": "slides/01-slides.html#office-model-vs.-engineering-model-3",
    "href": "slides/01-slides.html#office-model-vs.-engineering-model-3",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Office Model vs. Engineering Model",
    "text": "Office Model vs. Engineering Model\nThere is no one right way!\n\n\n\nThe Office model\nCons:\n\nWith changing analyses or data, manually updating your doc is laborous\nChaos-prone:\n\nYou got to remember which script generated what)\n\nError-prone:\n\nIt is easy to forget to update all figures, tables, results in text, etc.\n\n\n\nThe Engineering model\nCons:\n\nA bit of an entry cost\n\nNeed to learn a new coding language\n\nYou’ll always work with people who only use Word"
  },
  {
    "objectID": "slides/01-slides.html#office-model-vs.-engineering-model-4",
    "href": "slides/01-slides.html#office-model-vs.-engineering-model-4",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Office Model vs. Engineering Model",
    "text": "Office Model vs. Engineering Model\n\n\n\nThe Office model\nPros:\n\nNo coding, easy environments\nThe whole world runs on Word\n\n\nThe Engineering model\nPros:\n\nLess cognitive load\n\nWhile everything seems complex in the beginning, no chaos because all is documented and transparent\n\nLess work load (in the long run)\n\nNo need to copy/paste new results, add updated figures, reformat citation, etc.\n\nTransparency\n\nThere’s a record of everything you do\nYour findings are reproducible by anyone (and yourself!)"
  },
  {
    "objectID": "slides/01-slides.html#excel-failures",
    "href": "slides/01-slides.html#excel-failures",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Excel failures",
    "text": "Excel failures\n\n\n\nDept:GDP ratio 90%+ → -0.1% growth\n\n\n\n\nPaul Ryan’s 2013 House budget resolution"
  },
  {
    "objectID": "slides/01-slides.html#excel-failures-1",
    "href": "slides/01-slides.html#excel-failures-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Excel failures",
    "text": "Excel failures\n\n\n\n\n\nThomas Herndon\n\n\n\n\n\n\nFrom Paul Krugman, “The Excel Depression”"
  },
  {
    "objectID": "slides/01-slides.html#engineering-model-in-real-life",
    "href": "slides/01-slides.html#engineering-model-in-real-life",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Engineering model in real life",
    "text": "Engineering model in real life\nPrivate companies and governments use the engineering model to write reports on data\n\n\n\n\n\nAirbnb\n\n\n\n\n\n\n\nThe UK’s reproducible analysis pipeline"
  },
  {
    "objectID": "slides/01-slides.html#so-what-is-markdown",
    "href": "slides/01-slides.html#so-what-is-markdown",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "So, what is Markdown?",
    "text": "So, what is Markdown?\n\nThere are many different typesetting languages in which you can write.\nThe most widely used ones are perhaps LaTeX (mostly scientific work), HTML (web-based stuff) and Word.\n\n\n\n\nHow to get around learning all of them and having to switch for different outputs?\n\nWrite in one simplified syntax (Markdown)\nConvert to whatever output you want"
  },
  {
    "objectID": "slides/01-slides.html#and-what-is-rmarkdownquarto",
    "href": "slides/01-slides.html#and-what-is-rmarkdownquarto",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "And what is RMarkdown/Quarto?",
    "text": "And what is RMarkdown/Quarto?\n\nQuarto and RMarkdown are publishing systems which use markdown language.\nThey allow you to render to different outcome formats\n\n# To HTML\nquarto render manuscript.qmd --to html\n\n# To Word\nquarto render manuscript.qmd --to docx\n\n# To PDF (through LaTeX)\nquarto render manuscript.qmd --to pdf\n\nThey allow to combine code, figures, tables, images, text etc. (more on that now)"
  },
  {
    "objectID": "slides/01-slides.html#overview-4",
    "href": "slides/01-slides.html#overview-4",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nGetting Started\n\nAbout R\nThe R Studio IDE\nImport and eyeball data\nUse functions\n\n\n\n\n\nAnatomy of a data.frame\n\nData structure\nClasses\nVectors\nSubsetting\n\n\n\n\n\nWrap Up\n\nSummary and key take-aways\n\n\n\n\n\n\nMarkdown and universal writing\n\nOffice Model vs. Engineering Model\nExcel failures\nMarkdown\n\n\n\n\n\nWriting reports in Quarto\n\nWhat is Quarto?\nYAML header\nCode chunks\nText formatting\nRun and render your code\nInline code\nTables\nPreset themes\nReport parameters"
  },
  {
    "objectID": "slides/01-slides.html#what-is-quarto",
    "href": "slides/01-slides.html#what-is-quarto",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "What is Quarto?",
    "text": "What is Quarto?\n\nQuarto is an open-source publishing system in which you can both write/run code (R/Python/Julia/Observable) and edit text\nQuarto is the newer, fancier version of RMarkdown (which only worked with R code)\nIt is structured around 3 types of content:\n\nCode chunks to run and render the output\nEditable text to display\nYAML metadata for the Quarto build process"
  },
  {
    "objectID": "slides/01-slides.html#what-is-quarto-1",
    "href": "slides/01-slides.html#what-is-quarto-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "What is Quarto?",
    "text": "What is Quarto?\n\nLet’s create our first Quarto document!\nClick on File &gt; New File &gt; Quarto document"
  },
  {
    "objectID": "slides/01-slides.html#what-is-quarto-2",
    "href": "slides/01-slides.html#what-is-quarto-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "What is Quarto?",
    "text": "What is Quarto?\nIt creates a template containing the 3 types of content:\n\n\n\nYAML header\n \nText\n \nCode Chunk"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles",
    "href": "slides/01-slides.html#basic-principles",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nYAML Header\n\nThe YAML header contains general information related to the file configuration:\n\nTitle/subtitle (in quotes)\nAuthor/date (in quotes)\nOutput type (html/pdf)\nEditor configuration (use source, not visual)\n…\n\n\n\n\nIt should be specified at the very beginning of the document and surrounded by three dashes like this:\n\n---\ntitle: \"My first Quarto document\"\nsubtitle: \"What a blast\"\nauthor: \"My Name\"\ndate: \"05/01/2024\"\nformat: html\neditor: source\n---"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-1",
    "href": "slides/01-slides.html#basic-principles-1",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nCode Chunks\n\nCode chunks are blocks of R code that can be run when working on and rendering the .qmd file\n\n\n\nYou can insert a code chunk using Ctrl + Alt + i or by typing the backticks chunk delimiters as follows\n\n\n1 + 1\n\n\n\n\nWhen rendering the document, R will execute the code\n\nBoth the code and the output will appear in the document like so\n\n\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-2",
    "href": "slides/01-slides.html#basic-principles-2",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nCode Chunks\n\nThe content to be displayed from the code chunk can be specified in chunk options\n\nFor instance, to display only the output and not the code chunk, you can set echo to FALSE\n\n\n\n\n```{r, echo = F}\n1+1\n```\n\n```{r}\n#| echo: false\n1+1 \n```\n\n\nAnd the output will only be\n\n\n\n[1] 2\n\n\n\nInstead of\n\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-3",
    "href": "slides/01-slides.html#basic-principles-3",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nCode Chunks\n\n\n\nChunk Options to Know\n\n\nOption\nDefault\nEffect\n\n\n\n\neval\nTRUE\nWhether to evaluate the code and include its results\n\n\necho\nTRUE\nWhether to display code along with its results\n\n\nwarning\nTRUE\nWhether to display warnings\n\n\nerror\nTRUE\nWhether to display errors\n\n\nmessage\nTRUE\nWhether to display messages\n\n\nresults\n'markup'\n'hide' to hide the output\n\n\nfig.width\n7\nWidth in inches for plots created in chunk\n\n\nfig.height\n7\nHeight in inches for plots created in chunk"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-4",
    "href": "slides/01-slides.html#basic-principles-4",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nCode Chunks\n\nFor an option to be the default for the whole document, set it up in the YAML header:\n\n---\ntitle: \"My first Quarto document\"\nformat: html\nexecute:\n  echo: false\n  warning: false\n---"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-5",
    "href": "slides/01-slides.html#basic-principles-5",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nText Formatting\n\nQuarto is not only about rendering code but also about writing actual text\nYou can write paragraphs as you would normally do on a typical report\nAnd Quarto provides convenient ways to format your text\nUnlike most text editing software, in source Quarto text formatting isn’t about clicking on dedicated buttonds\nIt relies on symbols that should be written along with the text"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-6",
    "href": "slides/01-slides.html#basic-principles-6",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nText Formatting\n\n\n\n\nType…\n…to get\n\n\n\n\nSome text in a paragraph.\n\nMore text in the next paragraph. Always\nuse empty lines between paragraphs.\nSome text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n\n\n*Italic* or _Italic_\nItalic\n\n\n**Bold** or __Bold__\nBold\n\n\n# Heading 1\nHeading 1\n\n\n## Heading 2\nHeading 2\n\n\n### Heading 3\nHeading 3\n\n\n(Go up to heading level 6 with ######)\n\n\n\n[Link text](https://www.example.com)\nLink text"
  },
  {
    "objectID": "slides/01-slides.html#basic-principles-7",
    "href": "slides/01-slides.html#basic-principles-7",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Basic principles",
    "text": "Basic principles\nRun and render your code\n\n\n\nYou have different options to execute the content of a code chunk in Quarto\n\nCheck out the buttons at the top right of the chunk\n\n\n\n\n\n\n\n\nTo render a Quarto file, click on the render button"
  },
  {
    "objectID": "slides/01-slides.html#useful-features",
    "href": "slides/01-slides.html#useful-features",
    "title": "Introduction to R, RStudio and Quarto",
    "section": "Useful features",
    "text": "Useful features\nInline code\n\nQuarto allows to include R output directly in text\nTo do this, use `r r_code_here`\n\n```{r}\n#| label: find-avg-mpg\n#| echo: false\nnumber_of_days &lt;- 5\n```\n\nWe are `r number_of_days` days into the week. \n… would render to this:\n\nWe are 5 days into the week."
  },
  {
    "objectID": "slides/03-slides.html#today-we-learn-how-to-describe-data",
    "href": "slides/03-slides.html#today-we-learn-how-to-describe-data",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Today we learn how to describe data",
    "text": "Today we learn how to describe data\n\n\n\nVariables\nDistributions\n\nDefinition\nGraphical representation\nCommon distributions\n\nCentral tendency\n\nMean\nMedian\n\n\n\n\nSpread\n\nRange, quantiles, and the IQR\nVariance and standard deviation"
  },
  {
    "objectID": "slides/03-slides.html#variables",
    "href": "slides/03-slides.html#variables",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\nImagine you fill out a survey about your way to school."
  },
  {
    "objectID": "slides/03-slides.html#variables-1",
    "href": "slides/03-slides.html#variables-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\n\n\n\n\n\nHow do you get there, usually?\n\n\n\n\n\nHow much time approximately does it take you to get there?\n\n\n\n\n\nWhat arrondissement/suburb do you live in?\n\n\n\n\n\nCompared to your classmates, how close do you think you live to University?\n\n\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\n\n\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'"
  },
  {
    "objectID": "slides/03-slides.html#variables-2",
    "href": "slides/03-slides.html#variables-2",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\n\n\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\n\n\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\n\n\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\n\n\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\n\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\n\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree"
  },
  {
    "objectID": "slides/03-slides.html#variables-3",
    "href": "slides/03-slides.html#variables-3",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\n\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\n\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\n\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\n\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-4",
    "href": "slides/03-slides.html#variables-4",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\n\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\n\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\n\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-5",
    "href": "slides/03-slides.html#variables-5",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\n\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\n\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-6",
    "href": "slides/03-slides.html#variables-6",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\nOrdinal\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\n\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-7",
    "href": "slides/03-slides.html#variables-7",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\nOrdinal\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\nNominal\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\n\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-8",
    "href": "slides/03-slides.html#variables-8",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\nOrdinal\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\nNominal\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\nOrdinal\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\n\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-9",
    "href": "slides/03-slides.html#variables-9",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\nOrdinal\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\nNominal\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\nOrdinal\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\nOpen-ended\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance"
  },
  {
    "objectID": "slides/03-slides.html#variables-10",
    "href": "slides/03-slides.html#variables-10",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variables",
    "text": "Variables\n\n\n\n\n\nSurvey Question\nAnswer Options\nVariable Name\nVariable Type\n\n\n\n\nHow far do you live from the Jourdan University building?\nUse the exact distance in km\nDistance to school\nNumeric\n\n\nHow do you get there, usually?\nBike, Metro, Walking, or Other\nMode of transportation\nNominal\n\n\nHow much time approximately does it take you to get there?\nless than 15 mins, between 15 and 60 mins, more than 60 mins\nTravel time\nOrdinal\n\n\nWhat arrondissement/suburb do you live in?\nOpen-ended\nPlace of residence\nNominal\n\n\nCompared to your classmates, how close do you think you live to University?\nCloser, About the same, Further away\nRelative perceived distance\nOrdinal\n\n\nWhat’s the most annoying part of your itinerary to/from university?\nDescribe briefly\nObject of annoyance\nOpen-ended\n\n\nPlease indicate your level of (dis)agreement with the following statement: 'My itinerary to university is annoying.'\n1: Fully disagree – 5: Fully agree\nDegree of annoyance\nOrdinal/Numeric/Discrete"
  },
  {
    "objectID": "slides/03-slides.html#overview-variable-types",
    "href": "slides/03-slides.html#overview-variable-types",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Overview Variable Types",
    "text": "Overview Variable Types\n\n\n\n\n\nVariable Type\nDescription\nExample\n\n\n\n\nNominal\nThe color of a flower is another example of a nominal variable. Is the flower white, orange, or red? None of those options is “more” than the others; they’re just different.\nFlower color (White, Orange, Red)\n\n\nOrdinal\nAn ordinal variable, just like nominal variables, has categories. But some values are clearly “more” and others clearly “less” - you can ‘order’ observations. However, it is not clear how much more or less one value is than another, and differences might not always be the same between one value and the next.\nSatisfaction levels (Low, Medium, High)\n\n\nContinuous\nA continuous variable can take any numeric value within a given range.\nA person's height (e.g., 170.5 cm)\n\n\nDiscrete\nA discrete variable is numeric, but can only take specific, distinct values. For example, the score given by a judge to a gymnast (only integer values between 0 and 10).\nA judge's score in a gymnast competition (only integer values between 0 and 10)\n\n\nQualitative\nFree text. To quantify it, people typically try to cateogrize them.\nOpen-ended survey answers (e.g. 'Describe your day in detail') or a data frame with news paper headlines"
  },
  {
    "objectID": "slides/03-slides.html#distributions-1",
    "href": "slides/03-slides.html#distributions-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\n\nThe point of descriptive statistics is to summarize a big table of values with a small set of tractable statistics\nThe most comprehensive way to characterize a variable/vector is to compute its distribution:\n\nWhat are the values the variable takes?\nHow frequently does each of these values appear?"
  },
  {
    "objectID": "slides/03-slides.html#distributions-2",
    "href": "slides/03-slides.html#distributions-2",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nConsider this variable\n\n\n\n\n   V1\n1   3\n2   5\n3   4\n4   6\n5   5\n6   4\n7   5\n8   7\n9   7\n10  6\n11  1\n12  7\n13  6\n14  7\n15  6\n16  4\n17  7\n18  7\n19  6\n20  6\n21  5\n22  6\n23  6\n24  3\n25  4\n26  5\n27  2\n28  6\n29  8\n30  8\n\n\n\nWe can count how many times each value appears\n\n\n# A tibble: 8 × 2\n     V1     n\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     1\n3     3     2\n4     4     4\n5     5     5\n6     6     9\n7     7     6\n8     8     2\n\n\n\nVoilà the distribution of our variable."
  },
  {
    "objectID": "slides/03-slides.html#distributions-3",
    "href": "slides/03-slides.html#distributions-3",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nWe can represent this distribution graphically with a bar plot.\n\nEach possible value on the x-axis\nTheir number of occurrences on the y-axis"
  },
  {
    "objectID": "slides/03-slides.html#distributions-4",
    "href": "slides/03-slides.html#distributions-4",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nWould that also work for this variable?\n\n\n\n\n   V1\n1   3\n2   5\n3   4\n4   6\n5   5\n6   4\n7   5\n8   7\n9   7\n10  6\n11  1\n12  7\n13  6\n14  7\n15  6\n16  4\n17  7\n18  7\n19  6\n20  6\n21  5\n22  6\n23  6\n24  3\n25  4\n26  5\n27  2\n28  6\n29  8\n30  8\n\n\n\nNo! In this case, each value appears only once."
  },
  {
    "objectID": "slides/03-slides.html#distributions-5",
    "href": "slides/03-slides.html#distributions-5",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nThis is what the corresponding bar plot would look like"
  },
  {
    "objectID": "slides/03-slides.html#distributions-6",
    "href": "slides/03-slides.html#distributions-6",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nFor continuous variables, one solution to get a sense of the distribution is to do a histogram.\n\nConsider for instance the following variable. For clarity each point is shifted vertically by a random amount."
  },
  {
    "objectID": "slides/03-slides.html#distributions-7",
    "href": "slides/03-slides.html#distributions-7",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nWe can divide the domain of this variable into 5 bins"
  },
  {
    "objectID": "slides/03-slides.html#distributions-8",
    "href": "slides/03-slides.html#distributions-8",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nWe can divide the domain of this variable into 5 bins"
  },
  {
    "objectID": "slides/03-slides.html#distributions-9",
    "href": "slides/03-slides.html#distributions-9",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nAnd count the number of observations within each bin"
  },
  {
    "objectID": "slides/03-slides.html#distributions-10",
    "href": "slides/03-slides.html#distributions-10",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nIf we plot the count per bin, we get a histogram"
  },
  {
    "objectID": "slides/03-slides.html#distributions-11",
    "href": "slides/03-slides.html#distributions-11",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\nThere’s no definitive rule to choose the number of bins.\nToo few can be misleading, too many can be impractical for visualizing."
  },
  {
    "objectID": "slides/03-slides.html#distributions-12",
    "href": "slides/03-slides.html#distributions-12",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\n\nOftentimes, instead of histograms, density plots are used.\n\nBoth are based on the same principle: grouping data points.\nBut densities are continuous"
  },
  {
    "objectID": "slides/03-slides.html#distributions-13",
    "href": "slides/03-slides.html#distributions-13",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Distributions",
    "text": "Distributions\n\nYou won’t learn how to derive densities in this course\nAll you need to know: The higher the value on the y-axis, the more observations there are around the corresponding x location\nLike the histogram can have a varying number of bins, the density plot can vary in its bandwidth"
  },
  {
    "objectID": "slides/03-slides.html#mean",
    "href": "slides/03-slides.html#mean",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Mean",
    "text": "Mean\nThe mean is the most common statistic to describe central tendencies.\n\n\n\n\n   V1\n1   3\n2   5\n3   4\n4   6\n5   5\n6   4\n7   5\n8   7\n9   7\n10  6\n11  1\n12  7\n13  6\n14  7\n15  6\n16  4\n17  7\n18  7\n19  6\n20  6\n21  5\n22  6\n23  6\n24  3\n25  4\n26  5\n27  2\n28  6\n29  8\n30  8\n\n\n\nThe mean is simply the sum of all the grades divided by the number of grades:\n\\[\\bar{x} = \\frac{1}{N}\\sum_{i = 1}^Nx_i\\]\nIn R, we just need to pass a vector/variable to the mean() function\n\n# make a vector\nvariable &lt;- c(1, 2, 4, 8, 12)\n\n# calculate the mean\nmean(variable)\n\n[1] 5.4"
  },
  {
    "objectID": "slides/03-slides.html#median",
    "href": "slides/03-slides.html#median",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Median",
    "text": "Median\nTo obtain the median you first need to sort the values.\n\n\n\n\n   V1\n1   1\n2   2\n3   3\n4   3\n5   4\n6   4\n7   4\n8   4\n9   5\n10  5\n11  5\n12  5\n13  5\n14  6\n15  6\n16  6\n17  6\n18  6\n19  6\n20  6\n21  6\n22  6\n23  7\n24  7\n25  7\n26  7\n27  7\n28  7\n29  8\n30  8\n\n\n\nThe median is the value that divides the distribution into two halves\nWhen there is an even number of observations, the median is the average of the last value of the first half and the first value of the second half\n\\[\\text{Med}(x) = \\begin{cases} x[\\frac{N+1}{2}] & \\text{if } N \\text{ is odd}\\\\\n\\frac{x[\\frac{N}{2}]+x[\\frac{N}{2}+1]}{2} & \\text{if } N \\text{ is even}\n\\end{cases}\\]\nHere, since we have 30 observations, we take the average of the 15th and 16th value:\n\\[[\\frac{6+6}{2}] = 6\\]"
  },
  {
    "objectID": "slides/03-slides.html#median-1",
    "href": "slides/03-slides.html#median-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Median",
    "text": "Median\nTo obtain the median you first need to sort the values.\n\n\n\n\n   V1\n1   1\n2   2\n3   3\n4   3\n5   4\n6   4\n7   4\n8   4\n9   5\n10  5\n11  5\n12  5\n13  5\n14  6\n15  6\n16  6\n17  6\n18  6\n19  6\n20  6\n21  6\n22  6\n23  7\n24  7\n25  7\n26  7\n27  7\n28  7\n29  8\n30  8\n\n\n\nIn R, we just need to pass a vector/variable to the median() function\n\n# make a vector\nvariable &lt;- c(1, 2, 4, 8, 12)\n\n# calculate the mean\nmedian(variable)\n\n[1] 4"
  },
  {
    "objectID": "slides/03-slides.html#mean-vs.-median",
    "href": "slides/03-slides.html#mean-vs.-median",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\n\nWhich of these two measures of central tendency you use will vary on the context.\nMostly, it will be the mean."
  },
  {
    "objectID": "slides/03-slides.html#mean-vs.-median-1",
    "href": "slides/03-slides.html#mean-vs.-median-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Mean vs. Median",
    "text": "Mean vs. Median\n\nNote, however, that the mean is more sensitive to so called, “outliers”."
  },
  {
    "objectID": "slides/03-slides.html#mean-vs.-median-in-r",
    "href": "slides/03-slides.html#mean-vs.-median-in-r",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Mean vs. Median in R",
    "text": "Mean vs. Median in R\n\n\n\n\n\n\nWatch out for NAs\n\n\nUse the na.rm argument and set it to TRUE to remove NAs\n\n\n[1] NA\n\n\n[1] 2.5"
  },
  {
    "objectID": "slides/03-slides.html#range-quantiles-and-the-iqr",
    "href": "slides/03-slides.html#range-quantiles-and-the-iqr",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Range, quantiles, and the IQR",
    "text": "Range, quantiles, and the IQR\nOne simple way to quantify spread is by calculating the range\n\ndistribution &lt;- c(-3, -2, -1, 0, 1, 2, 3)\n\nWhat would be the range ?\n\n\nmax(distribution) - min(distribution)\n\n[1] 6\n\n\n\n\nHowever, with outliers, the range is sometimes not ideal."
  },
  {
    "objectID": "slides/03-slides.html#range-quantiles-and-the-iqr-1",
    "href": "slides/03-slides.html#range-quantiles-and-the-iqr-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Range, quantiles, and the IQR",
    "text": "Range, quantiles, and the IQR\nAn alternative are quantiles\n\nThe median divides the population into 2 groups of equal size\nQuartiles divide the population into 4 groups of equal size\nThere are also terciles, quintiles, deciles, and so on\n\n\nOne way to compute quartiles: divide the ordered variable according to the median\n\nThe lower quartile value is the median of the lower half of the data\nThe upper quartile value is the median of the upper half of the data\nIf there is an odd number of data points in the original ordered data set, don’t include the median in either half\n\n\n\n\n\n\n\n\n\n\n\n-3\n-2\n-1\n0\n1\n2\n3\n\n\n\n\n\n\\[Q_1 = -2,\\:\\:Q_2 = 0,\\:\\:Q_3 = 2\\]\n\n\n\n\n\n\n\n-3\n-2\n-1\n0\n0\n1\n2\n3\n\n\n\n\n\n\\[Q_1 = -1.5,\\:\\:Q_2 = 0,\\:\\:Q_3 = 1.5\\]"
  },
  {
    "objectID": "slides/03-slides.html#range-quantiles-and-the-iqr-2",
    "href": "slides/03-slides.html#range-quantiles-and-the-iqr-2",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Range, quantiles, and the IQR",
    "text": "Range, quantiles, and the IQR\nThe interquartile range is the difference between the third and the first quartile:\n\\(\\text{IQR} = Q_3 - Q_1\\)\nIn other words, it corresponds to the bounds of the set which contains the middle half of the distribution"
  },
  {
    "objectID": "slides/03-slides.html#variance-and-standard-deviation",
    "href": "slides/03-slides.html#variance-and-standard-deviation",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\nThe variance is a way to quantify how the values of a variable tend to deviate from their mean\n\nIf values tend to be close to the mean, then the spread is low\nIf values tend to be far from the mean, then the spread is large\n\n\n\n\nCan we just take the average deviation from the mean?\n\n\n\n\n\nx\nmean(x)\nx - mean(x)\n\n\n\n\n1\n2.5\n-1.5\n\n\n4\n2.5\n1.5\n\n\n-3\n2.5\n-5.5\n\n\n8\n2.5\n5.5\n\n\n\n\n\n\nBy construction it would always be 0: values above and under the mean compensate\n\nBut we can use the absolute value of each deviation: \\(|x_i-\\bar{x}|\\)\nOr their square: \\((x_i-\\bar{x})^2\\)"
  },
  {
    "objectID": "slides/03-slides.html#variance-and-standard-deviation-1",
    "href": "slides/03-slides.html#variance-and-standard-deviation-1",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Variance and standard deviation",
    "text": "Variance and standard deviation\nThis is how the variance is computed: by averaging the squared deviations from the mean\n\\[\\text{Var}(x) = \\frac{1}{N}\\sum_{i = 1}^N(x_i-\\bar{x})^2\\]\n\n\n\nBecause the variance is a sum of squares, it can get quite big compared to the other statistics like the mean, the median or the interquartile range.\nTo express the spread in the same unit as the data, we can take the square root of the variance, which is called the standard deviation\n\n\n\n\\[\\text{SD}(x) = \\sqrt{\\text{Var}(x)} = \\sqrt{\\frac{1}{N}\\sum_{i = 1}^N(x_i-\\bar{x})^2}\\]"
  },
  {
    "objectID": "slides/03-slides.html#computing-spread-in-r",
    "href": "slides/03-slides.html#computing-spread-in-r",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "Computing spread in R",
    "text": "Computing spread in R\nInterquartile range (IQR)\n\nvariable &lt;- c(0, 1, 3, 4, 6, 7, 8, 10, 11)\nIQR(variable)\n\n[1] 5\n\n\nStandard deviation (sd)\n\nsd(variable)\n\n[1] 3.844188\n\n\n\nYou can obtain the quantiles of a variable using the quantile() function (the default are quartiles)\n\nquantile(variable)\n\n  0%  25%  50%  75% 100% \n   0    3    6    8   11"
  },
  {
    "objectID": "slides/03-slides.html#thats-it-for-today",
    "href": "slides/03-slides.html#thats-it-for-today",
    "title": "Variables, Distributions and Summary Statistics",
    "section": "That’s it for today :)",
    "text": "That’s it for today :)"
  },
  {
    "objectID": "slides/05-slides.html#overview",
    "href": "slides/05-slides.html#overview",
    "title": "Statistical Inference",
    "section": "Overview",
    "text": "Overview\n\n\n\nPopulation vs. Sample\nInventing Null Worlds\nThe Central Limit theorem\nTheoretical Distributions"
  },
  {
    "objectID": "slides/05-slides.html#why-do-we-do-statistics",
    "href": "slides/05-slides.html#why-do-we-do-statistics",
    "title": "Statistical Inference",
    "section": "Why do we do statistics ?",
    "text": "Why do we do statistics ?\n To make inferences about a population based on observing only a sample"
  },
  {
    "objectID": "slides/05-slides.html#are-action-movies-better-than-comedies",
    "href": "slides/05-slides.html#are-action-movies-better-than-comedies",
    "title": "Statistical Inference",
    "section": "Are action movies better than comedies?",
    "text": "Are action movies better than comedies?\n\nData → Calculation → Estimate → Truth\n\n\n\n\n\n\n\n\n\n\n\nCategory\nDescription\nNotation\n\n\n\n\nData\nIMDB ratings\n\\(D\\)\n\n\nCalculation\nAverage action rating − average comedy rating\n\\(\\bar{D} = \\frac{\\sum{D}_\\text{Action}}{N} - \\frac{\\sum{D}_\\text{Comedy}}{N}\\)\n\n\nEstimate\n\\(\\bar{D}\\) in a sample of movies\n\\(\\hat{\\delta}\\)\n\n\nTruth\nDifference in rating for all movies\n\\(\\delta\\)"
  },
  {
    "objectID": "slides/05-slides.html#greek-latin-and-extra-markings",
    "href": "slides/05-slides.html#greek-latin-and-extra-markings",
    "title": "Statistical Inference",
    "section": "Greek, Latin, and extra markings",
    "text": "Greek, Latin, and extra markings\n\n\n\n\nGreek\n\nLetters like \\(\\delta\\) are the truth\nLetters with extra markings like \\(\\hat{\\delta}\\) are our estimate of the truth based on our sample\n\n\nLatin\n\nLetters like \\(D\\) are actual data from our sample\nLetters with extra markings like \\(\\bar{D}\\) are calculations from our sample"
  },
  {
    "objectID": "slides/05-slides.html#your-turn-1-calculating-an-estimate",
    "href": "slides/05-slides.html#your-turn-1-calculating-an-estimate",
    "title": "Statistical Inference",
    "section": "Your turn #1: Calculating an estimate",
    "text": "Your turn #1: Calculating an estimate\nCollect IMDB ratings for a bunch of films via the ggplot2movies package.\n\nInstall the package (use either console or the Rstudio interface. Do not use a Script)\nLoad the package in your script.\nLoad the movies data (type: data(\"movies\"))\nMake a new cleaned data frame by\n\n\nselecting only the title, year, rating, Action and Comedy columns\nfiltering out films that classify as both Action and Comedy\nmaking a new variable genre (using mutate() and case_when()) which takes the values “Action” or “Comedy”\nremoving the now obsolete Action and Comedy columns (use select and -)\n\n\nCalculate the average ratings for the two genres\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/05-slides.html#your-turn-1-calculating-an-estimate-1",
    "href": "slides/05-slides.html#your-turn-1-calculating-an-estimate-1",
    "title": "Statistical Inference",
    "section": "Your turn #1: Calculating an estimate",
    "text": "Your turn #1: Calculating an estimate\n\nInstall the package (use either console or the Rstudio interface. Do not use a Script)\n\nUse install.packages(\"ggplot2movies\") in your console.\n\nLoad the package in your script.\n\nUse library(ggplot2movies) in your script.\n\nLoad the movies data (type: data(\"movies\"))"
  },
  {
    "objectID": "slides/05-slides.html#your-turn-1-calculating-an-estimate-2",
    "href": "slides/05-slides.html#your-turn-1-calculating-an-estimate-2",
    "title": "Statistical Inference",
    "section": "Your turn #1: Calculating an estimate",
    "text": "Your turn #1: Calculating an estimate\n\nMake a new cleaned data (movie_data) frame by\n\n\nselecting only the title, year, rating, Action and Comedy columns\nfiltering out films that classify as both Action and Comedy\nmaking a new variable genre (using mutate() and case_when()) which takes the values “Action” or “Comedy”\nremoving the now obsolete Action and Comedy columns (use select and -)\n\n\n# Clean up data\nmovie_data &lt;- movies |&gt; \n  select(title, year, rating, Action, Comedy) |&gt; \n  filter(!(Action == 1 & Comedy == 1)) |&gt; \n  mutate(genre = case_when(Action == 1 ~ \"Action\",\n                           Comedy == 1 ~ \"Comedy\",\n                           TRUE ~ \"Neither\")) |&gt;\n  filter(genre != \"Neither\") |&gt;\n  # Make genre a factor (not necessary at this point)\n  mutate(genre = factor(genre)) |&gt; \n  select(-Action, -Comedy)"
  },
  {
    "objectID": "slides/05-slides.html#your-turn-1-calculating-an-estimate-3",
    "href": "slides/05-slides.html#your-turn-1-calculating-an-estimate-3",
    "title": "Statistical Inference",
    "section": "Your turn #1: Calculating an estimate",
    "text": "Your turn #1: Calculating an estimate\n\nCalculate the average ratings for the two genres\n\n\nmovie_data |&gt; \n  group_by(genre) |&gt; \n  summarize(avg_rating = mean(rating)) \n\n# A tibble: 2 × 2\n  genre  avg_rating\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Action       5.24\n2 Comedy       5.97"
  },
  {
    "objectID": "slides/05-slides.html#so-are-action-movies-better-than-comedies",
    "href": "slides/05-slides.html#so-are-action-movies-better-than-comedies",
    "title": "Statistical Inference",
    "section": "So, are action movies better than comedies?",
    "text": "So, are action movies better than comedies?\n\n\n\n# A tibble: 2 × 2\n  genre  avg_rating\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Action       5.24\n2 Comedy       5.97\n\n\n\n\\[\n\\hat{\\delta} = \\bar{D} = 5.24 - 5.97 = -0.73\n\\]\n\nAction movies seem to be slightly worse. But…\n\n\nWe don’t know if the estimate we found in this sample is actually true for the population of all films"
  },
  {
    "objectID": "slides/05-slides.html#simulated-null-world",
    "href": "slides/05-slides.html#simulated-null-world",
    "title": "Statistical Inference",
    "section": "Simulated Null World",
    "text": "Simulated Null World\n\nLet’s try to imagine a world with no differences between action and comedy movies\n\n\n\nWe simulate data with ratings for 1’000’000 movies where there is no difference (the true \\(\\delta\\) is 0). Imagine that’s the population, i.e. all movies ever made.\n\n\nset.seed(1234) # For reproducibility\n\nimaginary_movies &lt;- tibble(\n  movie_id = 1:1000000,\n  rating = sample(seq(1, 10, by = 0.1), size = 1000000, replace = TRUE),\n  genre = sample(c(\"Comedy\", \"Action\"), size = 1000000, replace = TRUE)\n)"
  },
  {
    "objectID": "slides/05-slides.html#simulated-null-world-1",
    "href": "slides/05-slides.html#simulated-null-world-1",
    "title": "Statistical Inference",
    "section": "Simulated Null World",
    "text": "Simulated Null World\nOur simulated action movies and comedies don’t all have the same rating, but on average there’s (almost) no difference\n\n\n\nimaginary_movies |&gt; \n  group_by(genre) |&gt; \n  summarize(avg_rating = mean(rating)) \n\n# A tibble: 2 × 2\n  genre  avg_rating\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Action       5.51\n2 Comedy       5.50\n\n\n\n\nggplot(imaginary_movies, \n       aes(x = rating, fill = genre)) +\n  geom_bar(alpha = 0.4, position = \"identity\") +\n  scale_x_continuous(breaks = seq(1,10))"
  },
  {
    "objectID": "slides/05-slides.html#sampling-estimating-in-the-null-world",
    "href": "slides/05-slides.html#sampling-estimating-in-the-null-world",
    "title": "Statistical Inference",
    "section": "Sampling & Estimating in the Null world",
    "text": "Sampling & Estimating in the Null world\nIn the actual IMDB data, we looked at a sample of about 20’000 films.\n\n\nWe can randomly pick a sample of that same size from our simulated population\n\n# draw a sample of 20'000 films\nimaginary_sample &lt;- imaginary_movies |&gt; \n  sample_n(20000)\n\n\n\nIn this sample, we actually find a small difference\n\n# compute rating difference in the sample\nestimate &lt;- imaginary_sample |&gt; \n  group_by(genre) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  summarise(diff = avg_rating[genre == \"Action\"] - avg_rating[genre == \"Comedy\"]) %&gt;%\n  pull(diff)\n\nestimate\n\n[1] -0.03535811"
  },
  {
    "objectID": "slides/05-slides.html#check-hatdelta-in-the-null-world",
    "href": "slides/05-slides.html#check-hatdelta-in-the-null-world",
    "title": "Statistical Inference",
    "section": "Check \\(\\hat{\\delta}\\) in the null world",
    "text": "Check \\(\\hat{\\delta}\\) in the null world\nDoes the estimate we found in the IMDB data (\\(\\hat{\\delta}\\) = -0.73) fit well into the world where the true difference \\(\\delta\\) is 0?\n\n\n\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  labs(title = \"Distribution of Rating Differences\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/05-slides.html#check-hatdelta-in-the-null-world-1",
    "href": "slides/05-slides.html#check-hatdelta-in-the-null-world-1",
    "title": "Statistical Inference",
    "section": "Check \\(\\hat{\\delta}\\) in the null world",
    "text": "Check \\(\\hat{\\delta}\\) in the null world\nDoes the estimate we found in the IMDB data (\\(\\hat{\\delta}\\) = -0.73) fit well into the world where the true difference \\(\\delta\\) is 0? Not really.\n\n\nggplot(data.frame(differences), aes(x = differences)) +\n  geom_histogram() +\n  geom_vline(xintercept = -0.73, color = \"red\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Distribution of Rating Differences\",\n       x = \"Mean Rating Difference (Action - Comedy)\",\n       y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/05-slides.html#so-again-are-action-movies-better-than-comedies",
    "href": "slides/05-slides.html#so-again-are-action-movies-better-than-comedies",
    "title": "Statistical Inference",
    "section": "So, again, are action movies better than comedies?",
    "text": "So, again, are action movies better than comedies?\n\n\nWe can now pretty confidently say that in a world where there is no difference, observing what we observed is super unlikely.\nTherefore, we’re pretty confident that in fact there is a difference.\n(We still don’t know what the true difference is, but at least we can say it’s unlikely to be 0)\n🎉 Congratulations, if you got that, you got the whole intuition behind hypothesis testing."
  },
  {
    "objectID": "slides/05-slides.html#quick-recap",
    "href": "slides/05-slides.html#quick-recap",
    "title": "Statistical Inference",
    "section": "Quick recap",
    "text": "Quick recap\n\n\nRemember our problem: We were not sure how (un)likely exactly our observation was in the Null world\nThanks to the central limit theorem, we know that sampling distributions approximate theoretical distributions.\nAnd for theoretical distributions, thanks to math, we know exactly how likely a certain value is 🎉"
  },
  {
    "objectID": "slides/05-slides.html#hypothesis-testing-in-a-nutshell",
    "href": "slides/05-slides.html#hypothesis-testing-in-a-nutshell",
    "title": "Statistical Inference",
    "section": "Hypothesis testing in a nutshell",
    "text": "Hypothesis testing in a nutshell\n\n\nStep 1: Calculate an estimate based on your sample (\\(\\hat{\\delta}\\)).\nThis is the main measure you care about: the difference in means, the average, the median, the proportion, the difference in proportions, etc.\nStep 2: Use simulation to invent a world where the true effect (\\(\\delta\\)) is null.\nSimulate what the world would look like if there was no difference between two groups, or if there was no difference in proportions, or where the average value is a specific number.\nStep 3: Look at \\(\\hat{\\delta}\\) in the null world.\nPut the sample statistic in the null world and see if it fits well.\nStep 4: Calculate the probability that \\(\\hat{\\delta}\\) could exist in the null world.\nThis is the p-value, or the probability that you’d see a \\(\\hat{\\delta}\\) at least that high in a world where there’s no difference.\nStep 5: Decide if \\(\\hat{\\delta}\\) is statistically significant.\nChoose some evidentiary standard or threshold for deciding if there’s sufficient proof for rejecting the null world. Standard thresholds (from least to most rigorous) are 0.1, 0.05, and 0.01."
  },
  {
    "objectID": "slides/05-slides.html#are-action-movies-better-than-comedies-1",
    "href": "slides/05-slides.html#are-action-movies-better-than-comedies-1",
    "title": "Statistical Inference",
    "section": "Are action movies better than comedies?",
    "text": "Are action movies better than comedies?\n\nWe can use a single command in R to test this hypothesis\n\n# Perform a t-test to compare ratings between Action and Comedy movies\nt.test(rating ~ genre, data = movie_data)\n\n\n    Welch Two Sample t-test\n\ndata:  rating by genre\nt = -26.537, df = 5578.2, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Action and group Comedy is not equal to 0\n95 percent confidence interval:\n -0.7907698 -0.6819730\nsample estimates:\nmean in group Action mean in group Comedy \n            5.237372             5.973744 \n\n\n\n\nWe get a very small p-value\n\n# Using format() to use non-scientific notation\nformat(2.2204460493e-16, scientific = FALSE)\n\n[1] \"0.0000000000000002220446\""
  },
  {
    "objectID": "slides/07-slides.html#overview",
    "href": "slides/07-slides.html#overview",
    "title": "Linear Regression",
    "section": "Overview",
    "text": "Overview\n\n\n\nDrawing Lines\nRunning a regression in R\nStatistical Inference for Regression"
  },
  {
    "objectID": "slides/07-slides.html#essential-parts-of-regression",
    "href": "slides/07-slides.html#essential-parts-of-regression",
    "title": "Linear Regression",
    "section": "Essential parts of regression",
    "text": "Essential parts of regression\n\n\nY\n\n“Outcome”/“Dependent”/“Response” variable\n\nThing you want to explain or predict\n\nX\n\n“Explanatory”/“Independent”/“Predictor” variable\n\nThing you use to explain or predict Y"
  },
  {
    "objectID": "slides/07-slides.html#for-example-does-eating-cookies-make-people-happier",
    "href": "slides/07-slides.html#for-example-does-eating-cookies-make-people-happier",
    "title": "Linear Regression",
    "section": "For example, Does eating cookies make people happier?",
    "text": "For example, Does eating cookies make people happier?"
  },
  {
    "objectID": "slides/07-slides.html#cookies-and-happiness",
    "href": "slides/07-slides.html#cookies-and-happiness",
    "title": "Linear Regression",
    "section": "Cookies and happiness",
    "text": "Cookies and happiness"
  },
  {
    "objectID": "slides/07-slides.html#how-good-is-the-fit",
    "href": "slides/07-slides.html#how-good-is-the-fit",
    "title": "Linear Regression",
    "section": "How good is the fit?",
    "text": "How good is the fit?"
  },
  {
    "objectID": "slides/07-slides.html#how-good-is-the-fit-1",
    "href": "slides/07-slides.html#how-good-is-the-fit-1",
    "title": "Linear Regression",
    "section": "How good is the fit?",
    "text": "How good is the fit?"
  },
  {
    "objectID": "slides/07-slides.html#how-good-is-the-fit-2",
    "href": "slides/07-slides.html#how-good-is-the-fit-2",
    "title": "Linear Regression",
    "section": "How good is the fit?",
    "text": "How good is the fit?"
  },
  {
    "objectID": "slides/07-slides.html#residuals",
    "href": "slides/07-slides.html#residuals",
    "title": "Linear Regression",
    "section": "Residuals",
    "text": "Residuals\nWe don’t need to rely on our visual intuition. We can calculate how well the line fits our data.\n\n\nResidual = difference between the observed and predicted values of the dependent variable\n(i.e. distance of a data point to the line, for a given value of X)\n\n\n\nFor example, if someone who ate 5 cookies reported a happiness level of 2.5, but the regression predicts 2.0, the residual is:\n\\(2.5−2.0=0.5\\)"
  },
  {
    "objectID": "slides/07-slides.html#ordinary-least-squares-ols",
    "href": "slides/07-slides.html#ordinary-least-squares-ols",
    "title": "Linear Regression",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\n\nGoal of regression: minimize residuals\n\nA (not so good solution): Take the sum of all residuals\n\nsome residuals are negative, some are positive, they will cancel out\n\n\n\nA better solution: Square all residuals, then sum them\n\nthis is a strategy we’ve already seen for calculating standard deviations.\n\n\n\n\n\n\n\n\n\nWhy not just use absolute values?\n\n\nIt is mathematically a lot easier to find the minimum of squared sums."
  },
  {
    "objectID": "slides/07-slides.html#linear-regression-estimates",
    "href": "slides/07-slides.html#linear-regression-estimates",
    "title": "Linear Regression",
    "section": "Linear regression estimates",
    "text": "Linear regression estimates"
  },
  {
    "objectID": "slides/07-slides.html#linear-regression-estimates-1",
    "href": "slides/07-slides.html#linear-regression-estimates-1",
    "title": "Linear Regression",
    "section": "Linear regression estimates",
    "text": "Linear regression estimates"
  },
  {
    "objectID": "slides/07-slides.html#linear-regression-estimates-2",
    "href": "slides/07-slides.html#linear-regression-estimates-2",
    "title": "Linear Regression",
    "section": "Linear regression estimates",
    "text": "Linear regression estimates"
  },
  {
    "objectID": "slides/07-slides.html#interpreting-linear-regression-output",
    "href": "slides/07-slides.html#interpreting-linear-regression-output",
    "title": "Linear Regression",
    "section": "Interpreting linear regression output",
    "text": "Interpreting linear regression output\n\n\n“A one unit increase in X is associated with a beta 1 increase (or decrease) in Y, on average.”\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute the OLS regression model\nlm(happiness ~ cookies, data = cookies)\n\n\nCall:\nlm(formula = happiness ~ cookies, data = cookies)\n\nCoefficients:\n(Intercept)      cookies  \n     1.1000       0.1636"
  },
  {
    "objectID": "slides/07-slides.html#interpreting-linear-regression-output-1",
    "href": "slides/07-slides.html#interpreting-linear-regression-output-1",
    "title": "Linear Regression",
    "section": "Interpreting linear regression output",
    "text": "Interpreting linear regression output\n\n\n“A one unit increase in X is associated with a beta 1 increase (or decrease) in Y, on average.”\n\n\n\n\n\n\n\n\n\n\nWe get some more detail doing this:\n\n# Compute the OLS regression model\nols_model &lt;- lm(happiness ~ cookies, data = cookies)\n\nsummary(ols_model)\n\n\nCall:\nlm(formula = happiness ~ cookies, data = cookies)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.76364 -0.57955 -0.07727  0.49545  1.08182 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  1.10000    0.47025   2.339   0.0475 *\ncookies      0.16364    0.07579   2.159   0.0629 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6884 on 8 degrees of freedom\nMultiple R-squared:  0.3682,    Adjusted R-squared:  0.2892 \nF-statistic: 4.662 on 1 and 8 DF,  p-value: 0.06287"
  },
  {
    "objectID": "slides/07-slides.html#interpreting-linear-regression-output-2",
    "href": "slides/07-slides.html#interpreting-linear-regression-output-2",
    "title": "Linear Regression",
    "section": "Interpreting linear regression output",
    "text": "Interpreting linear regression output\n\n\n“A one unit increase in X is associated with a beta 1 increase (or decrease) in Y, on average.”\n\n\n\n\n\n\n\n\n\n\nWe can also store the output in a data frame directly using the broom package.\n\nlibrary(broom)\n\ntidy(ols_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    1.1      0.470       2.34  0.0475\n2 cookies        0.164    0.0758      2.16  0.0629"
  },
  {
    "objectID": "slides/07-slides.html#how-does-hypothesis-testing-work-for-linear-regression",
    "href": "slides/07-slides.html#how-does-hypothesis-testing-work-for-linear-regression",
    "title": "Linear Regression",
    "section": "How does hypothesis testing work for linear regression?",
    "text": "How does hypothesis testing work for linear regression?\n\nEverything we’ve learned so far on hypothesis testing and statistical power also applies to linear regression\nIn the last two sessions, our estimate was the difference between comedies and action movies.\nThis time, our estimate is the slope of the regression."
  },
  {
    "objectID": "slides/07-slides.html#simulate-a-cookies-and-happiness-population",
    "href": "slides/07-slides.html#simulate-a-cookies-and-happiness-population",
    "title": "Linear Regression",
    "section": "Simulate a cookies and happiness population",
    "text": "Simulate a cookies and happiness population\nLet’s simulate a true effect world of cookie data with.\n\nset.seed(1234) # For reproducibility\n\n# true happiness without any cookies\nintercept &lt;- 1\n\n# effect of one cookie on happiness\nslope &lt;- 0.3\n\nimaginary_cookies &lt;- tibble(\n  id = 1:1000000,\n  cookies = sample(seq(1, 10, by = 1), size = 1000000, replace = TRUE),\n  # the rnorm() function adds noise, i.e. some random error\n  happiness = intercept + slope * cookies + rnorm(length(cookies), mean = 0, sd = 0.5)\n)"
  },
  {
    "objectID": "slides/07-slides.html#generate-a-sampling-distribution",
    "href": "slides/07-slides.html#generate-a-sampling-distribution",
    "title": "Linear Regression",
    "section": "Generate a sampling distribution",
    "text": "Generate a sampling distribution\nImagine we can ask a sample of 10 people on how happy they are and how many cookies they eat a day - let’s draw many (1000) samples of 10 people and calculate a regression for each.\n\nn_simulations &lt;- 1000\nregression_estimates &lt;- c() # make an empty vector\nsample_size &lt;- 10\n\nfor (i in 1:n_simulations) {\n  # draw a sample of 10 people\n  imaginary_sample &lt;- imaginary_cookies |&gt; \n    sample_n(sample_size)\n  \n  # run a regression on the sample \n  estimate &lt;- lm(happiness ~ cookies, data = imaginary_sample) |&gt; \n    tidy() |&gt; \n    filter(term == \"cookies\") |&gt; \n    pull(estimate)\n\n  regression_estimates [i] &lt;- estimate\n}"
  },
  {
    "objectID": "slides/07-slides.html#according-to-the-central-limit-theorem-what-do-we-expect-the-sampling-distribution-to-look-like",
    "href": "slides/07-slides.html#according-to-the-central-limit-theorem-what-do-we-expect-the-sampling-distribution-to-look-like",
    "title": "Linear Regression",
    "section": "According to the Central Limit Theorem, what do we expect the sampling distribution to look like?",
    "text": "According to the Central Limit Theorem, what do we expect the sampling distribution to look like?"
  },
  {
    "objectID": "slides/07-slides.html#sampling-distribution",
    "href": "slides/07-slides.html#sampling-distribution",
    "title": "Linear Regression",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nThe sampling distribution of estimates approximates a normal distribution."
  },
  {
    "objectID": "slides/07-slides.html#sampling-distribution-1",
    "href": "slides/07-slides.html#sampling-distribution-1",
    "title": "Linear Regression",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nThe sampling distribution gets narrower with a larger sample size"
  },
  {
    "objectID": "slides/07-slides.html#sampling-distribution-2",
    "href": "slides/07-slides.html#sampling-distribution-2",
    "title": "Linear Regression",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nThe sampling distribution gets narrower with a larger sample size"
  },
  {
    "objectID": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis",
    "href": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis",
    "title": "Linear Regression",
    "section": "Your turn: A power simulation for a regression analysis",
    "text": "Your turn: A power simulation for a regression analysis\nImagine we want to run a study to measure the association between cookies and happiness.\n\nWe want to know how many participants we need to recruit to achieve a statistical power of 0.8, assuming an effect of 0.1.\n\nThe final output should be a graph with the power for different sample sizes.\n\n\n\n\n\n\nNote\n\n\nThis task is definitely a challenge. It’s ok to get stuck. Make sure to use the guide on power simulation on the course website, and build on the functions on the next slides.\n\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-1",
    "href": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-1",
    "title": "Linear Regression",
    "section": "Your turn: A power simulation for a regression analysis",
    "text": "Your turn: A power simulation for a regression analysis\n\ngenerate_sample &lt;- function(sample_size){\n  \n  # set regression parameters\n  intercept &lt;- 1\n  slope &lt;- 0.1\n  \n  sample &lt;- tibble(\n    id = 1: sample_size,\n    cookies = sample(seq(1, 10, by = 1), size = sample_size, replace = TRUE),\n    # the rnorm() function adds noise, i.e. some random error\n    happiness = intercept + slope * cookies + rnorm(length(cookies), mean = 0, sd = 1)\n  )\n  \n  return(sample)\n}\n\n# test\n# generate_sample(sample_size = 100)"
  },
  {
    "objectID": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-2",
    "href": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-2",
    "title": "Linear Regression",
    "section": "Your turn: A power simulation for a regression analysis",
    "text": "Your turn: A power simulation for a regression analysis\n\ncalculate_regression &lt;- function(sample){\n  \n  # run a regression on the sample \n  p.value &lt;- lm(happiness ~ cookies, data = sample) |&gt; \n    tidy() |&gt; \n    filter(term == \"cookies\") |&gt; \n    pull(p.value)\n  \n  return(p.value)\n}\n\n# test\n# test_sample &lt;- generate_sample(sample_size = 100)\n# calculate_regression(sample = test_sample)"
  },
  {
    "objectID": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-3",
    "href": "slides/07-slides.html#your-turn-a-power-simulation-for-a-regression-analysis-3",
    "title": "Linear Regression",
    "section": "Your turn: A power simulation for a regression analysis",
    "text": "Your turn: A power simulation for a regression analysis\n\ngenerate_samples &lt;- function(n_simulations, sample_size) {\n  \n  # Make an empty vector\n  p.values &lt;- numeric(n_simulations)\n  \n  for (i in 1:n_simulations) {\n    # Draw a sample with the specified size\n    sample &lt;- generate_sample(sample_size) \n    \n    # Get an estimate\n    p.values[i] &lt;-  calculate_regression(sample)\n  }\n  \n  return(p.values)\n}\n# test\n# generate_samples(n_simulations = 100, sample_size = 10)"
  },
  {
    "objectID": "slides/07-slides.html#solution",
    "href": "slides/07-slides.html#solution",
    "title": "Linear Regression",
    "section": "Solution",
    "text": "Solution\nFirst, we need a function to calculate power\n\ncalculate_power &lt;- function(p.values){\n  \n  # get statistical power \n  power &lt;- data.frame(p.values) |&gt; \n    mutate(significant = ifelse(p.values &lt;= 0.5, TRUE, FALSE)) |&gt; \n    summarize(share_significant = sum(significant) / n()) |&gt; \n    pull(share_significant)\n  \n  return(power)\n}\n# test\n# some_p.values &lt;- generate_samples(n_simulations = 100, sample_size = 10)\n# calculate_power(p.values = some_p.values)"
  },
  {
    "objectID": "slides/07-slides.html#solution-1",
    "href": "slides/07-slides.html#solution-1",
    "title": "Linear Regression",
    "section": "Solution",
    "text": "Solution\nWe can then put it all together in a power simulation function. This function generates 1000 samples, calculates the p-value for the analysis on each sample, and calculates the power.\n\npower_simulation &lt;- function(sample_size, n_simulations = 1000) {\n  \n  # Generate multiple samples and compute estimates\n  sampled_p.values &lt;- generate_samples(n_simulations, sample_size)\n  \n  # Calculate statistical power\n  power &lt;- calculate_power(sampled_p.values)\n  \n  # Return results\n  return(tibble(\n    sample_size = sample_size,\n    n_simulations = n_simulations,\n    estimated_power = power\n  ))\n}\n# test\n# power_simulation(sample_size = 30, n_simulations = 100)"
  },
  {
    "objectID": "slides/07-slides.html#solution-2",
    "href": "slides/07-slides.html#solution-2",
    "title": "Linear Regression",
    "section": "Solution",
    "text": "Solution\nFinally we can use the function to run a power analysis for different sample sizes\n\nsample_sizes &lt;- c(10, 30, 50, 200)\n\n# make an empty data frame\npower_data &lt;- tibble()\n\nfor (i in sample_sizes) {\n  # run power simulation\n  power &lt;- power_simulation(sample_size = i, n_simulations = 1000)\n  \n  power_data &lt;- bind_rows(power_data, power)\n}"
  },
  {
    "objectID": "slides/07-slides.html#solution-3",
    "href": "slides/07-slides.html#solution-3",
    "title": "Linear Regression",
    "section": "Solution",
    "text": "Solution\nWe can then plot the power curve\n\nggplot(power_data, \n       aes(x = sample_size, y = estimated_power)) +\n  geom_point(color = 'red', size = 1.5) +\n  geom_line(color = 'red', size = 1) + \n  # add a horizontal line at 80%\n  geom_hline(aes(yintercept = .8), linetype = 'dashed') + \n  # Prettify!\n  theme_minimal() + \n  scale_y_continuous(labels = scales::percent, limits = c(0,1)) + \n  labs(title = \"Power Simulation for the effect of Cookies on Happiness\",\n       x = 'Sample Size', y = 'Power')"
  },
  {
    "objectID": "slides/09-slides.html#overview",
    "href": "slides/09-slides.html#overview",
    "title": "RCTs and Validity",
    "section": "Overview",
    "text": "Overview\n\n\n\nThe magic of randomization\nHow to analyze RCTs\nValidity"
  },
  {
    "objectID": "slides/09-slides.html#fundamental-problem-of-causal-inference",
    "href": "slides/09-slides.html#fundamental-problem-of-causal-inference",
    "title": "RCTs and Validity",
    "section": "Fundamental problem of causal inference",
    "text": "Fundamental problem of causal inference\n\nImagine we want to know if a treatment helps in quicker recovery of disease\nImagine there is only one patient, Angela\nWe could give Angela the treatment and see how quickly she gets better.\nOr we could not give her the treatment and see how quickly she gets better."
  },
  {
    "objectID": "slides/09-slides.html#fundamental-problem-of-causal-inference-1",
    "href": "slides/09-slides.html#fundamental-problem-of-causal-inference-1",
    "title": "RCTs and Validity",
    "section": "Fundamental problem of causal inference",
    "text": "Fundamental problem of causal inference\n\nIn either case, we’d want to know “What if…\n“What if we had/had not given her the treatment”\nThis is also called a counterfactual - counter to the fact of what actually happened."
  },
  {
    "objectID": "slides/09-slides.html#solution-randomization-and-averages",
    "href": "slides/09-slides.html#solution-randomization-and-averages",
    "title": "RCTs and Validity",
    "section": "Solution: randomization and averages",
    "text": "Solution: randomization and averages\n\nInstead of only one patient, we need to look at several patients\nIf we randomly assign patients to a treatment and a control condition…\nAnd if the sample is big enough…\nThen people in these groups are on average the same on all imaginable variables (e.g. age, sex, income)\nThat’s the magic of randomization"
  },
  {
    "objectID": "slides/09-slides.html#randomized-controlled-trials-rcts",
    "href": "slides/09-slides.html#randomized-controlled-trials-rcts",
    "title": "RCTs and Validity",
    "section": "Randomized Controlled Trials (RCTs)",
    "text": "Randomized Controlled Trials (RCTs)"
  },
  {
    "objectID": "slides/09-slides.html#analyzing-rcts-is-very-easy",
    "href": "slides/09-slides.html#analyzing-rcts-is-very-easy",
    "title": "RCTs and Validity",
    "section": "Analyzing RCTs is very easy",
    "text": "Analyzing RCTs is very easy\n\nStep 1: Check that key variables are balanced between control and treatment group\n(this is something we’d expect from randomization, but with small samples you might get unlucky)\n\nStep 2: Find difference in average outcome in treatment and control groups"
  },
  {
    "objectID": "slides/09-slides.html#example-rct",
    "href": "slides/09-slides.html#example-rct",
    "title": "RCTs and Validity",
    "section": "Example RCT",
    "text": "Example RCT\n\nimaginary_rct \n\n# A tibble: 800 × 6\n   person treatment   age sex    recovery_time male_num\n    &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n 1      1 Treatment    23 Female         3.94         0\n 2      2 Treatment    38 Male           4.84         1\n 3      3 Treatment    46 Female        -2.07         0\n 4      4 Treatment    12 Female         5.35         0\n 5      5 Treatment    39 Male           3.04         1\n 6      6 Treatment    40 Male           2.46         1\n 7      7 Treatment    29 Female         6.32         0\n 8      8 Treatment    30 Male           7.44         1\n 9      9 Treatment    29 Female        -0.442        0\n10     10 Treatment    26 Female         6.03         0\n# ℹ 790 more rows"
  },
  {
    "objectID": "slides/09-slides.html#check-balance",
    "href": "slides/09-slides.html#check-balance",
    "title": "RCTs and Validity",
    "section": "1. Check balance",
    "text": "1. Check balance\n\nimaginary_rct %&gt;% \n  group_by(treatment) %&gt;% \n  summarize(avg_age = mean(age),\n            prop_male = mean(sex == \"Male\"))\n\n# A tibble: 2 × 3\n  treatment avg_age prop_male\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 Control      35.3      0.52\n2 Treatment    35.1      0.52"
  },
  {
    "objectID": "slides/09-slides.html#calculate-difference",
    "href": "slides/09-slides.html#calculate-difference",
    "title": "RCTs and Validity",
    "section": "2. Calculate difference",
    "text": "2. Calculate difference\n\n\nGroup means\n\nimaginary_rct %&gt;% \n  group_by(treatment) %&gt;% \n  summarize(avg_outcome = round(mean(recovery_time), digits = 2))\n\n# A tibble: 2 × 2\n  treatment avg_outcome\n  &lt;chr&gt;           &lt;dbl&gt;\n1 Control          6.04\n2 Treatment        2.9 \n\n2.90 - 6.04\n\n[1] -3.14\n\n\n\nRegression\n\nrct_model &lt;- lm(recovery_time ~ treatment, \n                data = imaginary_rct)\n\ntidy(rct_model) |&gt; \n  select(estimate, statistic, p.value)\n\n# A tibble: 2 × 3\n  estimate statistic   p.value\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     6.04      40.4 6.84e-195\n2    -3.15     -14.9 2.84e- 44"
  },
  {
    "objectID": "slides/09-slides.html#your-turn-analyzing-an-rct",
    "href": "slides/09-slides.html#your-turn-analyzing-an-rct",
    "title": "RCTs and Validity",
    "section": "Your turn: Analyzing an RCT",
    "text": "Your turn: Analyzing an RCT\nImagine an NGO is planning on launching a training program designed to boost incomes.\nThey ran a study on 1,000 participants over the course of 6 months and you just got your data back.\n\nDownload and read the data set (either here:  village_randomized.csv, or from this week’s content on the course website)\nBefore calculating the effect of the program, first check how well balanced the random assignment was.\nEstimate the treatment effect. This is simply the average outcome for people in the program minus the average outcome for people not in the program.\n\n\ncountdown::countdown(\n  minutes = 15,\n  bottom = 0, \n  right = 0,\n  # Fanfare when it's over\n  play_sound = FALSE,\n  color_border              = \"#FFFFFF\",\n  color_text                = \"#7aa81e\",\n  color_running_background  = \"#7aa81e\",\n  color_running_text        = \"#FFFFFF\",\n  color_finished_background = \"#ffa07a\",\n  color_finished_text       = \"#FFFFFF\",\n  font_size = \"1em\",\n  start_immediately = TRUE\n  )\n\n\n−+\n15:00"
  },
  {
    "objectID": "slides/09-slides.html#solution",
    "href": "slides/09-slides.html#solution",
    "title": "RCTs and Validity",
    "section": "Solution",
    "text": "Solution\n\nDownload and read the data set\n\n\n# read data\nvillage_randomized &lt;- read_csv(\"data/village_randomized.csv\")\n\n\n\nRows: 1000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): sex, program\ndbl (6): id, age, pre_income, post_income, sex_num, program_num\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/09-slides.html#solution-1",
    "href": "slides/09-slides.html#solution-1",
    "title": "RCTs and Validity",
    "section": "Solution",
    "text": "Solution\n\nBefore calculating the effect of the program, first check how well balanced the random assignment was.\n\n\nvillage_randomized |&gt;\n  group_by(program) |&gt;\n  summarize(\n    n = n(),\n    prop_male = mean(sex_num),\n    avg_age = mean(age),\n    avg_pre_income = mean(pre_income)\n    ) |&gt; \n  # this rounds all numeric variables in the data frame to two digits\n  mutate_if(is.numeric, ~ round(.x, digits = 2)) \n\n# A tibble: 2 × 5\n  program        n prop_male avg_age avg_pre_income\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1 No program   503      0.58    34.9           803.\n2 Program      497      0.6     34.9           801."
  },
  {
    "objectID": "slides/09-slides.html#solution-2",
    "href": "slides/09-slides.html#solution-2",
    "title": "RCTs and Validity",
    "section": "Solution",
    "text": "Solution\n\nEstimate the treatment effect. This is simply the average outcome for people in the program minus the average outcome for people not in the program.\n\n\n# for descriptive findings\nvillage_randomized |&gt;\n  group_by(program) |&gt;\n  summarize(avg_post = mean(post_income))\n\n# A tibble: 2 × 2\n  program    avg_post\n  &lt;chr&gt;         &lt;dbl&gt;\n1 No program    1180.\n2 Program       1279.\n\n\n\n# as a regression\nmodel_rct &lt;- lm(post_income ~ program, data = village_randomized)\ntidy(model_rct)\n\n# A tibble: 2 × 5\n  term           estimate std.error statistic  p.value\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)      1180.       4.27     276.  0       \n2 programProgram     99.2      6.06      16.4 1.26e-53"
  },
  {
    "objectID": "slides/09-slides.html#there-are-many-different-threats-to-validity",
    "href": "slides/09-slides.html#there-are-many-different-threats-to-validity",
    "title": "RCTs and Validity",
    "section": "There are many different threats to validity",
    "text": "There are many different threats to validity\nThe overarching question is always the same:\n\nCan we draw valid conclusions about our research question from the data we have?"
  },
  {
    "objectID": "slides/09-slides.html#external-vs.-internal-validity",
    "href": "slides/09-slides.html#external-vs.-internal-validity",
    "title": "RCTs and Validity",
    "section": "External vs. internal validity",
    "text": "External vs. internal validity"
  },
  {
    "objectID": "slides/09-slides.html#internal-validity",
    "href": "slides/09-slides.html#internal-validity",
    "title": "RCTs and Validity",
    "section": "Internal validity",
    "text": "Internal validity\n“How well does our research design in identify the (causal) effect we are looking for?”\n\nRCTs allows us to establish (valid) causality, but it is not immune to everything…\n\n(Self-)selection\nAttrition\nHawthorne\nJohn Henry\nSpillovers\nIntervening events"
  },
  {
    "objectID": "slides/09-slides.html#self-selection",
    "href": "slides/09-slides.html#self-selection",
    "title": "RCTs and Validity",
    "section": "Self-selection",
    "text": "Self-selection\n\nIf people can choose to enroll in a program, those who enroll will be different from those who do not\n\n\nHow to fix it?\n\nMake sure randomization is happening correctly"
  },
  {
    "objectID": "slides/09-slides.html#attrition",
    "href": "slides/09-slides.html#attrition",
    "title": "RCTs and Validity",
    "section": "Attrition",
    "text": "Attrition\nIf the people who leave a program or study are different than those who stay, the effects will be biased\n\nHow to fix it?\n\nCheck characteristics of those who stay and those who leave"
  },
  {
    "objectID": "slides/09-slides.html#hawthorne-effect",
    "href": "slides/09-slides.html#hawthorne-effect",
    "title": "RCTs and Validity",
    "section": "Hawthorne effect",
    "text": "Hawthorne effect\nObserving people makes them behave differently\n\nHow to fix it?\n\nHide? A tough fix…"
  },
  {
    "objectID": "slides/09-slides.html#john-henry-effect",
    "href": "slides/09-slides.html#john-henry-effect",
    "title": "RCTs and Validity",
    "section": "John Henry effect",
    "text": "John Henry effect\nControl group works hard to prove they’re as good as the treatment group\n\nHow to fix it?\n\nKeep two groups separate"
  },
  {
    "objectID": "slides/09-slides.html#spillover-effects",
    "href": "slides/09-slides.html#spillover-effects",
    "title": "RCTs and Validity",
    "section": "Spillover effects",
    "text": "Spillover effects\nControl groups are sometimes naturally affected by what the treatment group is getting\ne.g. vaccine distribution in global south\n\nHow to fix it?\n\nKeep two groups separate; use distant control groups"
  },
  {
    "objectID": "slides/09-slides.html#external-validity",
    "href": "slides/09-slides.html#external-validity",
    "title": "RCTs and Validity",
    "section": "External validity",
    "text": "External validity\n“Are our findings generalizable to the population we care about?”"
  },
  {
    "objectID": "slides/09-slides.html#lab-conditions-vs.-real-world",
    "href": "slides/09-slides.html#lab-conditions-vs.-real-world",
    "title": "RCTs and Validity",
    "section": "Lab conditions vs. real world",
    "text": "Lab conditions vs. real world\n\nMost study volunteers are weird\nWestern, educated, from industrialized. rich, and democratic countries"
  },
  {
    "objectID": "slides/09-slides.html#validity-wrap-up",
    "href": "slides/09-slides.html#validity-wrap-up",
    "title": "RCTs and Validity",
    "section": "Validity wrap-up",
    "text": "Validity wrap-up\n\nRCTs are also vulnerable to some threats of internal validity\nRCTs definitely don’t magically fix external validity"
  },
  {
    "objectID": "slides/12-slides.html#overview",
    "href": "slides/12-slides.html#overview",
    "title": "Meta Analyses",
    "section": "Overview",
    "text": "Overview\n\n\n\nWhy meta-analyses\nThe research question\nEffect Sizes\nSystematic literature search\nRunning a meta-analysis"
  },
  {
    "objectID": "slides/12-slides.html#a-typical-textbook-pyramid-of-evidence",
    "href": "slides/12-slides.html#a-typical-textbook-pyramid-of-evidence",
    "title": "Meta Analyses",
    "section": "(A typical textbook) pyramid of evidence",
    "text": "(A typical textbook) pyramid of evidence"
  },
  {
    "objectID": "slides/12-slides.html#why-are-meta-analyses-at-the-top-of-the-pyramid",
    "href": "slides/12-slides.html#why-are-meta-analyses-at-the-top-of-the-pyramid",
    "title": "Meta Analyses",
    "section": "Why are meta-analyses at the top of the pyramid?",
    "text": "Why are meta-analyses at the top of the pyramid?\n\nResults of single studies are affected by many factors:\n\nthe country\nexperimental setup\nresearchers\nsample demographics…\n\nAveraging across many studies, we get a more robust, generalizable result"
  },
  {
    "objectID": "slides/12-slides.html#case-study-can-people-tell-true-news-from-false-news",
    "href": "slides/12-slides.html#case-study-can-people-tell-true-news-from-false-news",
    "title": "Meta Analyses",
    "section": "Case study: “Can people tell true news from false News ?”",
    "text": "Case study: “Can people tell true news from false News ?”\n\nPfänder, J., & Altay, S. (2025). Spotting false news and doubting true news: A systematic review and meta-analysis of news judgements. Nature Human Behaviour, 1–12. https://doi.org/10.1038/s41562-024-02086-1"
  },
  {
    "objectID": "slides/12-slides.html#case-study-can-people-tell-true-news-from-false-news-1",
    "href": "slides/12-slides.html#case-study-can-people-tell-true-news-from-false-news-1",
    "title": "Meta Analyses",
    "section": "Case study: “Can people tell true news from false News ?”",
    "text": "Case study: “Can people tell true news from false News ?”\n\n\n\n\n\nPennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293."
  },
  {
    "objectID": "slides/12-slides.html#define-a-quantifiable-outcome",
    "href": "slides/12-slides.html#define-a-quantifiable-outcome",
    "title": "Meta Analyses",
    "section": "Define a quantifiable outcome",
    "text": "Define a quantifiable outcome\n\n\n\\[\n\\text{discernment} = \\text{mean accuracy}_{\\text{true news}} - \\text{mean accuracy}_{\\text{false news}}\n\\]"
  },
  {
    "objectID": "slides/12-slides.html#your-turn",
    "href": "slides/12-slides.html#your-turn",
    "title": "Meta Analyses",
    "section": "Your turn:",
    "text": "Your turn:\n\nDownload the data from:\n\n\nLyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb\n\n Lyons_2024.csv\n\nCalculate a discernment score\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/12-slides.html#what-are-effect-sizes",
    "href": "slides/12-slides.html#what-are-effect-sizes",
    "title": "Meta Analyses",
    "section": "What are effect sizes?",
    "text": "What are effect sizes?\nIn Meta-analyses not individual participants, but single studies are the unit of analysis\nThe outcomes of these studies are called “effect sizes”.\n\nGraphic adapted from: Harrer, M., Cuijpers, P., A, F. T., & Ebert, D. D. (2021). Doing Meta-Analysis With R: A Hands-On Guide (1st ed.). Chapman & Hall/CRC Press."
  },
  {
    "objectID": "slides/12-slides.html#your-turn-1",
    "href": "slides/12-slides.html#your-turn-1",
    "title": "Meta Analyses",
    "section": "Your turn:",
    "text": "Your turn:\n\nDownload the data from\n\n\nAllen, J., Arechar, A. A., Pennycook, G., & Rand, D. G. (2021). Scaling up fact-checking using the wisdom of crowds. Science Advances, 7(36), eabf4393.\n\n Allen_2021.csv\n\nCalculate the discernment score.\nHow does this compare to the other study? What issue are you seeing when you want to compare the two?\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/12-slides.html#non-standardized-effect-sizes",
    "href": "slides/12-slides.html#non-standardized-effect-sizes",
    "title": "Meta Analyses",
    "section": "Non-standardized effect sizes",
    "text": "Non-standardized effect sizes\n\n…can only be directly interpreted on their original scales\n\n\n\n\n\n\npaper_id\nscale\nfake\ntrue\ndiscernment\n\n\n\n\nAllen_2021\n7\n3.82\n4.74\n0.92\n\n\nLyons_2024_b\n4\n1.86\n2.56\n0.69\n\n\n\n\n\n\nThis is not great if we want to compare studies."
  },
  {
    "objectID": "slides/12-slides.html#standardized-effect-sizes",
    "href": "slides/12-slides.html#standardized-effect-sizes",
    "title": "Meta Analyses",
    "section": "Standardized effect sizes",
    "text": "Standardized effect sizes\n\n… are not dependent on specific scales\n\nThey allow us to compare effects across studies that use different outcome measures."
  },
  {
    "objectID": "slides/12-slides.html#cohens-d",
    "href": "slides/12-slides.html#cohens-d",
    "title": "Meta Analyses",
    "section": "Cohen’s d",
    "text": "Cohen’s d\n\n\nPerhaps the most popular standardized effect size when comparing two groups on a continuous outcome\n\n\n\nThe idea is to express effect sizes in units of standard deviations"
  },
  {
    "objectID": "slides/12-slides.html#cohens-d-1",
    "href": "slides/12-slides.html#cohens-d-1",
    "title": "Meta Analyses",
    "section": "Cohen’s d",
    "text": "Cohen’s d\n\nIf we plot the distribution of all individual accuracy ratings, we get something like below (slightly less perfect).\nCohen’s d uses the standard devations of these distributions"
  },
  {
    "objectID": "slides/12-slides.html#cohens-d-2",
    "href": "slides/12-slides.html#cohens-d-2",
    "title": "Meta Analyses",
    "section": "Cohen’s d",
    "text": "Cohen’s d\n\n\\[\n\\text{Cohen's d} = \\frac{\\bar{x}_{\\text{true}} - \\bar{x}_{\\text{false}}}{SD_{\\text{pooled}}}\n\\]\nwith\n\\[\nSD_{\\text{pooled}} = \\sqrt{\\frac{SD_{\\text{true}}^2+SD_{\\text{false}}^2}{2}}\n\\]"
  },
  {
    "objectID": "slides/12-slides.html#your-turn-2",
    "href": "slides/12-slides.html#your-turn-2",
    "title": "Meta Analyses",
    "section": "Your turn:",
    "text": "Your turn:\nIn which of the two studies did participants discern better? Calcuate Cohens’ d for the two studies and compare.\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/12-slides.html#interpreting-cohens-d",
    "href": "slides/12-slides.html#interpreting-cohens-d",
    "title": "Meta Analyses",
    "section": "Interpreting Cohen’s d",
    "text": "Interpreting Cohen’s d\n“Participants in Lyons (2024) discerned better between true and false news than participants in Allen (2021), by 0.28 standard deviations”\n\nAlthough widely used, this is not always easy to interpret. In psychology, as a rough guide for intepreting Cohen’s d:\n\nsmall (0.2) &lt; medium (0.5) &lt; large (0.8)\n\n(but: depends a lot on the discipline, research question etc.)\n\n\nIf you want to play around with the interpretation of Cohen’s d, check out this guide by Kristoffer Magnusson"
  },
  {
    "objectID": "slides/12-slides.html#the-search-string",
    "href": "slides/12-slides.html#the-search-string",
    "title": "Meta Analyses",
    "section": "The search string",
    "text": "The search string\nIdeally, we want all studies that have ever been written on our research question. The more the better.\n\nBut…\n\n\n\nScreenshot from a google scholar search on June 27, 2024\n\n\nWe often need to be specific in our search."
  },
  {
    "objectID": "slides/12-slides.html#the-search-string-1",
    "href": "slides/12-slides.html#the-search-string-1",
    "title": "Meta Analyses",
    "section": "The search string",
    "text": "The search string\n\n\nWhen you start a meta-analysis, you often have at least a rough idea of what you are looking for/ have a paper that inspired your idea\nThis gives you ideas of keywords that you could look for."
  },
  {
    "objectID": "slides/12-slides.html#the-search-string-2",
    "href": "slides/12-slides.html#the-search-string-2",
    "title": "Meta Analyses",
    "section": "The search string",
    "text": "The search string\nThis was our search string:\n\n‘“false news” OR “fake news” OR “false stor*” AND “accuracy” OR “discernment” OR “credibilit*” OR “belief” OR “susceptib*”’\n\n\n\n\n\nWould this search string have yielded a study called “News accuracy ratings of US adults during 2016 presidential elections”?\n\n\n\n\nNo, because of how boolean operators work."
  },
  {
    "objectID": "slides/12-slides.html#boolean-operators",
    "href": "slides/12-slides.html#boolean-operators",
    "title": "Meta Analyses",
    "section": "Boolean operators",
    "text": "Boolean operators\n\n\n\n\n\nBoolean AND operator. Only if both keywords are included, a result will show up.\n\n\n\n\n\n\nBoolean OR operator. As long as one of the keywords is included, a result will show up."
  },
  {
    "objectID": "slides/12-slides.html#boolean-operators-1",
    "href": "slides/12-slides.html#boolean-operators-1",
    "title": "Meta Analyses",
    "section": "Boolean operators",
    "text": "Boolean operators\n\n‘“false news” OR “fake news” OR “false stor*” AND “accuracy” OR “discernment” OR “credibilit*” OR “belief” OR “susceptib*”’\n\n\n\nOur search string, put a bit more abstractly, reads …OR…OR…AND…Or…OR…\nAs in math, there is a hierarchy among operators.\nOn Scopus (the search engine we used), OR operators are treated before AND operators."
  },
  {
    "objectID": "slides/12-slides.html#data-bases",
    "href": "slides/12-slides.html#data-bases",
    "title": "Meta Analyses",
    "section": "Data bases",
    "text": "Data bases\n\nGoogle Scholar – great in most cases, but some disadvantages (e.g. user-specific results)\n\n\n\nThere are many other data bases out there:\n\nPubmed\nScopus\nWeb of Science\nYour local university library catalogue\n…"
  },
  {
    "objectID": "slides/12-slides.html#data-bases-1",
    "href": "slides/12-slides.html#data-bases-1",
    "title": "Meta Analyses",
    "section": "Data bases",
    "text": "Data bases\nData bases allow very refined searches."
  },
  {
    "objectID": "slides/12-slides.html#data-bases-2",
    "href": "slides/12-slides.html#data-bases-2",
    "title": "Meta Analyses",
    "section": "Data bases",
    "text": "Data bases\nSome databases also have features to export your search results as data sets."
  },
  {
    "objectID": "slides/12-slides.html#literature-screening",
    "href": "slides/12-slides.html#literature-screening",
    "title": "Meta Analyses",
    "section": "Literature screening",
    "text": "Literature screening\nThere are several stages of deciding which studies to include:\n\nTitle screening (sort out titles that are obviously irrelevant)\nAbstract screening\nFull-text screening\n\n\nIn particular in screening phases 2 and 3, all decisions are based on inclusion criteria (and must be documented!).\nFor example, some of our inclusion criteria were:\n\nenglish language\na measure of accuracy for both true and false news\nreal-world news items only"
  },
  {
    "objectID": "slides/12-slides.html#prisma-guidelines",
    "href": "slides/12-slides.html#prisma-guidelines",
    "title": "Meta Analyses",
    "section": "PRISMA guidelines",
    "text": "PRISMA guidelines\n\n\nThe whole point of a systematic search is to have an exhaustive and unbiased pool of studies.\nWe won’t discuss the whole process here, but if you ever do a systematic review, you’ll want to check out the PRISMA guidelines for systematic reviews and meta-analyses"
  },
  {
    "objectID": "slides/12-slides.html#the-meta-analytic-average",
    "href": "slides/12-slides.html#the-meta-analytic-average",
    "title": "Meta Analyses",
    "section": "The meta-analytic average",
    "text": "The meta-analytic average\n\nA meta-analysis is basically taking an average of all effect sizes\n\n\nGraphic adapted from: Harrer, M., Cuijpers, P., A, F. T., & Ebert, D. D. (2021). Doing Meta-Analysis With R: A Hands-On Guide (1st ed.). Chapman & Hall/CRC Press."
  },
  {
    "objectID": "slides/12-slides.html#the-meta-analytic-average-1",
    "href": "slides/12-slides.html#the-meta-analytic-average-1",
    "title": "Meta Analyses",
    "section": "The meta-analytic average",
    "text": "The meta-analytic average\n\n…but not just a normal average - a weighted average.\n\nThe idea is that larger studies (with more participants/observations) are given more weight than smaller studies\nThis is typically done via the standard error of the effect sizes"
  },
  {
    "objectID": "slides/12-slides.html#cohens-d-part-ii-the-standard-error",
    "href": "slides/12-slides.html#cohens-d-part-ii-the-standard-error",
    "title": "Meta Analyses",
    "section": "Cohen’s d (part II): the standard error",
    "text": "Cohen’s d (part II): the standard error\n\n\n\n\n\n\nTip\n\n\nRemember:\nThe standard error is a special standard deviation - the standard deviation of the sampling distribution (i.e. the–hypothetical–distribution of estimates we would expect from drawing many different samples from a population)."
  },
  {
    "objectID": "slides/12-slides.html#cohens-d-part-ii-the-standard-error-1",
    "href": "slides/12-slides.html#cohens-d-part-ii-the-standard-error-1",
    "title": "Meta Analyses",
    "section": "Cohen’s d (part II): the standard error",
    "text": "Cohen’s d (part II): the standard error\n\n\\[\nSE_{\\text{Cohen's d}} = \\sqrt{ \\frac{n_\\text{true} + n_\\text{false}}{n_\\text{true} n_\\text{false}} + \\frac{d^2}{2(n_\\text{true} + n_\\text{false})} }\n\\]\n\n\\(d\\) = Cohen’s d\n\\(n_\\text{false}\\) = sample size of fake news items,\n\\(n_\\text{true}\\) = sample size of true news items,\nand \\(SD_{\\text{pooled}}\\) the pooled standard deviation of both groups (see above).\n\n\n\n\n\n\n\n\nTip\n\n\nAll you need to remember:\nWith greater sample size, smaller standard error (this should ring a bell from our class on statistical power)."
  },
  {
    "objectID": "slides/12-slides.html#calculate-weigths",
    "href": "slides/12-slides.html#calculate-weigths",
    "title": "Meta Analyses",
    "section": "Calculate weigths",
    "text": "Calculate weigths\n\nAs noted earlier, the standard error helps us calculate a weight for each study \\(k\\) in our meta-analysis:\n\\[\nw_k = \\frac{1}{se^2_k}\n\\]\n\n\\(se^2\\) = squared standard error (also called variance) of a study \\(k\\)\n\n\n\n\n\n\n\nTip\n\n\nNote:\nThe bigger the sample size, the smaller the standard error, the greater the weight."
  },
  {
    "objectID": "slides/12-slides.html#calculate-the-meta-analytic-average",
    "href": "slides/12-slides.html#calculate-the-meta-analytic-average",
    "title": "Meta Analyses",
    "section": "Calculate the meta-analytic average",
    "text": "Calculate the meta-analytic average\n\nBased on the standardized effect sizes and their standard errors, we can finally calculate the meta-analytic average.\n\\[\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw_k}{\\sum^{K}_{k=1} w_k}\n\\]\n\n\\(\\hat\\theta\\) = estimate of the meta-analytic average"
  },
  {
    "objectID": "slides/12-slides.html#the-meta-analytic-average-2",
    "href": "slides/12-slides.html#the-meta-analytic-average-2",
    "title": "Meta Analyses",
    "section": "The meta-analytic average",
    "text": "The meta-analytic average\n\nIn practice, you’ll always use existing R packages for these calculations.\nThere are many packages out there, but a popular one is the metafor package"
  },
  {
    "objectID": "slides/12-slides.html#your-turn-3",
    "href": "slides/12-slides.html#your-turn-3",
    "title": "Meta Analyses",
    "section": "Your turn:",
    "text": "Your turn:\nCan people discern between true and false news? Use the metafor package and its rma.uni() function (check documentation by clicking on the function) to calculate the meta-analytic average.\n\n\n\n\n\n\nTip\n\n\n\nyou don’t need to specify the weights arguments\nyou only need to specify yi, sei and data\n\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/12-slides.html#forest-plot",
    "href": "slides/12-slides.html#forest-plot",
    "title": "Meta Analyses",
    "section": "Forest plot",
    "text": "Forest plot\n\nPoints are effect sizes, bars are 95% confidence intervals - an indicator of statistical significance we haven’t discussed yet. The idea is that if they exclude 0, that’s like having a p-value below 0.05: the estimate is statistically significant."
  }
]